<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EKVJPJXV5K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EKVJPJXV5K');
</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [["$", "$"], ["\\(", "\\)"]],
      displayMath: [["$$", "$$"], ["\\[", "\\]"]],
      processEscapes: true
    },
    "HTML-CSS": {
    scale: 100  // 调整公式字体大小，默认 100（百分比）
    },
    CommonHTML: {
      scale: 100  // 如果使用 CommonHTML 输出，也需要设置
    }
  });
</script>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jason‘s Blog</title>
    <link rel="stylesheet" href="/assets/css/custom.css">
    <link rel="icon" href="favicon.ico">
  </head>
  <body class="default-layout">
<!--     Header -->
    <header class="header">
      <div class="container">
        <span class="logo">🌟 Jason's Blog</span>
        <nav class="nav">
          <ul>
            
              <li><a href="/">Posts</a></li>
            
              <li><a href="/archive/">Archive</a></li>
            
              <li><a href="/chat/">Q&A</a></li>
            
              <li><a href="/tags/">Tags</a></li>
            
              <li><a href="/about/">About</a></li>
            
              <li><a href="/contact/">Contact</a></li>
            
          </ul>
        </nav>
      </div>
    </header>
    <!--   Main Content -->
    <main class="container">
      <div class="home">
  <!-- 欢迎语 -->
  <div class="welcome-section">
    <h1>Welcome to Jason's Blog👋</h1>
    <p> Hi, this is Jason. Sharing papers, projects, and ideas here since 2024. Enjoy!</p>
    <div class="social-icons">
      <a href="https://github.com/JasonDepblu" target="_blank">GitHub</a>
<!--      <a href="https://x.com/depblugz" target="_blank">X.com</a>-->
      <a href="#" id="wechat-link">WeChat</a>
    </div>
  </div>

    <!-- WeChat QR Code Modal -->
  <div id="wechat-modal" style="display: none; position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.7); z-index: 1000;">
    <div style="position: relative; width: 300px; margin: 100px auto; background-color: white; padding: 20px; border-radius: 5px; text-align: center;">
      <span id="close-modal" style="position: absolute; top: 10px; right: 15px; font-size: 20px; cursor: pointer;">&times;</span>
      <h3>Scan to connect on WeChat</h3>
      <!-- Replace with your actual WeChat QR code image path -->
      <img src="/assets/images/JasonWechat.png" alt="WeChat QR Code" style="width: 200px; height: 200px;">
    </div>
  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const wechatLink = document.getElementById('wechat-link');
      const wechatModal = document.getElementById('wechat-modal');
      const closeModal = document.getElementById('close-modal');

      wechatLink.addEventListener('click', function(e) {
        e.preventDefault();
        wechatModal.style.display = 'block';
      });

      closeModal.addEventListener('click', function() {
        wechatModal.style.display = 'none';
      });

      // Close modal when clicking outside the QR code box
      wechatModal.addEventListener('click', function(e) {
        if (e.target === wechatModal) {
          wechatModal.style.display = 'none';
        }
      });
    });
  </script>

  <div class="post-grid">
    
      <post-card class="post-card">
        <a href="/llm/papers/2025/02/19/Reasoning-model-reproduced.html">
          <h3>Reasoning model的复现之路</h3>
        </a>
        <p class="excerpt">“文章开篇介绍了人工智能领域的最新进展，尤其是大语言模型（LLMs）在复杂任务上的能力，如编程和高级数学问题求解。OpenAI 的 o1 模型展示了卓越的推理能力，包括任务分解、反思、纠错和探索新解决方案。本文提出了一个基于强化学习（Reinforcement Learning, RL）的路线图，目标是通过策略初始化、奖励设计、搜索和学习四个关键组成部分来复现o1的能力。”</p>
        <div class="post-meta">
          <span class="post-date">Date: February 19, 2025</span> |
          <span class="reading-time">Estimated Reading Time: 60 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
      </post-card>
    
      <post-card class="post-card">
        <a href="/llm/papers/2025/01/06/Byte-Latent-Transformer-Patches.html">
          <h3>Byte Latent Transformer: Patches Scale Better Than Tokens — 开创无tokenizer语言建模的新维度</h3>
        </a>
        <p class="excerpt">“大型语言模型（LLMs）的发展历程传统上由基于tokenizer的架构主导。然而，字节潜在变换器（BLT）的引入标志着一种范式的转变。由Meta的研究人员及其合作伙伴提出，BLT通过消除标记化并处理原始字节数据，创新性地提高了效率和鲁棒性，同时在性能上与tokenizer based model相抗衡。本文将探讨其设计、功能及对未来语言建模的影响。”</p>
        <div class="post-meta">
          <span class="post-date">Date: January 06, 2025</span> |
          <span class="reading-time">Estimated Reading Time: 30 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
      </post-card>
    
      <post-card class="post-card">
        <a href="/llm/papers/2024/12/25/reason-cot-post.html">
          <h3>Coconut：在连续潜在空间中的大语言模型推理范式研究</h3>
        </a>
        <p class="excerpt">本文基于新兴范式 Coconut（连续思维链）的引入，深入探讨了大语言模型(LLMs)中思维链(Chain-of-Thought, CoT)推理和潜在推理的分类，这些分类在思维图谱框架中得到了概述。本文旨在总结大语言模型推理领域的发展轨迹和核心挑战。</p>
        <div class="post-meta">
          <span class="post-date">Date: December 25, 2024</span> |
          <span class="reading-time">Estimated Reading Time: 15 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
      </post-card>
    
      <post-card class="post-card">
        <a href="/llm/papers/2024/12/12/my-first-post.html">
          <h3>Reasoning with REinforced Fine-Tuning</h3>
        </a>
        <p class="excerpt">《REFT: Reasoning with REinforced Fine-Tuning》提出了一种基于强化学习与微调相结合的创新方法，用以提升大语言模型（LLM）的推理能力。该方法旨在通过对推理路径的细化设计和多层次优化，在复杂推理任务中实现更高的准确性、解释性和效率。</p>
        <div class="post-meta">
          <span class="post-date">Date: December 12, 2024</span> |
          <span class="reading-time">Estimated Reading Time: 15 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
      </post-card>
    
      <post-card class="post-card">
        <a href="/llm/papers/2024/12/03/history1-post.html">
          <h3>Super Weights in Large Language Model</h3>
        </a>
        <p class="excerpt">这篇文章主要讨论了在大型语言模型中引入“超级权重”（Super Weights）这一概念，以增强模型的表现和适应性。 作者介绍了如何通过特殊加权策略，使模型在保持参数数量不变的情况下实现更高的推理能力和泛化性能。 文中同时阐述了相关的实验结果和案例分析，展示了“超级权重”在实际应用中的潜在优势。</p>
        <div class="post-meta">
          <span class="post-date">Date: December 03, 2024</span> |
          <span class="reading-time">Estimated Reading Time: 15 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
      </post-card>
    
  </div>
</div>

<link rel="stylesheet" href="/assets/main.css">
<link rel="stylesheet" href="/assets/css/custom.css">

    </main>
    <!-- Footer -->
    <footer class="footer">
      <p>&copy; 2025 Jason‘s Blog</p>
    </footer>
  </body>
</html>

<script src="/assets/js/main.js"></script>

<link rel="stylesheet" href="/assets/main.css">
<link rel="stylesheet" href="/assets/css/custom.css">