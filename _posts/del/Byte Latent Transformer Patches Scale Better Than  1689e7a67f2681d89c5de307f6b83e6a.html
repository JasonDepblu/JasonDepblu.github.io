<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1689e7a6-7f26-81d8-9c5d-e307f6b83e6a" class="page sans"><header><h1 class="page-title">Byte Latent Transformer: Patches Scale Better Than Tokens</h1><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-person"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesPerson"><path d="M10.9536 7.90088C12.217 7.90088 13.2559 6.79468 13.2559 5.38525C13.2559 4.01514 12.2114 2.92017 10.9536 2.92017C9.70142 2.92017 8.65137 4.02637 8.65698 5.39087C8.6626 6.79468 9.69019 7.90088 10.9536 7.90088ZM4.4231 8.03003C5.52368 8.03003 6.42212 7.05859 6.42212 5.83447C6.42212 4.63843 5.51245 3.68945 4.4231 3.68945C3.33374 3.68945 2.41846 4.64966 2.41846 5.84009C2.42407 7.05859 3.32251 8.03003 4.4231 8.03003ZM1.37964 13.168H5.49561C4.87231 12.292 5.43384 10.6074 6.78711 9.51807C6.18628 9.14746 5.37769 8.87231 4.4231 8.87231C1.95239 8.87231 0.262207 10.6917 0.262207 12.1628C0.262207 12.7974 0.548584 13.168 1.37964 13.168ZM7.50024 13.168H14.407C15.4009 13.168 15.7322 12.8423 15.7322 12.2864C15.7322 10.8489 13.8679 8.88354 10.9536 8.88354C8.04492 8.88354 6.17505 10.8489 6.17505 12.2864C6.17505 12.8423 6.50635 13.168 7.50024 13.168Z"></path></svg></span>Owner</th><td><span class="user"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/>Jason deng</span></td></tr><tr class="property-row property-row-url"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesUrl"><path d="M7.69922 10.8945L8.73828 9.84863C7.91797 9.77344 7.34375 9.51367 6.91992 9.08984C5.76465 7.93457 5.76465 6.29395 6.91309 5.14551L9.18262 2.87598C10.3379 1.7207 11.9717 1.7207 13.127 2.87598C14.2891 4.04492 14.2822 5.67188 13.1338 6.82031L11.958 7.99609C12.1768 8.49512 12.2451 9.10352 12.1289 9.62988L14.0908 7.6748C15.7725 6 15.7793 3.62109 14.084 1.92578C12.3887 0.223633 10.0098 0.237305 8.33496 1.91211L5.95605 4.29785C4.28125 5.97266 4.26758 8.35156 5.96289 10.0469C6.36621 10.4434 6.90625 10.7441 7.69922 10.8945ZM8.30078 5.13184L7.26855 6.17773C8.08203 6.25293 8.66309 6.51953 9.08008 6.93652C10.2422 8.09863 10.2422 9.73242 9.08691 10.8809L6.81738 13.1504C5.66211 14.3057 4.03516 14.3057 2.87305 13.1504C1.71094 11.9883 1.71777 10.3545 2.87305 9.20605L4.04199 8.03027C3.83008 7.53125 3.75488 6.92969 3.87109 6.39648L1.91602 8.35156C0.234375 10.0264 0.227539 12.4121 1.92285 14.1074C3.61816 15.8027 5.99707 15.7891 7.67188 14.1143L10.0439 11.7354C11.7256 10.0537 11.7324 7.6748 10.0371 5.98633C9.64062 5.58301 9.10059 5.28223 8.30078 5.13184Z"></path></svg></span>Paper URL</th><td><a href="https://arxiv.org/html/2412.09871v1" class="url-value">https://arxiv.org/html/2412.09871v1</a></td></tr><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>AI summary</th><td>The Byte Latent Transformer (BLT) introduces a byte-level architecture that matches the performance of tokenization-based models while improving efficiency and robustness. By dynamically grouping bytes into patches based on data complexity, BLT enhances training and inference efficiency, achieving significant reductions in computational costs and improved handling of noisy inputs.</td></tr><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Author</th><td>Artidoro Pagnoni   Ram Pasunuru   Pedro Rodriguez    Benjamin Muller   Margaret Li   Chunting Zhou   Lili Yu   Jason Weston   Luke Zettlemoyer   Gargi Ghosh   Mike Lewis   Ari Holtzman   Srinivasan Iyer</td></tr><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Code</th><td><a href="https://github.com/facebookresearch/blt">https://github.com/facebookresearch/blt</a></td></tr><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>organization</th><td>FAIR at Meta, Paul G. Allen School of Computer Science &amp; Engineering, University of Washington, University of Chicago<br/>\contribution[‡]Joint second author, \contribution[†]Joint last author, \contribution[⋄]Work done at Meta<br/></td></tr></tbody></table></header><div class="page-body"><h2 id="1689e7a6-7f26-816c-8bfb-d146dcb852bd" class="">Abstract</h2><p id="1689e7a6-7f26-81ef-ae48-ee2695b0638f" class="">We introduce the <mark class="highlight-red"><strong>Byte Latent Transformer (BLT)</strong></mark>, a new byte-level LLM architecture that, for the first time, matches tokenization-based LLM performance at scale with significant improvements in inference efficiency and robustness. BLT encodes bytes into dynamically sized patches, which serve as the primary units of computation. Patches are segmented based on the entropy of the next byte, allocating more compute and model capacity where increased data complexity demands it. We present the first flop controlled scaling study of byte-level models up to 8B parameters and 4T training bytes. Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.</p><p id="1689e7a6-7f26-8158-8b54-f3bf0481ef20" class=""><strong>correspondence:  </strong>artidoro at <a href="http://cs.washington.edu/">cs.washington.edu</a>, sviyer at metadata</p><figure id="1689e7a6-7f26-8177-9630-c1f584c64d43" class="image"><a href="https://arxiv.org/html/2412.09871v1/x1.png"><img style="width:480px" src="https://arxiv.org/html/2412.09871v1/x1.png"/></a></figure><figure id="1689e7a6-7f26-81fb-840e-fb50a2e1eee7" class="image"><a href="https://arxiv.org/html/2412.09871v1/x2.png"><img style="width:480px" src="https://arxiv.org/html/2412.09871v1/x2.png"/></a><figcaption>Figure 1 Scaling trends for fixed inference flop models (fully) trained with varying training budgets. In token-based models, a fixed inference budget determines the model size. In contrast, the BLT architecture provides a new scaling axis allowing simultaneous increases in model and patch size while keeping the same training and inference budget. BLT patch-size (ps) 6 and 8 models quickly overtake scaling trends of bpe Llama 2 and 3. Moving to the larger inference budget makes the larger patch size 8 model more desirable sooner. Both BPE compute-optimal point and crossover point are indicated with vertical lines.</figcaption></figure><p id="1699e7a6-7f26-80ff-951e-c42e09d6de33" class="">
</p><p id="1689e7a6-7f26-810c-a14b-d6ee4642fda0" class="">We introduce the Byte Latent Transformer (BLT), a tokenizer-free architecture that learns from raw byte data and, for the first time, matches the performance of tokenization-based models at scale, with significant improvements in efficiency and robustness (§<a href="https://arxiv.org/html/2412.09871v1#S6">6</a>). Existing large language models (llms) are trained almost entirely end-to-end, except for tokenization—a heuristic pre-processing step that groups bytes into a static set of tokens.<mark class="highlight-red_background"> Such tokens bias how a string is compressed,</mark> leading to <mark class="highlight-red"><strong>shortcomings</strong></mark> such as <mark class="highlight-orange_background">domain/modality sensitivity (Dagan et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib11">2024</a></mark><mark class="highlight-orange_background">)</mark>, <mark class="highlight-orange_background">sensitivity to input noise (§</mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#S6">6</a></mark><mark class="highlight-orange_background">)</mark>, <mark class="highlight-orange_background">a lack of orthographic knowledge (Edman et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib14">2024</a></mark><mark class="highlight-orange_background">)</mark>, and <mark class="highlight-orange_background">multilingual inequity (Liang et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib29">2023</a></mark><mark class="highlight-orange_background">; Petrov et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib35">2024</a></mark><mark class="highlight-orange_background">; Limisiewicz et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib30">2024</a></mark>).</p><p id="1689e7a6-7f26-81a1-b4fd-c110c51b14b9" class="">Tokenization has previously been essential because directly training llms on bytes is prohibitively costly at scale due to long sequence lengths (Xue et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib47">2022</a>). Prior works mitigate this by employing more efficient self-attention (El Boukkouri et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib15">2020</a>; <mark class="highlight-orange_background">Clark et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib9">2022</a></mark>) or attention-free architectures (Wang et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib45">2024</a>) (§<a href="https://arxiv.org/html/2412.09871v1#S8">8</a>). However, this primarily helps train small models. At scale, the computational cost of a Transformer is dominated by large feed-forward network layers that run on every byte, not the cost of the attention mechanism.</p><p id="1689e7a6-7f26-815e-adef-df77ff34bea1" class="">To efficiently allocate compute, we propose a dynamic, learnable method for grouping bytes into patches (§<a href="https://arxiv.org/html/2412.09871v1#S2">2</a>) and <mark class="highlight-red"><span style="border-bottom:0.05em solid">a new model architecture that mixes byte and patch information</span></mark>. Unlike tokenization, BLT has no fixed vocabulary for patches. Arbitrary groups of bytes are mapped to latent patch representations via light-weight learned encoder and decoder modules. We show that this results in more efficient allocation of compute than tokenization-based models.</p><p id="1689e7a6-7f26-814e-8a7b-ef7e988bc60e" class="">Tokenization-based llms allocate the same amount of compute to every token. This trades efficiency for performance, since tokens are induced with compression heuristics that are not always correlated with the complexity of predictions. Central to our architecture is the idea that models should dynamically allocate compute where it is needed. For example, a large transformer is not needed to predict the ending of most words, since these are comparably easy, low-entropy decisions compared to choosing the first word of a new sentence. This is reflected in BLT’s architecture (§<a href="https://arxiv.org/html/2412.09871v1#S3">3</a>) where there are three transformer blocks: two small byte-level local models and a large global latent transformer (<a href="https://arxiv.org/html/2412.09871v1#S1.F2">Figure 2</a>). To determine how to group bytes into patches and therefore how to dynamically allocate compute, BLT segments data based on the entropy of the next-byte prediction creating contextualized groupings of bytes with relatively uniform information density.</p><figure id="1689e7a6-7f26-81b0-aea9-d30f0091edea" class="image"><a href="https://arxiv.org/html/2412.09871v1/x3.png"><img style="width:624px" src="https://arxiv.org/html/2412.09871v1/x3.png"/></a><figcaption>Figure 2 BLT comprises three modules, a lightweight Local Encoder that encodes input bytes into patch representations, a computationally expensive Latent Transformer over patch representations, and a lightweight Local Decoder to decode the next patch of bytes. BLT incorporates byte n-gram embeddings and a cross-attention mechanism to maximize information flow between the Latent Transformer and the byte-level modules (Figure 5). Unlike fixed-vocabulary tokenization, BLT dynamically groups bytes into patches preserving access to the byte-level information.</figcaption></figure><p id="1689e7a6-7f26-81d0-9064-edd5c74ea127" class="">We present the first flop-controlled scaling study of byte-level models up to 8B parameters and 4T training bytes, showing that we can train a model end-to-end at scale from bytes without fixed-vocabulary tokenization. Overall, BLT matches training flop-controlled performance<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> of Llama 3 while using up to 50% fewer flops at inference (§<a href="https://arxiv.org/html/2412.09871v1#S5">5</a>). We also show that directly working with raw bytes provides significant improvements in modeling the long-tail of the data. BLT models are more robust than tokenizer-based models to noisy inputs and display enhanced character level understanding abilities demonstrated on orthographic knowledge, phonology, and low-resource machine translation tasks (§<a href="https://arxiv.org/html/2412.09871v1#S6">6</a>). Finally, with BLT models, we can simultaneously increase model size and patch size while maintaining the same inference flop budget. Longer patch sizes, on average, save compute which can be reallocated to grow the size of the global latent transformer, because it is run less often. We conduct inference-flop controlled scaling experiments (<a href="https://arxiv.org/html/2412.09871v1#S1.F1">Figure 1</a>), and observe significantly better scaling trends than with tokenization-based architectures.</p><p id="1689e7a6-7f26-81ba-8344-f126966770a2" class="">In summary, this paper makes <mark class="highlight-red"><mark class="highlight-red_background"><strong>the following contributions: </strong></mark></mark></p><p id="16d9e7a6-7f26-8057-b173-ca48a96379ce" class="">1) We introduce BLT, a byte latent llm architecture that dynamically allocates compute to improve flop efficiency, </p><p id="16d9e7a6-7f26-80c8-a0dd-c3de89d8a7dc" class="">2) We show that we achieve training flop-controlled parity with Llama 3 up to 8B scale while having the option to trade minor losses in evaluation metrics for flop efficiency gains of up to 50%, </p><p id="16d9e7a6-7f26-80dd-b1be-e30d88827383" class="">3) BLT models unlock a new dimension for scaling llms, where model size can now be scaled while maintaining a fixed-inference budget, </p><p id="16d9e7a6-7f26-8052-b314-c0668f3bc392" class="">4) We demonstrate the improved robustness of BLT models to input noise and their awareness of sub-word aspects of input data that token-based llms miss. </p><p id="16d9e7a6-7f26-8061-a3be-d83cc27cdf80" class="">We release the training and inference code for BLT at <a href="https://github.com/facebookresearch/blt">https://github.com/facebookresearch/blt</a>.</p><h2 id="1689e7a6-7f26-815b-9629-c7b2823b0ce8" class="">2 Patching: From Individual Bytes to Groups of Bytes</h2><figure id="1689e7a6-7f26-81a0-b6d6-ceb37820dccb" class="image"><a href="https://arxiv.org/html/2412.09871v1/extracted/6066458/assets/patching_types.png"><img src="https://arxiv.org/html/2412.09871v1/extracted/6066458/assets/patching_types.png"/></a><figcaption>Figure 3: Patching schemes group bytes in different ways, each leading to a different number of resulting patches. Since each patch is processed using a large transformer step, the number of patches directly determines the bulk of the compute expended in terms of flops. These schemes group bytes into patches by (a) striding every four bytes (§2.1) as in MegaByte (Yu et al., 2023), (b) tokenizing with Byte-Pair Encoding (bpe), in this case the Llama-3 (Dubey et al., 2024) tokenizer, (c &amp; d) entropy-based patching as in this work (§2.3), (e) patching on space-bytes (Slagle, 2024), (f) and patching on entropy using a small CNN byte-level model with 2-byte context.</figcaption></figure><p id="1689e7a6-7f26-81b0-be11-d8911880e3f0" class="">Segmenting bytes into <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">patches</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">es</span></span></span></span></span><span>﻿</span></span> allows BLT to dynamically allocate compute based on context. Figure <a href="https://arxiv.org/html/2412.09871v1#S2.F3">3</a> shows several different methods for segmenting bytes into patches. Formally, a patching function <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">f_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> segments a sequence of bytes <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒙</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∣</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">𝒙=\{x_i,|i=1,…n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> of length <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> into a sequence of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m&lt;n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> patches <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒑</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><mi>j</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">𝒑=\{p_j|j=1,…,m\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord boldsymbol" style="margin-right:0.07861em;">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> by mapping each <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> to the set <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span> indicates the start of a new patch. For both token-based and patch-based models, the computational cost of processing data is primarily determined by the number of steps executed by the main Transformer. In BLT, this is the number of patches needed to encode the data with a given patching function. Consequently, the average size of a patch, or simply patch size, is the main factor for determining the cost of processing data during both training and inference with a given patching function (§<a href="https://arxiv.org/html/2412.09871v1#S4.SS5">4.5</a>). Next, we introduce three patching functions: <mark class="highlight-red_background"><span style="border-bottom:0.05em solid">patching with a fixed number of bytes per patch (§</span></mark><mark class="highlight-red_background"><a href="https://arxiv.org/html/2412.09871v1#S2.SS1"><span style="border-bottom:0.05em solid">2.1</span></a></mark><mark class="highlight-red_background"><span style="border-bottom:0.05em solid">)</span></mark>, <mark class="highlight-red_background"><span style="border-bottom:0.05em solid">whitespace patching (§</span></mark><mark class="highlight-red_background"><a href="https://arxiv.org/html/2412.09871v1#S2.SS2"><span style="border-bottom:0.05em solid">2.2</span></a></mark><mark class="highlight-red_background"><span style="border-bottom:0.05em solid">)</span></mark>, and <mark class="highlight-red_background"><span style="border-bottom:0.05em solid">dynamically patching with entropies from a small byte lm (§</span></mark><mark class="highlight-red_background"><a href="https://arxiv.org/html/2412.09871v1#S2.SS3"><span style="border-bottom:0.05em solid">2.3</span></a></mark><mark class="highlight-red_background"><span style="border-bottom:0.05em solid">)</span></mark>. Finally, we discuss incremental patching and how tokenization is different from patching (§<a href="https://arxiv.org/html/2412.09871v1#S2.SS4">2.4</a>).</p><h3 id="1689e7a6-7f26-815c-91f3-ca813b77a5a0" class="">2.1 Strided Patching Every K Bytes</h3><p id="1689e7a6-7f26-811c-ae32-c13603d7707f" class="">Perhaps the most straightforward way to group bytes is into patches of fixed size k as done in MegaByte (Yu et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib48">2023</a>). The fixed stride is easy to implement for training and inference, provides a straightforward mechanism for changing the average patch size, and therefore makes it easy to control the flop cost. However, this patching function comes <mark class="highlight-red"><mark class="highlight-red_background"><strong>with significant downsides.</strong></mark></mark> </p><p id="16d9e7a6-7f26-8033-81b6-e4f3a4ad4451" class="">First, compute is not dynamically allocated to where it is needed most: one could be either wasting a transformer step <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span><span>﻿</span></span> if only predicting whitespace in code, or not allocating sufficient compute for bytes dense with information such as math. </p><p id="16d9e7a6-7f26-8018-9654-fc0c480893d2" class="">Second, this leads to inconsistent and non-contextual patching of similar byte sequences, such as the same word being split differently.</p><h3 id="1689e7a6-7f26-817b-9e68-c5a953d133be" class="">2.2 Space Patching</h3><p id="1689e7a6-7f26-81f5-8d3d-f5aa1729e5c5" class="">Slagle (<a href="https://arxiv.org/html/2412.09871v1#bib.bib39">2024</a>) proposes a simple yet effective improvement over strided patching that creates new patches after any space-like bytes<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> which are natural boundaries for linguistic units in many languages. In Space patching, a latent transformer step (i.e., more flops) is allocated to model every word. This ensures words are patched in the same way across sequences and that flops are allocated for hard predictions which often follow spaces. For example, predicting the first byte of the answer to the question “Who composed the Magic Flute? ” is much harder than predicting the remaining bytes after “M” since the first character significantly reduces the number of likely choices, making the completion “Mozart” comparatively easy to predict. <mark class="highlight-red"><mark class="highlight-red_background"><strong>However, space patching cannot gracefully handle all languages and domains, and most importantly cannot vary the patch size.</strong></mark></mark> Next, we introduce a new patching method that uses the insight that the first bytes in words are typically most difficult to predict, but that provides a natural mechanism for controlling patch size.</p><h3 id="1689e7a6-7f26-81d0-b657-eb8be02e9f52" class="">2.3 Entropy Patching: Using Next-Byte Entropies from a Small Byte LM</h3><p id="1689e7a6-7f26-81a3-a1ba-d061a53d88e6" class="">Rather than relying on a rule-based heuristic such as whitespace, we instead take a data-driven approach to identify high uncertainty next-byte predictions. We introduce <mark class="highlight-red"><strong>entropy patching</strong></mark>, which uses entropy estimates to derive patch boundaries.</p><p id="1689e7a6-7f26-810c-b74e-f036611f68bd" class="">We train a small byte-level auto-regressive language model on the training data for BLT and compute next byte entropies under the LM distribution <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">p_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> over the byte vocabulary <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒱</mi></mrow><annotation encoding="application/x-tex">𝒱</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.27523em;">V</span></span></span></span></span><span>﻿</span></span>:</p><p id="16d9e7a6-7f26-8082-8ffa-e0538253e5af" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mi>𝒱</mi></mrow></msub><msub><mi>p</mi><mi>e</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mi>v</mi><mi mathvariant="normal">∣</mi><msub><mi>𝒙</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mtext>⁢</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mtext>⁡ </mtext><msub><mi>p</mi><mi>e</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mi>v</mi><mi mathvariant="normal">∣</mi><msub><mi>𝒙</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H⁢(x_i)=∑_{v∈𝒱}p_e⁢(x_i=v|𝒙_{&lt;i})⁢log⁡\ p_e⁢(x_i=v|𝒙_{&lt;i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0771em;vertical-align:-0.3271em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1903em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mrel mtight">∈</span><span class="mord mathscr mtight" style="margin-right:0.27523em;">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">∣</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1258em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">⁢</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord">⁡</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">∣</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1258em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>           ……(1)</p><p id="16d9e7a6-7f26-8045-989f-e27f1430ff4f" class="">
</p><figure id="1689e7a6-7f26-81d4-8d7c-de2f3e840a14" class="image"><a href="https://arxiv.org/html/2412.09871v1/x4.png"><img src="https://arxiv.org/html/2412.09871v1/x4.png"/></a><figcaption>Figure 4 This figure plots the entropy H(x_i) of each byte in “Daenerys Targeryen is in Game of Thrones, a fantasy epic by George R.R. Martin.” with spaces shown as underscores. Patches end when H(x_i) exceeds the global threshold θ_g, shown as a red horizontal line. The start of new patches are shown with vertical gray lines. For example, the entropies of “G” and “e” in “George R.R. Martin” exceed θ_g , so “G” is the start of a single byte patch and “e” of a larger patch extending to the end of the named entity as the entropy H(x_i) stays low, resulting in no additional patches.</figcaption></figure><p id="1689e7a6-7f26-811d-92de-e601f667ecd4" class="">We experiment with two methods to identify patch boundaries given entropies <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H⁢(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>. <mark class="highlight-red"><mark class="highlight-red_background">The first, finds points above a global entropy threshold</mark></mark>, as illustrated in <a href="https://arxiv.org/html/2412.09871v1#S2.F4">Figure 4</a>. </p><p id="16d9e7a6-7f26-809b-832b-cc34278def32" class=""><mark class="highlight-red"><mark class="highlight-red_background">The second, identifies points that are high relative to the previous entropy.</mark></mark> The second approach can also be interpreted as identifying points that break approximate monotonically decreasing entropy within the patch.</p><p id="16d9e7a6-7f26-80a5-bc96-c46a91b3e0c4" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mtext> Global Constraint </mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>H</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>&gt;</mo><msub><mi>θ</mi><mi>g</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mtext> Approx. Monotonic Constraint </mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>H</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi>H</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow><mo>&gt;</mo><msub><mi>θ</mi><mi>r</mi></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\text { Global Constraint } &amp; H\left(x_t\right)&gt;\theta_g \\
\text { Approx. Monotonic Constraint } &amp; H\left(x_t\right)-H\left(x_{t-1}\right)&gt;\theta_r
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord"> Global Constraint </span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord"> Approx. Monotonic Constraint </span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="1689e7a6-7f26-81a1-8921-e71a13587db0" class="">Patch boundaries are identified during a lightweight preprocessing step executed during dataloading. This is different from Nawrot et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib34">2023</a>) where classifier is trained to predict entropy-based patch boundaries. In our experiments (§<a href="https://arxiv.org/html/2412.09871v1#S4">4</a>), we compare these two methods for distinguishing between low and high entropy bytes.</p><h3 id="1689e7a6-7f26-81ef-a96c-e43ea5b90a6f" class="">2.4 The Byte-Pair Encoding (BPE) Tokenizer and Incremental Patching</h3><p id="1689e7a6-7f26-81bb-818d-ca0b6a52fddb" class="">Many modern llms, including our baseline Llama 3, use a subword tokenizer like bpe (Gage, <a href="https://arxiv.org/html/2412.09871v1#bib.bib16">1994</a>; Sennrich et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib37">2016</a>). We use “tokens” to refer to byte-groups drawn from a finite vocabulary determined prior to training as opposed to “patches” which refer to dynamically grouped sequences without a fixed vocabulary. <mark class="highlight-red"><mark class="highlight-red_background"><strong>A critical difference between patches and tokens is that with tokens, the model has no direct access to the underlying byte features.</strong></mark></mark></p><p id="1689e7a6-7f26-81bd-84ae-daf4ffe88129" class=""><mark class="highlight-red"><mark class="highlight-red_background"><span style="border-bottom:0.05em solid">A crucial improvement of BLT over tokenization-based models is that redefines the trade off between the vocabulary size and compute. In standard llms, increasing the size of the vocabulary means larger tokens on average and therefore fewer steps for the model but also larger output dimension for the final projection layer of the model. </span></mark></mark>This trade off effectively leaves little room for tokenization based approaches to achieve significant variations in token size and inference cost. For example, Llama 3 increases the average token size from 3.7 to 4.4 bytes at the cost of increasing the size of its embedding table 4x compared to Llama 2.</p><p id="1689e7a6-7f26-810a-9c23-f4a4aa75338c" class="">When generating, BLT needs to decide whether the current step in the byte sequence is at a patch boundary or not as this determines whether more compute is invoked via the Latent Transformer. This decision needs to occur independently of the rest of the sequence which has yet to be generated. Thus patching cannot assume access to future bytes in order to choose how to segment the byte sequence. Formally, a patching scheme <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">f_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> satisfies the property of incremental patching if it satisfies:</p><p id="16d9e7a6-7f26-80fc-89ac-c041f871d5ef" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>𝒙</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>𝒙</mi><msub><mo stretchy="false">)</mo><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">f_p⁢(𝒙_{&lt;i})=f_p⁢(𝒙)_{&lt;i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1258em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> </p><p id="1689e7a6-7f26-8181-bec8-d427564dea36" class="">BPE is not an incremental patching scheme as the same prefix can be tokenized differently depending on the continuation sequence, and therefore does not satisfy the property above<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>.</p><h2 id="1689e7a6-7f26-8172-84f0-c05c7ffca75b" class="">3 BLT Architecture</h2><p id="1689e7a6-7f26-81fb-b224-fe6edc2cd487" class="">BLT is composed of a large global autoregressive language model that operates on patch representations, along with two smaller local models that encode sequences of bytes into patches and decode patch representations back into bytes (<a href="https://arxiv.org/html/2412.09871v1#S1.F2">Figure 2</a>).</p><h3 id="1689e7a6-7f26-8171-b9eb-dec1d5e2c85e" class="">3.1 Latent Global Transformer Model</h3><p id="1689e7a6-7f26-8149-9ad9-d07701dd0e43" class=""><em>The Latent Global Transformer</em> is an autoregressive transformer model <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒢</mi></mrow><annotation encoding="application/x-tex">𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.17322em;">G</span></span></span></span></span><span>﻿</span></span> with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">l_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> layers, which maps a sequence of latent input patch representations, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> into a sequence of output patch representations, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">o_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. Throughout the paper, we use the subscript j to denote patches and i to denote bytes. The global model uses a block-causal attention mask (Dubey et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>), which restricts attention to be up to and including the current patch within the current document. This model consumes the bulk of the flops during pre-training as well as inference, and thus, choosing when to invoke it allows us to control and vary the amount of compute expended for different portions of the input and output as a function of input/output complexity.</p><h3 id="1689e7a6-7f26-818c-8460-ff2e4f8fd4b5" class="">3.2 Local Encoder</h3><p id="1689e7a6-7f26-8108-aeb4-f7c279c72408" class=""><em>The Local Encoder Model</em>, denoted by ℰ, is a lightweight transformer-based model with lℰ&lt;&lt;l𝒢 layers, whose main role is to efficiently map a sequence of input bytes <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, into expressive patch representations, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. <mark class="highlight-red_background">A primary departure from the transformer architecture is the addition of </mark><mark class="highlight-red"><mark class="highlight-red_background"><strong>a cross-attention layer after each transformer layer</strong></mark></mark><mark class="highlight-red_background">, whose function is to pool byte representations into patch representations</mark> (<a href="https://arxiv.org/html/2412.09871v1#S3.F5">Figure 5</a>). First, the input sequence of bytes, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, are embedded using a <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="normal">R</mi><mrow><mn>256</mn><mo>∗</mo><msub><mi>h</mi><mi mathvariant="script">E</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">ℝ^{256*h_ℰ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">256</span><span class="mbin mtight">∗</span><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> matrix, denoted as <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. These embeddings are then optionally augmented with additional information in the form of<mark class="highlight-red"><mark class="highlight-red_background"> hash-embeddings</mark></mark> (§<a href="https://arxiv.org/html/2412.09871v1#S3.SS2.SSS1">3.2.1</a>). A series of alternating transformer and cross-attention layers (§<a href="https://arxiv.org/html/2412.09871v1#S3.SS2.SSS2">3.2.2</a>) then transform these representations into patch representations, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> that are processed by the global transformer, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒢</mi></mrow><annotation encoding="application/x-tex">𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.17322em;">G</span></span></span></span></span><span>﻿</span></span>. The transformer layers use a local block causal attention mask; each byte attends to a fixed window of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">w_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> preceding bytes that in general can cross the dynamic patch boundaries but can not cross document boundaries. The following subsections describe details about the embeddings and the cross-attention block.</p><h3 id="1689e7a6-7f26-814f-9cdb-e20e2f01762c" class="">3.2.1 Encoder Hash n-gram Embeddings</h3><p id="1689e7a6-7f26-8187-a4e1-ffc744e567b2" class="">A key component in creating robust, expressive representations at each step <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> is to incorporate information about the preceding bytes. In BLT, we achieve this by modeling both the byte <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> individually and as part of a byte n-gram. For each step <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span>, we first construct byte-grams for each byte position <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> from three to eight.<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="16f9e7a6-7f26-80cd-92ee-e415731a008b" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>b</mi><mrow><mi>i</mi><mo>−</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">g_{i,n}=\{b_{i−n+1},…,b_i\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span>             ……(2)</p><p id="1689e7a6-7f26-813a-931d-db3a0eca5685" class="">We then introduce hash n-gram embeddings, that map all byte n-grams via a hash function to an index in an embedding table <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>E</mi><mi>n</mi><mrow><mi>h</mi><mtext>⁢</mtext><mi>a</mi><mtext>⁢</mtext><mi>s</mi><mtext>⁢</mtext><mi>h</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">E_n^{h⁢a⁢s⁢h}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0961em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.453em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">s</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> with a fixed size, for each size <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>5</mn><mo separator="true">,</mo><mn>6</mn><mo separator="true">,</mo><mn>7</mn><mo separator="true">,</mo><mn>8</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">n∈\{3,4,5,6,7,8\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">6</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">7</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">8</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> (Bai et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib3">2010</a>). The resulting embedding is then added to the embedding of the byte before being normalized and passed as input to the local encoder model. We calculate the augmented embedding</p><p id="16f9e7a6-7f26-800d-b7e4-f656a8dc8647" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>3</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mn>8</mn></mrow></msub><msubsup><mi>E</mi><mi>n</mi><mrow><mi>h</mi><mtext>⁢</mtext><mi>a</mi><mtext>⁢</mtext><mi>s</mi><mtext>⁢</mtext><mi>h</mi></mrow></msubsup><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>H</mi><mi>a</mi><mi>s</mi><mi>h</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>g</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i=x_i+∑_{n=3,…,8}E_n^{h⁢a⁢s⁢h}⁢(Hash⁢(g_i,n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2849em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">3</span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mtight">8</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.453em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">s</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">))</span></span></span></span></span><span>﻿</span></span>           ……(3)</p><p id="16f9e7a6-7f26-8032-864c-fc68ca487ef3" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>e</mi><mo separator="true">,</mo><mi>H</mi><mi>a</mi><mi>s</mi><mi>h</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mi>o</mi><mi>l</mi><mi>l</mi><mi>P</mi><mi>o</mi><mi>l</mi><mi>y</mi><mi>H</mi><mi>a</mi><mi>s</mi><mi>h</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>g</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">%</mi><mtext>⁢</mtext><mi mathvariant="normal">∣</mi><msubsup><mi>E</mi><mi>n</mi><mrow><mi>h</mi><mtext>⁢</mtext><mi>a</mi><mtext>⁢</mtext><mi>s</mi><mtext>⁢</mtext><mi>h</mi></mrow></msubsup><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">where, Hash⁢(g_{i,n})=RollPolyHash⁢(g_{i,n})\%⁢|E_n^{h⁢a⁢s⁢h}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">h</span><span class="mord mathnormal">ere</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1352em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.13889em;">llP</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.08125em;">yH</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">%⁢∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.453em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">s</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span><span>﻿</span></span>               ……(4)</p><p id="1689e7a6-7f26-810f-a089-ee50fa8c51d5" class="">We normalize <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> by the number of n-grams sizes plus one and use RollPolyHash as defined in Appendix <a href="https://arxiv.org/html/2412.09871v1#S13">13</a>. In Section <a href="https://arxiv.org/html/2412.09871v1#S7">7</a>, we ablate the effects of n-gram hash embeddings with different values for n and embedding table size on flop-controlled scaling law trends. In addition to hash n-gram embeddings, we also experimented with frequency based n-gram embeddings, and we provide details of this exploration in Appendix <a href="https://arxiv.org/html/2412.09871v1#S14">14</a>.</p><figure id="1689e7a6-7f26-8144-a6e2-c4eb0497b170" class="image"><a href="https://arxiv.org/html/2412.09871v1/x5.png"><img src="https://arxiv.org/html/2412.09871v1/x5.png"/></a><figcaption>Figure 5 The local encoder uses a cross-attention block with patch representations as queries, and byte representations as keys/values to encode byte representations into patch representations. The local decoder uses a similar block but with the roles reversed i.e. byte representations are now the queries and patch representations are the keys/values. Here we use Cross-Attn k= 2.</figcaption></figure><h3 id="1689e7a6-7f26-81ef-a196-c6ad9e259b9c" class="">3.2.2 Encoder Multi-Headed Cross-Attention</h3><p id="1689e7a6-7f26-8131-acf1-e1f62f6de8a3" class="">We closely follow the input cross-attention module of <mark class="highlight-red"><strong>the Perceiver architecture</strong></mark> (Jaegle et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib22">2021</a>), with <mark class="highlight-red_background"><strong>the main difference being that latent representations correspond to variable patch representations as opposed to a fixed set of latent representations (</strong></mark><mark class="highlight-red_background"><strong><a href="https://arxiv.org/html/2412.09871v1#S3.F5">Figure 5</a></strong></mark><mark class="highlight-red_background"><strong>), and only attend to the bytes that make up the respective patch</strong></mark>. The module comprises <mark class="highlight-red">a query vector, corresponding to each patch </mark><mark class="highlight-red"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></mark><mark class="highlight-red">,</mark> <span style="border-bottom:0.05em solid">which is initialized by pooling the byte representations corresponding to patch </span><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, <mark class="highlight-red">followed by a linear projection, </mark><mark class="highlight-red"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">E</mi><mi>C</mi></msub><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><msub><mi>h</mi><mi mathvariant="script">E</mi></msub><mo>∗</mo><mo stretchy="false">(</mo><msub><mi>h</mi><mi mathvariant="script">E</mi></msub><mo>×</mo><msub><mi>U</mi><mi mathvariant="script">E</mi></msub><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">ℰ_C∈ℝ^{h_ℰ*(h_ℰ×U_ℰ)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.18583em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1858em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></mark><mark class="highlight-red">,</mark> where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">U_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the number of encoder cross-attention heads. Formally, if we let <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mrow><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_{bytes}⁢(p_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">es</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> denote the sequence of bytes corresponding to patch, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, then we calculate</p><p id="1709e7a6-7f26-80b7-98d7-d88bae0ae8a0" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mn>0</mn><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><msub><mi mathvariant="script">E</mi><mi>C</mi></msub><mo stretchy="false">(</mo><msub><mi>f</mi><mrow><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>p</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">P_{0,j}=ℰ_C(f_{bytes}(p_j)),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.18583em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1858em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">es</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mpunct">,</span></span></span></span></span><span>﻿</span></span> f is a pooling function                     ……(5)</p><p id="1709e7a6-7f26-80c3-ba2f-d693f376a073" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>l</mi></msub><mo>=</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mi>o</mi></msub><mrow><mo fence="true">(</mo><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">P_l=P_{l-1}+W_o\left(\operatorname{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0895em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span><span>﻿</span></span>                              ……(6)</p><p id="1709e7a6-7f26-803c-9b71-c3aee2988fc1" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> where </mtext><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>Q</mi><mi>j</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>W</mi><mi>q</mi></msub><mrow><mo fence="true">(</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>k</mi></msub><mrow><mo fence="true">(</mo><msub><mi>h</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>v</mi></msub><mrow><mo fence="true">(</mo><msub><mi>h</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>h</mi><mi>l</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mtext> Encoder-Transformer-Layer </mtext><mi>l</mi></msub><mrow><mo fence="true">(</mo><msub><mi>h</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\text { where } \begin{aligned}
Q_j &amp; =W_q\left(P_{l-1, j}\right), K_i=W_k\left(h_{l-1, i}\right), V_i=W_v\left(h_{l-1, i}\right) \\
h_l &amp; =\text { Encoder-Transformer-Layer }_l\left(h_{l-1}\right)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="mord text"><span class="mord"> where </span></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord text"><span class="mord"> Encoder-Transformer-Layer </span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.242em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>       ……(7) (8)</p><p id="1689e7a6-7f26-81d8-830b-da86c0317e4b" class="">where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><msub><mi>n</mi><mi>p</mi></msub><mo>×</mo><msub><mi>h</mi><mi>𝒢</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">P∈ℝ^{n_p×h_𝒢}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> represents <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">n_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> patch representations to be processed by the global model, which is initialized by pooling together the byte embeddings <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> corresponding to each patch <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">W_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">W
_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">W_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">W_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> are the projections corresponding to the queries, keys, values, and output where the keys and values are projections of byte representations <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">h_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> from the previous layer (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> for the first layer). We use a masking strategy specific to patching where each query <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">Q_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> only attends to the keys and values that correspond to the bytes in patch <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span></span><span>﻿</span></span>. Because we use multi-headed attention over <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span><span>﻿</span></span> and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span><span>﻿</span></span> and patch representations are typically of larger dimension (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">h_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>) than <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">h_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, we maintain <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">P_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> as multiple heads of dimension <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">h_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> when doing cross-attention, and later, concat these representations into <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">h_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> dimensions. Additionally, we use a pre-LayerNorm on the queries, keys and values and no positional embeddings are used in this cross-attention module. Finally, we use a residual connection around the cross-attention block.</p><h3 id="1689e7a6-7f26-8155-874e-dc07109aa335" class="">3.3 Local Decoder</h3><p id="1689e7a6-7f26-814d-b35f-d99d284ea44e" class="">Similar to the local encoder, the local decoder <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒟</mi></mrow><annotation encoding="application/x-tex">𝒟</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.09371em;">D</span></span></span></span></span><span>﻿</span></span> is a lightweight transformer-based model with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>𝒟</mi></msub><mo>&lt;</mo><mo>&lt;</mo><msub><mi>l</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">l_𝒟&lt;&lt;l_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.09371em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> layers, that decodes a sequence of global patch representations <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">o_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, into raw bytes, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. The local decoder predicts a sequence of raw bytes, as a function of previously decoded bytes, and thus, takes as input the hidden representations produced by the local encoder for the byte-sequence. It applies a series of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mi>𝒟</mi></msub></mrow><annotation encoding="application/x-tex">l_𝒟</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.09371em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> alternating layers of cross attention and transformer layers. The cross-attention layer in the decoder is applied before the transformer layer to first create byte representations from the patch representations, and the local decoder transformer layer operates on the resulting byte sequence.</p><h3 id="1689e7a6-7f26-81cd-a47b-dfa5314837e2" class="">3.3.1 Decoder Multi-headed Cross-Attention</h3><p id="1689e7a6-7f26-819c-b37c-fb82ddc17f8d" class="">In the decoder cross-attention, the roles of the queries and key/values are interchanged i.e. the byte-representations are now the queries, and the patch representations are now the key/values. The initial byte-representations for the cross-attention are initialized as the byte embeddings from the last encoder layer i.e. <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><msub><mi>l</mi><mi mathvariant="script">E</mi></msub></msub></mrow><annotation encoding="application/x-tex">h_{l_{ℰ}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9531em;vertical-align:-0.2586em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.0197em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2586em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. The subsequent byte-representations for layer <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>l</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{l,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>are computed as:</p><p id="1709e7a6-7f26-80d9-9a2c-d276bee4e64e" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mn>0</mn></msub><mo>=</mo><msub><mi>h</mi><msub><mi>l</mi><mi mathvariant="script">E</mi></msub></msub></mrow><annotation encoding="application/x-tex">D_0=h_{l_ℰ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9531em;vertical-align:-0.2586em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.0197em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2586em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>                                                                   ……(9)</p><p id="1709e7a6-7f26-807f-919a-fd5f8b554a5e" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>l</mi></msub><mo>=</mo><msub><mi>D</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mi>o</mi></msub><mrow><mo fence="true">(</mo><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">B_l=D_{l-1}+W_o\left(\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0895em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span><span>﻿</span></span>,          ……(10)</p><p id="1709e7a6-7f26-80e0-b1bb-d7bc72c7dfb1" class="">where   <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>q</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>d</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>k</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>𝒟</mi><mi>C</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>o</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>v</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>𝒟</mi><mi>C</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>o</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_i=W_q⁢(d_{l−1,i}),K_i=W_k⁢(𝒟_C⁢(o_j)),V_i=W_v⁢(𝒟_C⁢(o_j))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathscr" style="margin-right:0.09371em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0937em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathscr" style="margin-right:0.09371em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0937em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span><span>﻿</span></span>             ……(11)</p><p id="1709e7a6-7f26-80eb-b292-ea40e7cc3863" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>l</mi></msub><mo>=</mo><msub><mtext>Decoder-Transformer-layerl</mtext><mi>l</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>B</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_l=\text {Decoder-Transformer-layerl}_l⁢(B_l)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord text"><span class="mord">Decoder-Transformer-layerl</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.242em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>        ……(12)</p><p id="1689e7a6-7f26-81c6-818b-d77c63eca48f" class="">where once again, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">W_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">W_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> are key/value projection matrices that operate on a linear transformation and split operation <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝒟</mi><mi>C</mi></msub></mrow><annotation encoding="application/x-tex">𝒟_C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.09371em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0937em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, applied to the final patch representations <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>o</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">o_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> from the global model, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">W_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is a query projection matrices operating on byte representations <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">d_{l−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> from the previous decoder transformer layer (or <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><msub><mi>l</mi><mi mathvariant="script">E</mi></msub></msub></mrow><annotation encoding="application/x-tex">h_{l_ℰ}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9531em;vertical-align:-0.2586em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.0197em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2586em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> for the first layer), and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">W_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the output projection matrix, thus making <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><msub><mi>h</mi><mi>𝒟</mi></msub><mo>×</mo><msub><mi>n</mi><mi>b</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">B∈ℝ^{h_𝒟×n_b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathscr mtight" style="margin-right:0.09371em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1552em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">n_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the number of output bytes. The next decoder representations <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">D_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> are computed using a decoder transformer layer on the output of the cross-attention block, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span></span><span>﻿</span></span>. <mark class="highlight-red_background"><span style="border-bottom:0.05em solid">As in the local encoder cross-attention, we use multiple heads in the attention, use pre LayerNorms, no positional embeddings, and a residual connection around the cross-attention module.</span></mark></p><h2 id="1689e7a6-7f26-81e0-8b52-d2b745747f01" class="">4 Experimental Setup</h2><p id="1689e7a6-7f26-8111-8a51-d413cfd75676" class="">We carefully design controlled experiments to compare BLT with tokenization based models with particular attention to not give BLT any advantages from possibly using longer sequence contexts.</p><h3 id="1689e7a6-7f26-81c9-900b-eb31416b13b6" class="">4.1 Pre-training Datasets</h3><p id="1689e7a6-7f26-8141-b1f8-ca8c167223ca" class="">All model scales that we experiment in this paper are pre-trained on two datasets: </p><p id="1719e7a6-7f26-80be-b7b9-f2b824da65c5" class="">1) The Llama 2 dataset (Touvron et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib43">2023</a>), which comprises 2 trillion tokens collected from a variety of publicly available sources, which are subsequently cleaned and filtered to improve quality; </p><p id="1719e7a6-7f26-804a-aa9c-e02eb8e0e4e5" class="">and 2) BLT-1T: A new dataset with 1 trillion tokens gathered from various public sources, and also including a subset of the pre-training data released by Datacomp-LM (Li et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib28">2024</a>). </p><p id="1719e7a6-7f26-80f8-aab7-d57d6f9d485f" class="">The former is used for scaling law experiments on optimal number of tokens as determined by Dubey et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>) to determine the best architectural choices for BLT, while the latter is used for a complete pre-training run to compare with Llama 3 on downstream tasks. </p><p id="1719e7a6-7f26-80d4-a7d2-cae64fc45e2e" class="">Neither of these datasets include any data gathered from Meta products or services. Furthermore, for baseline experiments for tokenizer-based models, we use the Llama 3 tokenizer with a vocabulary size of 128K tokens, which produced stronger baseline performance that the Llama 2 tokenizer in our experiments.</p><h3 id="1689e7a6-7f26-8108-a64c-de4265c48d6c" class="">4.2 Entropy Model</h3><p id="1689e7a6-7f26-8174-83bb-f8ddfdf62795" class="">The entropy model in our experiments is a byte level language model trained on the same training distribution as the full BLT model. Unless otherwise mentioned, we use a transformer with 100M parameters, 14 layers, and a hidden dimensionality of 512, and sliding window attention of 512 bytes. The remaining hyperparameters are the same as in our local and global transformers. We experimented with different model sizes, receptive fields, and architectures as discussed in <a href="https://arxiv.org/html/2412.09871v1#S7">section 7</a>. In particular, when the receptive field of the model is small enough, the trained entropy model can be encoded in an efficient lookup table.</p><h3 id="1689e7a6-7f26-81a9-b898-d023f9ccc8ec" class="">4.3 Entropy Threshold and Equalizing Context Length</h3><p id="1689e7a6-7f26-8187-97b2-fafc97f956c3" class="">For models using entropy-based patching, we estimate a patching threshold that achieves a desired average patch size on the pretraining data mix. In BLT, unlike with tokenization, the patch size can be arbitrarily chosen having significant implications on the context size used by the model. To maintain the same average context length and avoid giving larger patch sizes unfair advantage, we ensure that the number of bytes in each batch remains constant in expectation. This means that we reduce the sequence length of models with larger patch sizes. On Llama 2 data, we use a 8k byte context while on the BLT-1T dataset we increase the context to 16k bytes on average while maintaining the same batch size of 16M bytes on average.</p><p id="1689e7a6-7f26-810e-8430-db3a70d67742" class="">While the average batch size is constant, when loading batches of data, dynamic patching methods yield different ratios of bytes to patches. For efficiency reasons, our implementation of BLT training packs batches of patches to avoid padding steps in the more expensive latent transformer. This ensures that every batch has the same number of patches. During training we pad and possibly truncate byte sequences to 12k and 24k bytes respectively for Llama 2 and BLT-1T datasets, to avoid memory spikes from sequences with unusually large patches.</p><h3 id="1689e7a6-7f26-8156-b698-e48cbf3a0b4c" class="">4.4 Entropy Model Context</h3><p id="1689e7a6-7f26-81ae-af3b-e148149263ba" class="">Empirically, we find that using entropy patching yields progressively larger patches in structured content <mark class="highlight-red"><mark class="highlight-red_background">like multiple choice tasks</mark></mark> (see patching on an MMLU example in <a href="https://arxiv.org/html/2412.09871v1#S15.F9">Figure 9</a>) which are often very repetitive. These variations are caused by lower entropy on the repeated content found in the entropy model context. So for the large scale run of BLT-Entropy with patch size 4.5, we reset the entropy context with new lines and use approximate monotonicity constraint as it suffers less from &quot;entropy drift&quot; from changes in context length. This change only affects how we compute entropies, but we still follow the same procedure to identify the value of the entropy threshold.</p><h3 id="1689e7a6-7f26-8101-8032-ea927f6cbcd2" class="">4.5 FLOPs Estimation</h3><p id="1689e7a6-7f26-8176-a905-f7e6fd8cdea4" class="">We largely follow the equations for computation of transformer flops from Chinchilla (Hoffmann et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib21">2022</a>) comprising flops for the feed-forward layers, QKVO projections in the self-attention layer, and computation of attention and output projection. A notable difference is that we assume the input embedding layer is implemented as an efficient lookup instead of a dense matrix multiplication, therefore becoming a 0-FLOP operation. Following previous work, we estimate that the backwards pass has twice the number of flops as the forward pass.</p><p id="1689e7a6-7f26-81b2-be8b-f1e136ddfd54" class="">To compute flops per byte for BLT models, we add up the flops for the local encoder transformer, the global latent transformer, and the local decoder transformer, together with the cross attention blocks in the encoder and the decoder:</p><p id="1719e7a6-7f26-8054-9c47-f1d2c9e48973" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">L</mi></mrow><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">T</mi></mrow></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">Transf.</mi><mo>⁡</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">L</mi></mrow><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi mathvariant="script">G</mi></msub><mo separator="true">,</mo><msub><mi>l</mi><mi mathvariant="script">G</mi></msub><mo separator="true">,</mo><mi>m</mi><mo>=</mo><msub><mi>n</mi><mrow><mi>c</mi><mi>t</mi><mi>x</mi></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>n</mi><mi>p</mi></msub><mo separator="true">,</mo><mi>V</mi><mo>=</mo><mn>0</mn><mo fence="true">)</mo></mrow><mi mathvariant="normal">/</mi><msub><mi>n</mi><mi>p</mi></msub><mtext>         ......(13)</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mi mathvariant="normal">Transf.</mi><mo>⁡</mo><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">L</mi></mrow><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi mathvariant="script">E</mi></msub><mo separator="true">,</mo><msub><mi>l</mi><mi mathvariant="script">E</mi></msub><mo separator="true">,</mo><mi>m</mi><mo>=</mo><msub><mi>w</mi><mi mathvariant="script">E</mi></msub><mo separator="true">,</mo><mi>V</mi><mo>=</mo><mn>0</mn><mo fence="true">)</mo></mrow><mtext>                        ......(14)</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mi mathvariant="normal">Transf.</mi><mo>⁡</mo><mi mathvariant="normal">FL</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi mathvariant="script">D</mi></msub><mo separator="true">,</mo><msub><mi>l</mi><mi mathvariant="script">D</mi></msub><mo separator="true">,</mo><mi>m</mi><mo>=</mo><msub><mi>w</mi><mi mathvariant="script">D</mi></msub><mo separator="true">,</mo><mi>V</mi><mo>=</mo><mn>256</mn><mo fence="true">)</mo></mrow><mtext>                   ......(15)</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mtext> Cross Attn. FL </mtext><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi mathvariant="script">E</mi></msub><mo separator="true">,</mo><msub><mi>l</mi><mi mathvariant="script">E</mi></msub><mo separator="true">,</mo><mi>m</mi><mo>=</mo><msub><mi>n</mi><mi>p</mi></msub><mo separator="true">,</mo><mi>r</mi><mo>=</mo><msub><mi>n</mi><mi>p</mi></msub><mi mathvariant="normal">/</mi><mi>k</mi><mo fence="true">)</mo></mrow><mo>×</mo><mi>k</mi><mi mathvariant="normal">/</mi><msub><mi>n</mi><mi>p</mi></msub><mtext>         ......(16)</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mtext> Cross Attn. </mtext><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">L</mi></mrow><mrow><mo fence="true">(</mo><msub><mi>h</mi><mi mathvariant="script">D</mi></msub><mo separator="true">,</mo><msub><mi>l</mi><mi mathvariant="script">D</mi></msub><mo separator="true">,</mo><mi>m</mi><mo>=</mo><mi>k</mi><mo separator="true">,</mo><mi>r</mi><mo>=</mo><mi>k</mi><mi mathvariant="normal">/</mi><msub><mi>n</mi><mi>p</mi></msub><mo fence="true">)</mo></mrow><mtext>            ......(17)</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mathrm{FL}_{\mathrm{BLT}} &amp; =\operatorname{Transf.} \mathrm{FL}\left(h_{\mathcal{G}}, l_{\mathcal{G}}, m=n_{c t x} / n_p, V=0\right) / n_p \text{\ \ \ \ \ \ \ \ \ ......(13)}\\
&amp; +\operatorname{Transf.} \mathrm{FL}\left(h_{\mathcal{E}}, l_{\mathcal{E}}, m=w_{\mathcal{E}}, V=0\right) \text{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ......(14)}\\
&amp; +\operatorname{Transf.} \operatorname{FL}\left(h_{\mathcal{D}}, l_{\mathcal{D}}, m=w_{\mathcal{D}}, V=256\right) \text{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ......(15)}\\
&amp; + \text { Cross Attn. FL }\left(h_{\mathcal{E}}, l_{\mathcal{E}}, m=n_p, r=n_p / k\right) \times k / n_p \text{\ \ \ \ \ \ \ \ \ ......(16)}\\
&amp; + \text { Cross Attn. } \mathrm{FL}\left(h_{\mathcal{D}}, l_{\mathcal{D}}, m=k, r=k / n_p\right)\text{\ \ \ \ \ \ \ \ \ \ \ \ ......(17)}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.5em;vertical-align:-3.5em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4em;"><span style="top:-6.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathrm">FL</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">BLT</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-0.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.5em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4em;"><span style="top:-6.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop"><span class="mord mathrm">Transf.</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathrm">FL</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.0593em;">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2181em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.0593em;">G</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2181em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">/</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">         ......(13)</span></span></span></span><span style="top:-4.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">Transf.</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathrm">FL</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">                        ......(14)</span></span></span></span><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">Transf.</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">FL</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">256</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">                   ......(15)</span></span></span></span><span style="top:-1.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord"> Cross Attn. FL </span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">         ......(16)</span></span></span></span><span style="top:-0.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord"> Cross Attn. </span></span><span class="mord"><span class="mord mathrm">FL</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">            ......(17)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.5em;"><span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="1689e7a6-7f26-8111-8ff1-fafe4fcd7997" class="">where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mrow><mi>c</mi><mtext>⁢</mtext><mi>t</mi><mtext>⁢</mtext><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{c⁢t⁢x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">t</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the sequence length in bytes, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">n_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the patch size, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span></span><span>﻿</span></span> is the ratio of queries to key/values, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span><span>﻿</span></span> is the ratio of patch-dimension to byte-dimension i.e. the number of local model splits that concatenate to form a global model representation (k=2 in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Figure 5</a>). <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span><span>﻿</span></span> corresponds to the vocabulary size for the output projection, which is only used in the local decoder. Depending on whether a module is applied on the byte or patch sequence, the attention uses a different context length, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span><span>﻿</span></span>. We modify the attention flops accordingly for each component. The exact equations for flops computation for Transformer-FLOPs and Cross-Attention FLOPs are provided in Appendix <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">12</a>.</p><h3 id="1689e7a6-7f26-819d-bdda-ec50ac24e4cc" class="">4.6 Bits-Per-Byte Estimation</h3><p id="1689e7a6-7f26-8148-a0de-d2307371212e" class="">Perplexity only makes sense in the context of a fixed tokenizer as it is a measure of the uncertainty for each token. When comparing byte and token-level models, following previous work (Xue et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib47">2022</a>; Yu et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib48">2023</a>; Wang et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib45">2024</a>), we instead report Bits-Per-Byte (BPB), a tokenizer independent version of perplexity. Specifically:</p><p id="1729e7a6-7f26-80e5-accf-e310a0f16449" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>P</mi><mi>B</mi><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>C</mi><mtext>⁢</mtext><mi>E</mi></mrow></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><mrow><mi>l</mi><mi>n</mi><mtext>⁡</mtext><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>n</mi><mrow><mi>b</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">BPB⁢(x)=\frac{ℒ_{C⁢E}⁢(𝒙)}{ln⁡(2)⋅n_{bytes}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">BPB</span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.5581em;vertical-align:-0.5481em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">n</span><span class="mord mtight">⁡</span><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">es</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2901em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathscr mtight" style="margin-right:0.19189em;">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.1919em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span><span class="mord mtight">⁢</span><span class="mopen mtight">(</span><span class="mord boldsymbol mtight" style="margin-right:0.12583em;">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5481em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span>                                    ……(18)</p><p id="1689e7a6-7f26-81a4-a16a-f7974bf0ca90" class="">where the uncertainty over the data 𝒙 as measured by the sum of the cross-entropy loss is normalized by the total number of bytes in 𝒙 and a constant.</p><h3 id="1689e7a6-7f26-81e7-bc42-efa33e8e719e" class="">4.7 Transformer Architecture Hyperparameters</h3><p id="1689e7a6-7f26-81df-a7d0-f5b5ebe41cad" class="">For all the transformer blocks in BLT, i.e. both local and global models, we largely follow the architecture of Llama 3 (Dubey et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>); we use the SwiGLU activation function (Shazeer, <a href="https://arxiv.org/html/2412.09871v1#bib.bib38">2020</a>) in the feed-forward layers, rotary positional embeddings (RoPE) (Su et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib40">2021</a>) with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>=</mo><mn>500000</mn></mrow><annotation encoding="application/x-tex">θ=500000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">500000</span></span></span></span></span><span>﻿</span></span> (Xiong et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib46">2024</a>) only in self-attention layers, and RMSNorm (Zhang and Sennrich, <a href="https://arxiv.org/html/2412.09871v1#bib.bib50">2019</a>) for layer normalization. We use Flash attention (Dao et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib12">2022</a>) for all self-attention layers that use fixed-standard attention masks such as block causal or fixed-window block causal, and a window size of 512 for fixed-width attention masks. Since our cross-attention layers involve dynamic patch-dependent masks, we use Flex Attention<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>5</mn></msup></mrow><annotation encoding="application/x-tex">^5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> to produce fused implementations and significantly speed up training.</p><h3 id="1689e7a6-7f26-81b1-b9f6-fcf18954795f" class="">4.8 BLT-Specific Hyperparameters</h3><p id="1689e7a6-7f26-810b-91d2-cf8cbc1c1e5b" class="">To study the effectiveness of BLT models, we conduct experiments along two directions, scaling trends, and downstream task evaluations, and we consider models at different scales: 400M, 1B, 2B, 4B and 8B for these experiments. The architecture hyperparameters for these models are presented in Appendix Table <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">10</a>. We use max-pooling to initialize the queries for the first cross-attention layer in the local encoder. We use 500,000 hashes with a single hash function, with n-gram sizes ranging from 3 to 8, for all BLT models. We use a learning rate of 4⁢e−4 for all models. The choice of matching learning rate between token and BLT models follows a hyperparameter search between 1⁢e−3 and 1⁢e−4 at 400M and 1B model scales showing the same learning rate is optimal. For scaling trends on Llama-2 data, we use training batch-sizes as recommended by Dubey et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>) or its equivalent in bytes. For optimization, we use the AdamW optimizer (Loshchilov and Hutter, <a href="https://arxiv.org/html/2412.09871v1#bib.bib31">2017</a>) with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">β1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord">1</span></span></span></span></span><span>﻿</span></span> set to 0.9 and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">β2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord">2</span></span></span></span></span><span>﻿</span></span> to 0.95, with an <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">ϵ=10^{−8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. We use a linear warm-up of 2000 steps with an cosine decay schedule of the learning rate to 0, we apply a weight decay of 0.1, and global gradient clipping at a threshold of 1.0.</p><h2 id="1689e7a6-7f26-8175-8167-ca02370dcf67" class="">5 Scaling Trends</h2><p id="1689e7a6-7f26-8166-9321-f0da854550a6" class="">We present a holistic picture of the scaling trends of byte-level models that can inform further scaling of BLT models. Our scaling study aims to address the limitations of previous research on byte-level models in the following ways: </p><p id="1729e7a6-7f26-8028-b353-d5362d8c6e8f" class="">(a) We compare trends for the compute-optimal training regime, </p><p id="1729e7a6-7f26-80ec-8e31-c1468d6ec254" class="">(b) We train matching 8B models on non-trivial amounts of training data (up to 1T tokens/4T bytes) and evaluate on downstream tasks, and </p><p id="1729e7a6-7f26-80c3-b66f-eb5a4c0c249c" class="">(c) We measure scaling trends in inference-cost controlled settings. In a later section, we will investigate specific advantages from modeling byte-sequences.</p><figure id="1689e7a6-7f26-819a-8890-fef570a0a387" class="image"><a href="https://arxiv.org/html/2412.09871v1/x6.png"><img style="width:624px" src="https://arxiv.org/html/2412.09871v1/x6.png"/></a></figure><figure id="1689e7a6-7f26-8166-9451-c98d978423e8" class="image"><a href="https://arxiv.org/html/2412.09871v1/x7.png"><img style="width:624px" src="https://arxiv.org/html/2412.09871v1/x7.png"/></a><figcaption>Figure 6 Scaling trends for BLT models with different architectural choices, as well as for baseline BPE token-based models. We train models at multiple scales from 1B up to 8B parameters for the optimal number of tokens as computed by Dubey et al. (2024) and report bits-per-byte on a sample from the training distribution. BLT models perform on par with state-of-the-art tokenizer-based models such as Llama 3, at scale. PS denotes patch size. We illustrate separate architecture improvements on space-patching (left) and combine them with dynamic patching (right).</figcaption></figure><h3 id="1689e7a6-7f26-81fe-9af8-d06f3ab1b4cb" class="">5.1 Parameter Matched Compute Optimal Scaling Trends</h3><p id="1689e7a6-7f26-81f1-8740-e5a89f13b70f" class="">Using the Llama 2 dataset, we train various <em>compute-optimal</em> BPE and BLT models across four different sizes, ranging from 1B to 8B parameters. We then plot the training flops against language modeling performance on a representative subset of the training data mixture. The bpe models are trained using the optimal ratio of model parameters to training data, as determined by Llama 3 (Dubey et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>). This compute-optimal setup is theoretically designed to achieve the best performance on the training dataset within a given training budget (Hoffmann et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib21">2022</a>), providing a robust baseline for our model. For each bpe model, we also train a corresponding BLT model on the same data, using a Latent Transformer that matches the size and architecture of the corresponding bpe Transformer.</p><p id="1689e7a6-7f26-8122-bbbf-c51c9e40983f" class="">As illustrated in <a href="https://arxiv.org/html/2412.09871v1#S5.F6">Figure 6</a> (right), BLT models either match or outperform their bpe counterparts and this trend holds as we scale model size and flops. To the best of our knowledge, BLT is the first byte-level Transformer architecture to achieve matching scaling trends with BPE-based models at compute optimal regimes. This therefore validates our assumption that the optimal ratio of parameters to training compute for bpe also applies to BLT, or at least it is not too far off.</p><p id="1689e7a6-7f26-81b8-8b25-c9194c4c8356" class="">Both architectural improvements and dynamic patching are crucial to match bpe scaling trends. In <a href="https://arxiv.org/html/2412.09871v1#S5.F6">Figure 6</a> (left), we compare space-patching-based models against Llama 3. We approximate SpaceByte (Slagle, <a href="https://arxiv.org/html/2412.09871v1#bib.bib39">2024</a>) using BLT space-patching without n-gram embeddings and cross-attention. Although SpaceByte improves over Megabyte, it remains far from Llama 3. In <a href="https://arxiv.org/html/2412.09871v1#S5.F6">Figure 6</a> (right), we illustrate the improvements from both architectural changes and dynamic patching. BLT models perform on par with state-of-the-art tokenizer-based models such as Llama 3, at scale.</p><p id="1689e7a6-7f26-8164-b0ef-f82f118fd2e0" class="">We also observe the effects of the choice of tokenizer on performance for tokenizer-based models, i.e., models trained with the Llama-3 tokenizer outperform those trained using the Llama-2 tokenizer on the same training data.</p><p id="1689e7a6-7f26-81ed-86d4-d3971db6a71d" class="">Finally, our BLT architecture trends between Llama 2 and 3 when using significantly larger patch sizes. The bpe tokenizers of Llama 2 and 3 have an average token size of 3.7 and 4.4 bytes. In contrast, BLT can achieve similar scaling trends with an average patch size of 6 and even 8 bytes. Inference flop are inversely proportional to the average patch size, so using a patch size of 8 bytes would lead to nearly 50% inference flop savings. Models with larger patch sizes also seem to perform better as we scale model and data size. BLT with patch size of 8 starts at a significantly worse point compared to bpe Llama 2 at 1B but ends up better than bpe at 7B scale. This suggests that such patch sizes might perform better at even larger scales and possibly that even larger ones could be feasible as model size and training compute grow.</p><h3 id="1689e7a6-7f26-8102-959c-f26a34783c14" class="">5.2 Beyond Compute Optimal Task Evaluations</h3><p id="1689e7a6-7f26-8110-846a-da575ff059d1" class="">To assess scaling properties further, we train an 8B BLT model beyond the compute optimal ratio on the BLT-1T dataset, a larger higher-quality dataset, and measure performance on a suite of standard classification and generation benchmarks. For evaluation, we select the following common sense reasoning, world knowledge, and code generation tasks:</p><h3 id="1689e7a6-7f26-81fd-a1ca-dd4547640c03" class="">Classification tasks</h3><p id="1689e7a6-7f26-81c2-88ef-de785e7b301c" class="">include ARC-Easy (0-shot) (Clark et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib10">2018</a>), Arc-Challenge (0-shot) (Clark et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib10">2018</a>), HellaSwag (0-shot) (Zellers et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib49">2019</a>), PIQA (0-shot) (Bisk et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib4">2020</a>), and MMLU (5-shot) (Hendrycks et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib20">2020</a>). We employ a prompt-scoring method, calculating the likelihood over choice characters, and report the average accuracy.</p><h3 id="1689e7a6-7f26-81a2-90bc-fadbe1a4372f" class="">Coding related generation tasks:</h3><p id="1689e7a6-7f26-8187-acef-f878fbc94171" class="">We report pass@1 scores on MBPP (3-shot) (Austin et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib2">2021</a>) and HumanEval (0-shot) (Chen et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib6">2021</a>), to evaluate the ability of LLMs to generate Python code.</p><p id="1689e7a6-7f26-81c5-9c5b-d7b759f47e1c" class="">In <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 1</a>, we compare three models trained on the BLT-1T dataset: a bpe Llama 3 tokenizer-based model, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>6</mn></msup></mrow><annotation encoding="application/x-tex">^6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> and two variants of the BLT model. One employing a space-patching scheme (BLT-Space) and another utilizing an entropy-based patching scheme (BLT-Entropy). with approx. monotonicity constraint and reset the context of the entropy model with new lines (as discussed in<a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21"> subsection 4.4</a>). All three models are trained with an equivalent flop budget. However, with BLT-Entropy we additionally make an inference time adjustment of the entropy threshold from 0.6 to 0.1 which we find to improve task performance at the cost of more inference steps.</p><figure id="1729e7a6-7f26-8017-a393-d34a167ec115" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image.png"><img style="width:576px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image.png"/></a><figcaption>Table 1 Comparison of flop-matched BLT 8B models trained on the BLT-1T dataset comprising high-quality tokens of text and code from publicly available sources, with baseline models using the Llama 3 tokenizer. BLT performs better than Llama 3 on average, and depending on the patching scheme, achieves significant flops savings with a minor reduction in performance.</figcaption></figure><p id="1689e7a6-7f26-8103-8f70-d53b5fd85260" class=""><mark class="highlight-red"><mark class="highlight-red_background"><strong>The BLT-Entropy model outperforms the Llama 3 model on 4 out of 7 tasks while being trained on the same number of bytes.</strong></mark></mark><strong> </strong>This improvement is like due to a combination of </p><p id="1729e7a6-7f26-80db-9180-e9f5873b4961" class="">(1) a better use of training compute via dynamic patching, and </p><p id="1729e7a6-7f26-80de-b292-d0b6e72c788c" class="">(2) the direct modeling of byte-level information as opposed to tokens.</p><p id="1689e7a6-7f26-81c5-8f30-c50a51a504a8" class="">On the other hand, BLT-Space underperforms the Llama 3 tokenizer on all but one task, but it achieves a significant reduction in inference flops with its larger average patch size of 6 bytes. In comparison, the bpe and entropy-patching based models have roughly equivalent average patch size of approximately 4.5 bytes on the training data mix. With the same training budget, the larger patch size model covers 30% more data than the other two models which might push BLT further away from the compute-optimal point.</p><h3 id="1689e7a6-7f26-817b-ac19-e07e9ad2096b" class="">5.3 Patches Scale Better Than Tokens</h3><p id="1689e7a6-7f26-8199-a195-e55d05d04670" class="">With BLT models, we can simultaneously increase model size and patch size while maintaining the same training and inference flop budget and keeping the amount of training data constant. Arbitrarily increasing the patch size is a unique feature of patch-based models which break free of the efficiency tradeoffs of fixed-vocabulary token-based models, as discussed in Section <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">2.4</a>. Longer patch sizes save compute, which can be reallocated to grow the size of the global latent transformer, because it is run less often.</p><p id="1689e7a6-7f26-81c0-b069-ec943614e2dc" class="">We conduct a fixed inference scaling study to test the hypothesis that larger models taking fewer steps on larger patches might perform better than smaller models taking more steps. Starting from model sizes of 400m and 3.6B parameters with the Llama 2 tokenizer, we find flop equivalent models with the Llama 3 tokenizer and BLT-Entropy models with average patch sizes of 6 and 8 bytes on the training datamix (see <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 2</a> for model details). For patch size 8 models, we use 3 encoder layers instead of 1. We train each model for various training flop budgets.</p><figure id="1729e7a6-7f26-80d1-9778-c27325d406e0" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%201.png"><img style="width:864px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%201.png"/></a><figcaption>Table 2 Details of models used in the fixed-inference scaling study. We report non-embedding parameters for each model and their relative number compared to Llama 2. We pick model sizes with equal inference flops per byte. We also indicate BPE’s compute-optimal training data quantity and the crossover point where BLT surpasses BPE as seen in Figure 1 (both expressed in bytes of training data). This point is achieved at much smaller scales compared to many modern training budgets.</figcaption></figure><p id="1689e7a6-7f26-81db-ae26-d0cda2d598f8" class=""><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Figure 1</a> shows that BLT models achieve better scaling trends than tokenization-based architectures for both inference flop classes.<mark class="highlight-red"><mark class="highlight-red_background"><span style="border-bottom:0.05em solid"> In both cases, BPE models perform better with small training budgets and are quickly surpassed by BLT, not far beyond the compute-optimal regime. </span></mark></mark>In practice, it can be preferable to spend more during the one-time pretraining to achieve a better performing model with a fixed inference budget. A perfect example of this is the class of 8B models, like Llama 3.1, which has been trained on two orders of magnitude more data than what is compute-optimal for that model size.</p><p id="1689e7a6-7f26-816c-96c9-ffdbf1db5fb7" class="">The crossover point where BLT improves over token-based models has shifted slightly closer to the compute-optimal point when moving to the larger flop class models (from 3x down to 2.5x the compute optimal budget). Similarly, the larger patch size 8 model has steeper scaling trend in the larger flop class overtaking the other models sooner. As discussed in Section <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">5.1</a>, <mark class="highlight-red"><strong><span style="border-bottom:0.05em solid">larger patch sizes appear to perform closer to BPE models at larger model scales</span></strong></mark>. We attribute this, in part, to the decreasing share of total flops used by the byte-level Encoder and Decoder modules which seem to scale slower than the Latent Transformer. When growing total parameters 20x from 400M to 8B, we only roughly double BLT’s local model parameters. This is important as larger patch sizes only affect flops from the patch Latent Transformer and not the byte-level modules. In fact, that is why the BLT-Entropy ps=8 went from 1.6x to 1.7x of the Llama 2 model size when moving to the larger model scale.</p><p id="1689e7a6-7f26-81ac-b578-ec1218ba7241" class="">In summary, our patch-length scaling study demonstrates that the BLT patch-based architecture can achieve better scaling trends by simultaneously increasing both patch and model size. Such trends seem to persist and even improve at larger model scales.</p><h2 id="1689e7a6-7f26-815f-a2e2-e207c6482904" class="">6 Byte Modeling Improves Robustness</h2><p id="1689e7a6-7f26-81d5-bc56-d0f2c543db7b" class="">We also measure the robustness of BLT compared to token-based models that lack direct byte-level information, and present an approach to byte-ify pretrained token-based models.</p><h3 id="1689e7a6-7f26-81e1-948d-d29f6470a951" class="">6.1 Character-Level Tasks</h3><p id="1689e7a6-7f26-814c-9d30-f357af7d041f" class="">A very early motivation for training byte-level models was to take advantage of their robustness to byte level noise in the input, and also to exploit their awareness of the constituents of tokens, which current tokenizer-based models struggle with. <mark class="highlight-red"><strong>To measure these phenomena, we perform additional evaluations on benchmarks that evaluate both robustness to input noise as well as awareness of characters, both English and multi-lingual, including digits and phonemes.</strong></mark> We present these results in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 3</a>.</p><figure id="1729e7a6-7f26-80e1-a385-d66c0039e540" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%202.png"><img style="width:480px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%202.png"/></a><figcaption>Table 3 We compare our 8B BLT model to 8B BPE Llama 3 trained on 1T tokens on tasks that assess robustness to noise and awareness of the constituents of language (best result bold). We also report the performance of Llama 3.1 on the same tasks and underline best result overall. BLT outperforms the Llama 3 BPE model by a large margin and even improves over Llama 3.1 in many tasks indicating that the byte-level awareness is not something that can easily be obtained with more data.</figcaption></figure><p id="1729e7a6-7f26-8006-9b03-db0e93207803" class="">
</p><h3 id="1689e7a6-7f26-8135-98fd-fd637ebce238" class="">Noisy Data</h3><p id="1689e7a6-7f26-816a-8f0c-e921db284fac" class="">We create noised versions of the benchmark classification tasks described in Section <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">5.2</a>, to compare the robustness of tokenizer-based models with that of BLT. We employ five distinct character-level noising strategies to introduce variations in the text: </p><p id="1729e7a6-7f26-8098-844a-c0522846e4ca" class="">(a) AntSpeak: This strategy converts the entire text into uppercase, space-separated characters. </p><p id="1729e7a6-7f26-806d-974a-e75060e682bd" class="">(b) Drop: Randomly removes 10% of the characters from the text. </p><p id="1729e7a6-7f26-80a0-a507-d73efba2dd9b" class="">(c) RandomCase: Converts 50% of the characters to uppercase and 50% to lowercase randomly throughout the text. </p><p id="1729e7a6-7f26-8056-921a-dcd2547796a2" class="">(d) Repeat: Repeats 20% of the characters up to a maximum of four times. </p><p id="1729e7a6-7f26-808b-b540-e907ff2239c9" class="">(e) UpperCase: Transforms all characters in the text to uppercase. </p><p id="1729e7a6-7f26-800c-87c0-f7839114be67" class="">During evaluation, we apply each noising strategy to either the prompt, completion, or both as separate tasks and report the average scores. In Table <a href="https://arxiv.org/html/2412.09871v1#S5.T3">3</a> we report results on noised HellaSwag (Zellers et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib49">2019</a>) and find that BLT indeed outperforms tokenizer-based models across the board in terms of robustness, <mark class="highlight-red"><mark class="highlight-red_background"><strong>with an average advantage of 8 points over the model trained on the same data</strong></mark></mark>, and even improves over the Llama 3.1 model trained on a much larger dataset.</p><h3 id="1689e7a6-7f26-818f-b70b-d1ea17071423" class="">Phonology - Grapheme-to-Phoneme (G2P)</h3><p id="1689e7a6-7f26-81df-a799-dc3e2cd238b4" class="">We assess BLT’s capability to map a sequence of graphemes (characters representing a word) into a transcription of that word’s pronunciation (phonemes). In <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 3</a>, we present the results of the G2P task in a 5-shot setting using Phonology Bench (Suvarna et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib42">2024</a>) and find that BLT outperforms the baseline Llama 3 1T tokenizer-based model on this task.</p><h3 id="1689e7a6-7f26-813c-821a-d86d6d98acb1" class="">CUTE</h3><p id="1689e7a6-7f26-817b-a52d-e60783f0e1bc" class="">To assess character-level understanding, we evaluate BLT on the CUTE benchmark (Edman et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib14">2024</a>), which comprises several tasks that are broadly classified into three categories:<mark class="highlight-red"><strong> understanding composition, understanding orthographic similarity, and ability to manipulate sequences.</strong></mark> This benchmark poses a significant challenge for most tokenizer-based models, as they appear to possess knowledge of their tokens’ spellings but struggle to effectively utilize this information to manipulate text. <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 3</a> shows that BLT-Entropy outperforms both BPE Llama 3 models by more than 25 points on this benchmark. In particular, our model demonstrates exceptional proficiency in character manipulation tasks achieving 99.9% on both spelling tasks. Such large improvements despite BLT having been trained on 16x less data than Llama 3.1 indicates that character level information is hard to learn for BPE models. <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Figure 7</a> illustrates a few such scenarios where Llama 3 tokenizer model struggles but our BLT model performs well. Word deletion and insertion are the only two tasks where BPE performs better. Such word manipulation might not be straightforward for a byte-level model but the gap is not too wide and building from characters to words could be easier than the other way around. We use the same evaluation setup in all tasks and the original prompts from Huggingface. BPE models might benefit from additional prompt engineering.</p><figure id="1729e7a6-7f26-80db-84b1-eb0a07f5e6b0" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%203.png"><img style="width:857.9774780273438px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%203.png"/></a><figcaption>Figure 7 Output responses from Llama 3 and BLT models for various tasks from CUTE benchmark. BLT model performs better on sequence manipulation tasks compared to the tokenizer-based Llama 3 model. Note that few-shot examples are not shown in the above prompts to maintain clarity.</figcaption></figure><h3 id="1689e7a6-7f26-8103-b293-d6ded9bdc3f9" class="">Low Resource Machine Translation</h3><p id="1689e7a6-7f26-81d2-865d-c4a63a9148bf" class="">We evaluate BLT on translating into and out of six popular language families and twenty one lower resource languages with various scripts from the FLORES-101 benchmark (Goyal et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib17">2022</a>) and report SentencePiece BLEU in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 4</a>. Our results demonstrate that BLT outperforms a model trained with the Llama 3 tokenizer, achieving a 2-point overall advantage in translating into English and a 0.5-point advantage in translating from English. In popular language pairs, BLT performs comparably to or slightly better than Llama 3. However, BLT outperforms Llama 3 on numerous language pairs within lower-resource language families, underscoring the effectiveness of byte modeling for generalizing to long-tail byte sequences.</p><figure id="1729e7a6-7f26-805c-a520-f4052edccd42" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%204.png"><img style="width:432px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%204.png"/></a><figcaption>Table 4 Performance of 8B BLT and 8B Llama 3 trained for 1T tokens on translating into and from six widely-used languages and twenty one lower resource languages with various scripts from the FLORES-101 benchmark (Goyal et al., 2022).</figcaption></figure><p id="1729e7a6-7f26-806e-9b31-cf4644d20a49" class="">
</p><h3 id="1689e7a6-7f26-8133-86fe-d89e5d9bfcc6" class="">6.2 Training BLT from Llama 3</h3><p id="1689e7a6-7f26-816c-b38b-e1b316805f73" class="">We explore a workflow where BLT models can leverage existing pre-trained tokenizer-based models for better and faster training convergence, achieved by initializing the global transformer parameters of BLT with those of a pre-trained Llama 3.1 model. Subsequently, we update the weights of the global transformer using one-tenth the learning rate employed for the local encoder and local decoder model, for Llama 3 optimal number of steps, and present a comparison with a baseline BLT in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 5</a>. It is evident that BLT from Llama 3.1 significantly outperforms both the Llama 3 and BLT baselines, which were trained with the same number of flops. Moreover, when compared to our BLT-Entropy model (as presented in Table <a href="https://arxiv.org/html/2412.09871v1#S5.T1">1</a>), which was trained on a significantly larger dataset (1T tokens), BLT from Llama 3.1 still achieves superior performance on MMLU task, suggesting that it can be an effective approach in significantly reducing the training flops.</p><figure id="1729e7a6-7f26-8005-a529-f363a0dda67b" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%205.png"><img style="width:624px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%205.png"/></a><figcaption>Table 5 Initializing the global transformer model of BLT from the non-embedding parameters of Llama 3 improves performance on several benchmark tasks. First three models trained on the Llama 2 data for compute-optimal steps.</figcaption></figure><p id="1689e7a6-7f26-8173-8f87-f054f3602d67" class=""><mark class="highlight-red"><mark class="highlight-red_background">This setup can also be viewed as transforming tokenizer-based models into tokenizer-free ones, effectively converting a pre-trained LLaMA 3.1 model into a BLT model. </mark></mark>To provide a comprehensive comparison, we include the original LLaMA 3.1 model trained on 15T tokens in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 5 </a>and evaluate it against the BLT derived from LLaMA 3. <mark class="highlight-red"><mark class="highlight-red_background"><strong><span style="border-bottom:0.05em solid">Our model experiences a slight performance decline on MMLU and HumanEval, but a more significant drop on other tasks. This suggests that further work is needed to fully leverage the pre-trained model and improve upon its performance, particularly in terms of optimizing data mixtures and other hyperparameters.</span></strong></mark></mark></p><h2 id="1689e7a6-7f26-818f-8524-dc8e7d272bbb" class="">7 Ablations and Discussion</h2><p id="1689e7a6-7f26-812b-96bb-df44f2ce5d0e" class="">In this section, we discuss ablations justifying architectural choices for BLT and the patching scheme and hyper-parameters for the BLT 8B parameter model trained on the BLT-1T dataset.</p><figure id="1689e7a6-7f26-81c7-a565-c8e398ec84a0" class="image" style="text-align:center"><a href="https://arxiv.org/html/2412.09871v1/x8.png"><img style="width:672px" src="https://arxiv.org/html/2412.09871v1/x8.png"/></a><figcaption>Figure 8 Variation of language modeling performance in bits-per-byte (bpb) with training flops for 400m and 1b BLT models patched with entropy models of different sizes and context windows. Both dimensions improve scaling performance, with diminishing returns beyond 50m parameter entropy models with a context of 512 bytes.</figcaption></figure><h3 id="1689e7a6-7f26-81ca-90f3-c8f07dfd240b" class="">Entropy Model Hyper-parameters</h3><p id="1689e7a6-7f26-81c1-8594-e3502d6c6a6d" class="">To study the effect of varying entropy model size and context window length on scaling performance, we train byte-level entropy transformer models of different model sizes between 1m and 100m parameters, with varying context window lengths from 64 to 512. We plot bpb vs training flop scaling law curves, created using our 400⁢m and 1⁢b BLT models trained on the Llama-2 dataset and present them in <a href="https://arxiv.org/html/2412.09871v1#S7.F8">Figure 8</a>. We find that scaling performance is positively correlated with both these dimensions of the entropy model, with diminishing returns when we scale beyond 50m parameters.</p><h3 id="1689e7a6-7f26-819c-b953-ddc896c20bdf" class="">Types of Patching</h3><p id="1689e7a6-7f26-81fb-b60b-d0ee3e102cc5" class="">We ablate the four different patching schemes, introduced in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Section 2</a> i.e. </p><p id="1729e7a6-7f26-8075-a905-c38c3e246eab" class="">1) Strided Patching with a stride of 4 and 6, </p><p id="1729e7a6-7f26-80b6-9a83-efebcc3276ca" class="">2) Patching on whitepsace, </p><p id="1729e7a6-7f26-8053-b150-fbc732bb430a" class="">3) BPE Tokenizer patching based on the Llama 3 tokenizer, and </p><p id="1729e7a6-7f26-8072-b208-d82d2c6ad5fe" class="">4) Entropy based patching using a small byte llm.</p><p id="1689e7a6-7f26-8184-84ef-d83c14eb2807" class="">While dynamic patching reduces the effective length of sequences, we control for the sequence length to maintain a similar context length for all patching schemes. All the models see the same number of bytes in each sequence during training and inference in expectation to prevent any confounding factors from being able to model larger contexts. <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Figure 6</a> highlights the results of these ablations. All the remaining patching schemes outperform static patching, with space patching being a very close competitor to dynamic entropy based patching.</p><p id="1689e7a6-7f26-819b-937b-caf33393f3ef" class="">In <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 6,</a> we present benchmark evaluations for BLT models comparing tokenizer-based models, space patching, and entropy-based patching, trained on the Llama 2 dataset for an optimal number of steps (Dubey et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>). Although space patching is a simpler strategy that does not involve running an entropy model on the fly during training, we find that the gains we observed using entropy-based patching on scaling trends (<a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Section 5</a>) do indeed carry forward even to downstream benchmark tasks.7</p><figure id="1729e7a6-7f26-80ee-a384-ddece6a9c5e2" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%206.png"><img style="width:480px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%206.png"/></a><figcaption>Table 6 Benchmark evaluations of two patching schemes for 8b BLT models and BPE Llama3 baseline. These models are trained on the Llama 2 data for the optimal number of steps as determined by Dubey et al. (2024).</figcaption></figure><h3 id="1689e7a6-7f26-81a9-853b-e1f29b51dc0b" class="">Cross-Attention</h3><p id="1689e7a6-7f26-810e-9ac9-f1c758ea2462" class="">In <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 7,</a> we ablate including cross-attention at various points in the encoder and decoder of BLT. For the encoder cross-attention we test initializing the queries with </p><p id="1729e7a6-7f26-8017-ac2e-e092f65eefbe" class="">1) the same learned embedding for every global state, </p><p id="1729e7a6-7f26-8094-b8cc-d3c5f54dc9a8" class="">2) a hash embedding of the bytes in the patch, and </p><p id="1729e7a6-7f26-801d-b563-d51991123b8c" class="">3) pooling of the encoder hidden representation of the patch bytes at the given encoder layer.</p><figure id="1729e7a6-7f26-80fb-a890-de44a9af626a" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%207.png"><img style="width:672px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%207.png"/></a><figcaption>Table 7 Ablations on the use of Cross Attention for a 1B BLT model trained on 100B bytes. We report bits-per-byte (bpb) on different datasets. We also report bpb on a random sample of the training data (denoted as Train Dist.) The Cross Attn. Enc. and Dec. columns denote which transformer layers the cross-attention block is applied after (or before for the decoder) in the local encoder and decoder respectively.</figcaption></figure><p id="1689e7a6-7f26-815f-ac5f-e516a61acdb8" class="">We find that using cross-attention in the decoder is most effective. In the encoder, there is a slight improvement in using cross-attention but only with pooling initialization of queries. Additionally, we find that cross-attention helps particularly on Common-Crawl and especially with larger patch sizes.</p><h3 id="1689e7a6-7f26-8175-bb78-ca82859b4583" class="">n-gram Hash Embeddings</h3><p id="1689e7a6-7f26-81d6-9b10-c785978a2f7c" class="">We ablate settings of 0, 100K, 200K and 400K n-gram hash embedding vocabularies and present results in <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">Table 8</a>. We find that hash embeddings help on all domains, but particularly on Wikipedia and Github (0.04 bpb difference compared to 0.01 bpb difference after 15k steps at 8B). At 8B scale going from 500K to 300K hashes changed performance by 0.001 bpb on 15k steps. This indicates that hashes are vital to bringing the performance of BLT to match those of tokenizer based models, however, after 300K hashes, there are diminishing returns. Additionally, it appears that the gains are largely complementary with cross-attention as they provide improvements on different datasets.</p><figure id="1729e7a6-7f26-808a-906f-cb9a3c7de745" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%208.png"><img style="width:672px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%208.png"/></a><figcaption>Table 8 Ablations on the use of n-gram hash embedding tables for a 1B BLT model trained on 100B bytes. We find that hash n-gram embeddings are very effective with very large improvements in BPB. The most significant parameter is the per-ngram vocab size and that smaller ngram sizes are more impactful than larger ones.</figcaption></figure><h3 id="1689e7a6-7f26-81ad-8d03-eea5ec2ca756" class="">Local Model Hyperparamaters</h3><p id="1689e7a6-7f26-81e0-8052-f2e4ef322d06" class=""><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">In Table 9</a>, we ablate various settings for the number of layers in the local encoder and decoder. When paired with hash n-gram embeddings, <mark class="highlight-red"><mark class="highlight-red_background"><strong>BLT works well with an encoder that is extremely light-weight i.e. just one layer, and with a heavier decoder.</strong></mark></mark></p><figure id="1729e7a6-7f26-805c-97e0-fae8e21025a5" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%209.png"><img style="width:672px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%209.png"/></a><figcaption>Table 9 When paired with hash n-gram embeddings, a light-weight local encoder is sufficient. More layers can then be allocated to the decoder for the same cost.</figcaption></figure><h2 id="1689e7a6-7f26-812c-9ab4-fac04058f219" class="">8 Related Work</h2><p id="1689e7a6-7f26-813d-8201-c4a0cd0ade42" class=""><strong>Character-Level RNNs: </strong></p><p id="1729e7a6-7f26-8058-b4f3-e63646fe60d7" class="">Character Language Modeling has been a popular task ever since the early days of neural models (Sutskever et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib41">2011</a>; Mikolov et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib32">2012</a>; Graves, <a href="https://arxiv.org/html/2412.09871v1#bib.bib18">2013</a>) owing to their flexibility of modeling out of vocabulary words organically without resorting to back-off methods. Kim et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib26">2016</a>) also train a model that processes characters only on the input side using convolutional and highway networks that feed into LSTM-based RNNs and are able to match performance with the RNN based state-of-the-art language models of the time on English and outperform them on morphologically rich languages, another sought-after advantage of character-level LLMs. Kenter et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib25">2018</a>) do machine comprehension using byte-level LSTM models that outperformed word-level models again on morphologically-rich Turkish and Russian languages. Along similar lines, Zhang et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib51">2015</a>) used character-based convolutional models for classification tasks, which outperformed word-level models for certain tasks. Chung et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib8">2019</a>) use hierarchical LSTM models using boundary-detectors at each level to discover the latent hierarchy in text, to further improve performance on character level language modeling. ByteNet by Kalchbrenner et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib23">2016</a>) uses CNN based layers on characters as opposed to attention for machine translation.</p><p id="1689e7a6-7f26-81ee-86ad-c07bacf0aadc" class=""><strong>Character-Level Transformers: </strong></p><p id="1729e7a6-7f26-8006-b92f-d7c6d99c03dd" class="">The development of transformer models using attention (Vaswani et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib44">2017</a>) together with subword tokenization (Sennrich et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib37">2016</a>), significantly improved the performance of neural models on language modeling and benchmark tasks. However, word and sub-word units implicitly define an inductive bias for the level of abstraction models should operate on. To combine the successes of transformer models with the initial promising results on character language modeling, Al-Rfou et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib1">2019</a>) use very deep transformers, and with the help of auxiliary losses, train transformer-based models that outperformed previous LSTM based character llms. However, they still saw a significant gap from word level LLMs. GPT-2 (Radford et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib36">2019</a>) also observed that on large scale datasets like the 1 billion word benchmark, byte-level LMs were not competitive with word-level LMs.</p><p id="1689e7a6-7f26-816d-97c4-d03f11bebb44" class="">While Choe et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib7">2019</a>) demonstrated that byte-level llms based on transformers can outperform subword level LLMs with comparable parameters, the models take up much more compute and take much longer to train. Similarly, El Boukkouri et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib15">2020</a>) train a BERT model (CharFormer) that builds word representations by applying convolutions on character embeddings, and demonstrate improvements on the medical domain, but they also expend much more compute in doing so. Clark et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib9">2022</a>) develop CANINE, a 150M parameter encoder-only model that operates directly on character sequences. CANINE uses a deep transformer stack at its core similar in spirit to our global model, and a combination of a local transformer and strided convolutions to downsample the input characters, and outperforms the equivalent token-level encoder-only model (mBERT) on downstream multilingual tasks. ByT5 (Xue et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib47">2022</a>) explored approaches for byte-level encoder decoder models, that do not use any kind of patching operations. While their model exhibited improved robustness to noise, and was competitive with tokenizer-based models with 4x less data, the lack of patching meant that the models needed to compute expensive attention operations over every byte, which was extremely compute heavy. Directly modeling bytes instead of subword units increases the sequence length of the input making it challenging to efficiently scale byte level models. Recently, using the Mamba Architecture (Gu and Dao, <a href="https://arxiv.org/html/2412.09871v1#bib.bib19">2023</a>), which can maintain a fixed-size memory state over a very large context length, Wang et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib45">2024</a>) train a byte-level Mamba architecture also without using patching, and are able to outperform byte-level transformer models in a flop controlled setting at the 350M parameter scale in terms of bits-per-byte on several datasets.</p><p id="1689e7a6-7f26-818d-826e-f55a55e8dc3e" class=""><strong>Patching-based approaches: </strong></p><p id="1729e7a6-7f26-80ea-9436-f2490ccd92ee" class="">The effective use of patching can bring down the otherwise inflated number of flops expended by byte-level LLMs while potentially retaining performance, and many works demonstrated initial successes at a small scale of model size and number of training bytes. Nawrot et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib33">2022</a>) experiment with static patching based downsampling and upsampling and develop the hourglass transformer which outperforms other byte-level baselines at the 150M scale. Nawrot et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib34">2023</a>) further improve this with the help of dynamic patching schemes, including a boundary-predictor that is learned in an end-to-end fashion, a boundary-predictor supervised using certain tokenizers, as well as an entropy-based patching model similar to BLT, and show that this approach can outperform the vanilla transformers of the time on language modeling tasks at a 40M parameter scale on 400M tokens. Lester et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib27">2024</a>) investigate training on sequences compressed using arithmetic coding to achieve compression rates beyond what BPE can achieve, and by using a equal-info windows technique, are able to outperform byte-level baselines on language modeling tasks, but underperform subword baselines.</p><p id="1689e7a6-7f26-8148-af7c-c5d385583dfd" class="">Our work draws inspiration and is most closely related to MegaByte (Yu et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib48">2023</a>), which is a decoder only causal LLM that uses a fixed static patching and concatenation of representations to convert bytes to patches, and uses a local model on the decoder side to convert from patches back into bytes. They demonstrate that MegaByte can match tokenizer-based models at a 1B parameter scale on a dataset of 400B bytes. We ablate MegaByte in all our experiments and find that static patching lags behind the current state-of-the-art compute optimally trained tokenizer based models in a flop controlled setting and we demonstrate how BLT bridges this gap. Slagle (<a href="https://arxiv.org/html/2412.09871v1#bib.bib39">2024</a>) make the same observation about MegaByte and suggest extending the static patching method to patching on whitespaces and other space-like bytes, and also add a local encoder model. They find improvements over tokenized-based transformer models in a compute controlled setting on some domains such as Github and arXiv at the 1B parameter scale. We also report experiments with this model, and show that further architectural improvements are needed to scale up byte-level models even further and truly match current state-of-the-art token-based models such as Llama 3.</p><h2 id="1689e7a6-7f26-811e-bc33-e63b0ade73f6" class="">9 Limitations and Future Work</h2><p id="1689e7a6-7f26-8182-9d5c-c0e42d4591eb" class="">In this work, for the purposes of architectural choices, we train models for the optimal number of steps as determined for Llama 3 (Dubey et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>). However, these scaling laws were calculated for BPE-level transformers and may lead to suboptimal (data, parameter sizes) ratios in the case of BLT. We leave for future work the calculation of scaling laws for BLT potentially leading to even more favorable scaling trends for our architecture. Additionally, many of these experiments were conducted at scales upto 1B parameters, and it is possible for the optimal architectural choices to change as we scale to 8B parameters and beyond, which may unlock improved performance for larger scales.</p><p id="1689e7a6-7f26-81e1-9a32-ce8efdbaae19" class="">Existing transformer libraries and codebases are designed to be highly efficient for tokenizer-based transformer architectures. While we present theoretical flop matched experiments and also use certain efficient implementations (such as FlexAttention) to handle layers that deviate from the vanilla transformer architecture, our implementations may yet not be at parity with tokenizer-based models in terms of wall-clock time and may benefit from further optimizations.</p><p id="1689e7a6-7f26-81ab-8f0f-f91b9b401146" class="">While BLT uses a separately trained entropy model for patching, learning the patching model in an end-to-end fashion can be an interesting direction for future work. In Section <a href="https://arxiv.org/html/2412.09871v1#S6.SS2">6.2</a>, we present initial experiments showing indications of success for “byte-ifying” tokenizer-based models such as Llama 3 that are trained on more than 10T tokens, by initializing and freezing the global transformer with their weights. Further work in this direction may uncover methods that not only retain the benefits of bytefying, but also push performance beyond that of these tokenizer-based models without training them from scratch.</p><h2 id="1689e7a6-7f26-8157-a086-e28c0f7aa159" class="">10 Conclusion</h2><p id="1689e7a6-7f26-810e-a032-f46d872490c4" class="">This paper presents the Byte Latent Transformer (BLT), a new architecture that redefines the conventional dependency on fixed-vocabulary tokenization in large language models. By introducing a dynamic, learnable method for grouping bytes into patches, BLT effectively allocates computational resources based on data complexity, leading to significant improvements in both efficiency and robustness. Our extensive scaling study demonstrates that BLT models can match the performance of tokenization-based models like Llama 3 at scales up to 8B and 4T bytes, and can trade minor losses in evaluation metrics for up to 50% reductions in inference flops. Furthermore, BLT unlocks a new dimension for scaling, allowing simultaneous increases in model and patch size within a fixed inference budget. This new paradigm becomes advantageous for compute regimes commonly encountered in practical settings. While directly engaging with raw byte data, BLT also improves the model’s ability to handle the long-tail of data, offering significant improvements in robustness to noisy inputs and a deeper understanding of sub-word structures. Overall, these results position BLT as a promising alternative to traditional tokenization-based approaches, providing a scalable and robust framework for more efficient and adaptable language models.</p><h2 id="1689e7a6-7f26-81c7-92a6-c63ff11a1a9e" class="">Acknowledgements</h2><p id="1689e7a6-7f26-81a5-99b1-cb2708881c69" class="">We would like to thank Kalyan Saladi for help with everything relating to pre-training infrastructure; Gabriel Synnaeve, Ammar Rizvi, Jacob Kahn, Michel Meyer for helping organize resources for scaling up BLT; Badr Youbi Idirissi, Mathurin Videau, and Jade Copet for invaluable discussions and feedback about BLT, for access to the Lingua framework for open-sourcing code for BLT, and for help preparing the BLT-1T dataset used in this paper; Omer Levy, who was actively involved in the early stages of the project and provided valuable feedback and ideas; Driss Guessous for help with FlexAttention; and Sida Wang, Melanie Sclar, Amanda Bertsch, and Hunter Lang for feedback and discussions.</p><h2 id="1689e7a6-7f26-81a6-82b4-ee25d843d218" class="">Contributors</h2><p id="1689e7a6-7f26-81f8-bd6c-f473a59bcadf" class="">In this section, we list individual contributions.</p><h3 id="1689e7a6-7f26-8109-8266-d10de7eb1a32" class="">Core Contributors:</h3><p id="1689e7a6-7f26-814a-9d03-c50e42b5f4e3" class="">Artidoro Pagnoni, Srinivasan Iyer, Ramakanth Pasunuru, Pedro Rodriguez, John Nguyen, Gargi Ghosh (Project Lead)</p><h3 id="1689e7a6-7f26-81f6-bf30-f9fc82ec7300" class="">Core Advising Group:</h3><p id="1689e7a6-7f26-818a-9f8c-f8a2e995d753" class="">Mike Lewis, Ari Holtzman, Luke Zettlemoyer</p><h3 id="1689e7a6-7f26-81b6-b8c1-e652de631ea6" class="">Advisors and Contributors:</h3><p id="1689e7a6-7f26-81c5-8030-e8f132bf9d83" class="">Jason Weston, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu</p><h2 id="1689e7a6-7f26-8144-ad46-e2c7c386edbb" class="">References</h2><ul id="1689e7a6-7f26-8113-9f33-feb067266272" class="bulleted-list"><li style="list-style-type:disc">Al-Rfou et al. (2019) Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, and Llion Jones. Character-level language modeling with deeper self-attention. In <em>Association for the Advancement of Artificial Intelligence</em>, volume 33, pages 3159–3166, 2019.</li></ul><ul id="1689e7a6-7f26-818b-9c42-ca0d29141370" class="bulleted-list"><li style="list-style-type:disc">Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language models, 2021.</li></ul><ul id="1689e7a6-7f26-8185-aaee-dde010f1cb13" class="bulleted-list"><li style="list-style-type:disc">Bai et al. (2010) Bing Bai, Jason Weston, David Grangier, Ronan Collobert, Kunihiko Sadamasa, Yanjun Qi, Olivier Chapelle, and Kilian Weinberger. Learning to rank with (a lot of) word features. <em>Information retrieval</em>, 13:291–314, 2010.</li></ul><ul id="1689e7a6-7f26-8153-b52b-e65c0aa42d80" class="bulleted-list"><li style="list-style-type:disc">Bisk et al. (2020) Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense in natural language. In <em>Association for the Advancement of Artificial Intelligence</em>, pages 7432–7439, 2020.</li></ul><ul id="1689e7a6-7f26-81ba-b7a8-f4290013d2f9" class="bulleted-list"><li style="list-style-type:disc">Casson (2023) Adam Casson. Transformer flops, 2023. <a href="https://www.adamcasson.com/posts/transformer-flops">https://www.adamcasson.com/posts/transformer-flops</a>.</li></ul><ul id="1689e7a6-7f26-8166-915b-db701a1d67cc" class="bulleted-list"><li style="list-style-type:disc">Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code, 2021.</li></ul><ul id="1689e7a6-7f26-81c4-a4f7-c8b316e61c75" class="bulleted-list"><li style="list-style-type:disc">Choe et al. (2019) Dokook Choe, Rami Al-Rfou, Mandy Guo, Heeyoung Lee, and Noah Constant. Bridging the gap for tokenizer-free language models. <em>arXiv</em>, abs/1908.10322, 2019.</li></ul><ul id="1689e7a6-7f26-81ec-af8a-ffbcad3eb156" class="bulleted-list"><li style="list-style-type:disc">Chung et al. (2019) Junyoung Chung, Sungjin Ahn, and Yoshua Bengio. Hierarchical multiscale recurrent neural networks. In <em>Proceedings of the International Conference on Learning Representations</em>, 2019.</li></ul><ul id="1689e7a6-7f26-810c-8c03-cd927aef731e" class="bulleted-list"><li style="list-style-type:disc">Clark et al. (2022) Jonathan H Clark, Dan Garrette, Iulia Turc, and John Wieting. Canine: Pre-training an efficient tokenization-free encoder for language representation. <em>Transactions of the Association for Computational Linguistics</em>, 10:73–91, 2022.</li></ul><ul id="1689e7a6-7f26-8133-9375-e6aaffa40a5a" class="bulleted-list"><li style="list-style-type:disc">Clark et al. (2018) Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? Try ARC, the AI2 reasoning challenge. <em>arXiv</em>, 2018.</li></ul><ul id="1689e7a6-7f26-8154-8bf3-ca6c25b5e214" class="bulleted-list"><li style="list-style-type:disc">Dagan et al. (2024) Gautier Dagan, Gabriel Synnaeve, and Baptiste Roziere. Getting the most out of your tokenizer for pre-training and domain adaptation. In <em>Forty-first International Conference on Machine Learning</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81f3-adbc-d26f7c429078" class="bulleted-list"><li style="list-style-type:disc">Dao et al. (2022) Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. FlashAttention: Fast and memory-efficient exact attention with io-awareness. <em>Proceedings of Advances in Neural Information Processing Systems</em>, 35, 2022.</li></ul><ul id="1689e7a6-7f26-8160-b2b6-c0e1ea22bdda" class="bulleted-list"><li style="list-style-type:disc">Dubey et al. (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81b2-a70b-ef9a52a84553" class="bulleted-list"><li style="list-style-type:disc">Edman et al. (2024) Lukas Edman, Helmut Schmid, and Alexander Fraser. CUTE: Measuring llms’ understanding of their tokens. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-8128-8f75-eb2ff35001a7" class="bulleted-list"><li style="list-style-type:disc">El Boukkouri et al. (2020) Hicham El Boukkouri, Olivier Ferret, Thomas Lavergne, Hiroshi Noji, Pierre Zweigenbaum, and Jun’ichi Tsujii. CharacterBERT: Reconciling elmo and bert for word-level open-vocabulary representations from characters. In <em>Proceedings of International Conference on Computational Linguistics</em>, 2020.</li></ul><ul id="1689e7a6-7f26-8115-acec-d3010398daac" class="bulleted-list"><li style="list-style-type:disc">Gage (1994) Philip Gage. A new algorithm for data compression. <em>The C Users Journal</em>, 12(2):23–38, 1994.</li></ul><ul id="1689e7a6-7f26-81ba-9955-ce0ef16a737a" class="bulleted-list"><li style="list-style-type:disc">Goyal et al. (2022) Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán, and Angela Fan. The Flores-101 evaluation benchmark for low-resource and multilingual machine translation. <em>Transactions of the Association for Computational Linguistics</em>, 10:522–538, 2022. <a href="https://doi.org/10.1162/tacl_a_00474">10.1162/tacl_a_00474</a>. <a href="https://aclanthology.org/2022.tacl-1.30">https://aclanthology.org/2022.tacl-1.30</a>.</li></ul><ul id="1689e7a6-7f26-81c3-9f22-c8d41a78762e" class="bulleted-list"><li style="list-style-type:disc">Graves (2013) Alex Graves. Generating sequences with recurrent neural networks. <em>arXiv</em>, 2013.</li></ul><ul id="1689e7a6-7f26-8163-a1c1-dd788da2e7fb" class="bulleted-list"><li style="list-style-type:disc">Gu and Dao (2023) Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state spaces. <em>arXiv</em>, 2023.</li></ul><ul id="1689e7a6-7f26-81d4-a3f5-d9b3e620b2e8" class="bulleted-list"><li style="list-style-type:disc">Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. In <em>Proceedings of the International Conference on Learning Representations</em>, 2020.</li></ul><ul id="1689e7a6-7f26-8150-b8bc-c4a434d10f91" class="bulleted-list"><li style="list-style-type:disc">Hoffmann et al. (2022) Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. In <em>Proceedings of Advances in Neural Information Processing Systems</em>, 2022.</li></ul><ul id="1689e7a6-7f26-8124-80db-ff05d1b90f19" class="bulleted-list"><li style="list-style-type:disc">Jaegle et al. (2021) Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and Joao Carreira. Perceiver: General perception with iterative attention. In <em>Proceedings of the International Conference of Machine Learning</em>. PMLR, 2021.</li></ul><ul id="1689e7a6-7f26-816c-b923-eabc4c5d0d40" class="bulleted-list"><li style="list-style-type:disc">Kalchbrenner et al. (2016) Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aäron van den Oord, Alexander Graves, and Koray Kavukcuoglu. Neural machine translation in linear time. <em>arXiv</em>, 2016.</li></ul><ul id="1689e7a6-7f26-810d-84e8-dd1cd54be839" class="bulleted-list"><li style="list-style-type:disc">Kaplan et al. (2020) Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. <em>arXiv</em>, 2020.</li></ul><ul id="1689e7a6-7f26-816e-bd2c-c9f3af446eb2" class="bulleted-list"><li style="list-style-type:disc">Kenter et al. (2018) Tom Kenter, Llion Jones, and Daniel Hewlett. Byte-level machine reading across morphologically varied languages. In <em>Association for the Advancement of Artificial Intelligence</em>, 2018.</li></ul><ul id="1689e7a6-7f26-811b-b02f-f32adf772106" class="bulleted-list"><li style="list-style-type:disc">Kim et al. (2016) Yoon Kim, Yacine Jernite, David Sontag, and Alexander Rush. Character-aware neural language models. In <em>Association for the Advancement of Artificial Intelligence</em>, 2016.</li></ul><ul id="1689e7a6-7f26-81e9-96cb-e031149a2ed8" class="bulleted-list"><li style="list-style-type:disc">Lester et al. (2024) Brian Lester, Jaehoon Lee, Alex Alemi, Jeffrey Pennington, Adam Roberts, Jascha Sohl-Dickstein, and Noah Constant. Training llms over neurally compressed text. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-815a-9796-f9f526450e90" class="bulleted-list"><li style="list-style-type:disc">Li et al. (2024) Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, et al. Datacomp-lm: In search of the next generation of training sets for language models. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81ce-ac80-f8ea7e685986" class="bulleted-list"><li style="list-style-type:disc">Liang et al. (2023) Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, and Madian Khabsa. Xlm-v: Overcoming the vocabulary bottleneck in multilingual masked language models. In <em>Proceedings of Empirical Methods in Natural Language Processing</em>, 2023.</li></ul><ul id="1689e7a6-7f26-81d6-b7da-e37af0536b47" class="bulleted-list"><li style="list-style-type:disc">Limisiewicz et al. (2024) Tomasz Limisiewicz, Terra Blevins, Hila Gonen, Orevaoghene Ahia, and Luke Zettlemoyer. Myte: Morphology-driven byte encoding for better and fairer multilingual language modeling. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81a6-b6d1-e2ddf3e8491a" class="bulleted-list"><li style="list-style-type:disc">Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. <em>arXiv</em>, 2017.</li></ul><ul id="1689e7a6-7f26-8190-b5e6-ca981ea64806" class="bulleted-list"><li style="list-style-type:disc">Mikolov et al. (2012) Tomáš Mikolov, Ilya Sutskever, Anoop Deoras, Hai-Son Le, Stefan Kombrink, and Jan Cernocky. Subword language modeling with neural networks. <em>preprint (http://www. fit. vutbr. cz/imikolov/rnnlm/char. pdf)</em>, 8(67), 2012.</li></ul><ul id="1689e7a6-7f26-8131-9904-cdf0d8d4ce5e" class="bulleted-list"><li style="list-style-type:disc">Nawrot et al. (2022) Piotr Nawrot, Szymon Tworkowski, Michał Tyrolski, Lukasz Kaiser, Yuhuai Wu, Christian Szegedy, and Henryk Michalewski. Hierarchical transformers are more efficient language models. In <em>Conference of the North American Chapter of the Association for Computational Linguistics</em>. Association for Computational Linguistics, 2022.</li></ul><ul id="1689e7a6-7f26-813d-b55b-ca6740392d8e" class="bulleted-list"><li style="list-style-type:disc">Nawrot et al. (2023) Piotr Nawrot, Jan Chorowski, Adrian Lancucki, and Edoardo Maria Ponti. Efficient transformers with dynamic token pooling. In <em>Proceedings of the Association for Computational Linguistics</em>. Association for Computational Linguistics, 2023.</li></ul><ul id="1689e7a6-7f26-81fc-a572-d64c74e008cb" class="bulleted-list"><li style="list-style-type:disc">Petrov et al. (2024) Aleksandar Petrov, Emanuele La Malfa, Philip Torr, and Adel Bibi. Language model tokenizers introduce unfairness between languages. <em>Proceedings of Advances in Neural Information Processing Systems</em>, 2024.</li></ul><ul id="1689e7a6-7f26-8122-8468-ddbcb979d5fd" class="bulleted-list"><li style="list-style-type:disc">Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. <em>OpenAI blog</em>, 1(8):9, 2019.</li></ul><ul id="1689e7a6-7f26-8187-b73d-d675b8a1dee4" class="bulleted-list"><li style="list-style-type:disc">Sennrich et al. (2016) Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In <em>Proceedings of the Association for Computational Linguistics</em>. Association for Computational Linguistics, 2016.</li></ul><ul id="1689e7a6-7f26-81d5-b677-e5f4e6afe732" class="bulleted-list"><li style="list-style-type:disc">Shazeer (2020) Noam Shazeer. GLU variants improve transformer. <em>arXiv</em>, 2020.</li></ul><ul id="1689e7a6-7f26-8149-a8c5-dcec7cb0e71b" class="bulleted-list"><li style="list-style-type:disc">Slagle (2024) Kevin Slagle. Spacebyte: Towards deleting tokenization from large language modeling. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-8157-9da7-d416b733eca8" class="bulleted-list"><li style="list-style-type:disc">Su et al. (2021) Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. RoFormer: Enhanced transformer with rotary position embedding. arxiv e-prints, art. <em>arXiv</em>, 2021.</li></ul><ul id="1689e7a6-7f26-815c-b787-da7947b6b60a" class="bulleted-list"><li style="list-style-type:disc">Sutskever et al. (2011) Ilya Sutskever, James Martens, and Geoffrey E Hinton. Generating text with recurrent neural networks. In <em>Proceedings of the International Conference of Machine Learning</em>, pages 1017–1024, 2011.</li></ul><ul id="1689e7a6-7f26-8122-97c3-f645b7c43531" class="bulleted-list"><li style="list-style-type:disc">Suvarna et al. (2024) Ashima Suvarna, Harshita Khandelwal, and Nanyun Peng. Phonologybench: Evaluating phonological skills of large language models. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81f6-b67d-c358e5ea20fc" class="bulleted-list"><li style="list-style-type:disc">Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. <em>arXiv</em>, 2023.</li></ul><ul id="1689e7a6-7f26-813e-972f-c3e0267c2290" class="bulleted-list"><li style="list-style-type:disc">Vaswani et al. (2017) Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In <em>Neural Information Processing Systems</em>, 2017.</li></ul><ul id="1689e7a6-7f26-8144-8a3e-e94e13673d81" class="bulleted-list"><li style="list-style-type:disc">Wang et al. (2024) Junxiong Wang, Tushaar Gangavarapu, Jing Nathan Yan, and Alexander M Rush. Mambabyte: Token-free selective state space model. <em>arXiv</em>, 2024.</li></ul><ul id="1689e7a6-7f26-8158-9cf4-fb6b843b5c1a" class="bulleted-list"><li style="list-style-type:disc">Xiong et al. (2024) Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui Hou, Louis Martin, Rashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, et al. Effective long-context scaling of foundation models. In <em>Conference of the North American Chapter of the Association for Computational Linguistics</em>, 2024.</li></ul><ul id="1689e7a6-7f26-81e9-95c0-cf8381e4449f" class="bulleted-list"><li style="list-style-type:disc">Xue et al. (2022) Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. Byt5: Towards a token-free future with pre-trained byte-to-byte models. <em>Transactions of the Association for Computational Linguistics</em>, 10:291–306, 2022.</li></ul><ul id="1689e7a6-7f26-8116-9145-f3553e1c53f7" class="bulleted-list"><li style="list-style-type:disc">Yu et al. (2023) Lili Yu, Dániel Simig, Colin Flaherty, Armen Aghajanyan, Luke Zettlemoyer, and Mike Lewis. Megabyte: Predicting million-byte sequences with multiscale transformers. <em>Proceedings of Advances in Neural Information Processing Systems</em>, 2023.</li></ul><ul id="1689e7a6-7f26-8166-99d6-d24cd950a0c8" class="bulleted-list"><li style="list-style-type:disc">Zellers et al. (2019) Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a machine really finish your sentence? <em>arXiv</em>, 2019.</li></ul><ul id="1689e7a6-7f26-81aa-9c87-f9c2db1c3c2f" class="bulleted-list"><li style="list-style-type:disc">Zhang and Sennrich (2019) Biao Zhang and Rico Sennrich. Root mean square layer normalization. <em>Proceedings of Advances in Neural Information Processing Systems</em>, 32, 2019.</li></ul><ul id="1689e7a6-7f26-8156-a622-fc54bea894c2" class="bulleted-list"><li style="list-style-type:disc">Zhang et al. (2015) Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, <em>Proceedings of Advances in Neural Information Processing Systems</em>, volume 28. Curran Associates, Inc., 2015. <a href="https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf</a>.</li></ul><p id="1689e7a6-7f26-81c7-be30-d3b5507df729" class="">\beginappendix</p><h2 id="1689e7a6-7f26-81ce-9848-ef15317f3404" class="">11 Model Hyper Parameters</h2><p id="1689e7a6-7f26-81aa-b409-e7049aad78e4" class="">Table <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">10</a> shows different hyper parameter settings for BLT models.</p><figure id="1729e7a6-7f26-80b6-9890-dd3ee678769d" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%2010.png"><img style="width:857.9861450195312px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%2010.png"/></a><figcaption>Table 10 Architectural hyper-parameters for different BLT model sizes that we train for flop-controlled experiments described in this paper.</figcaption></figure><h2 id="1689e7a6-7f26-812c-af30-de976a0ef460" class="">12 FLOPs Equations</h2><p id="1689e7a6-7f26-81d1-9277-cef9ebce1163" class="">Here, we provide the equations used for flop computation for the forward-pass of transformer and BLT models based on Hoffmann et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib21">2022</a>); Kaplan et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib24">2020</a>); Casson (<a href="https://arxiv.org/html/2412.09871v1#bib.bib5">2023</a>). We assume that the backward pass uses twice as much flops as the forward pass.</p><figure id="1729e7a6-7f26-80fc-b801-cdd3599f9a80" class="image"><a href="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%2011.png"><img style="width:672px" src="../../../../../../Downloads/3a7bf723-52b7-428e-ae03-b93298716179_Export-7777e3d6-e75b-4e9f-bc1a-b77c8b325aa3/Byte%20Latent%20Transformer%20Patches%20Scale%20Better%20Than%20%201689e7a67f2681d89c5de307f6b83e6a/image%2011.png"/></a><figcaption>Table 11 flops for operations used in transformer and BLT models. l corresponds to layers, h is the hidden dimension (h_k with n_{heads} heads), m is the context length, d_{f f} = 4 is the feed-forward dimension multiplier, p is the patch size, and r is the ratio of queries to keys.</figcaption></figure><p id="1689e7a6-7f26-81df-964e-c103110c732c" class="">For a transformer model with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span></span><span>﻿</span></span> layers, hidden dimension <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span></span><span>﻿</span></span>, context length <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mrow><mi>h</mi><mtext>⁢</mtext><mi>e</mi><mtext>⁢</mtext><mi>a</mi><mtext>⁢</mtext><mi>d</mi><mtext>⁢</mtext><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{h⁢e⁢a⁢d⁢s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">e</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">d</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> attention heads of dimension <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">h_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, and a feed-forward multipler of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>f</mi><mtext>⁢</mtext><mi>f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{f⁢f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mtight">⁢</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, we compute FLOPs as:</p><p id="1729e7a6-7f26-80d4-b4b5-efa6ff90b511" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">Transformer-FLOPs</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><msub><mi>n</mi><mtext>heads </mtext></msub><mo separator="true">,</mo><msub><mi>h</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo separator="true">,</mo><mi>V</mi><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">Feed-Forward</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo fence="true">)</mo></mrow><mtext>                </mtext><mrow><mo>…</mo><mtext> </mtext><mo>…</mo><mtext>(19)</mtext></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mi mathvariant="normal">QKVO</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>l</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>r</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mtext>                          </mtext><mrow><mo>…</mo><mtext> </mtext><mo>…</mo><mtext>(20)</mtext></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mi mathvariant="normal">Attention</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>l</mi><mo separator="true">,</mo><msub><mi>h</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>n</mi><mtext>heads </mtext></msub><mo separator="true">,</mo><mi>m</mi><mo fence="true">)</mo></mrow><mtext>            </mtext><mrow><mo>…</mo><mtext> </mtext><mo>…</mo><mtext>(21)</mtext></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>+</mo><mi mathvariant="normal">De-Embedding</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>h</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mtext>                     </mtext><mrow><mo>…</mo><mtext> </mtext><mo>…</mo><mtext>(22)</mtext></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\operatorname{Transformer-FLOPs}\left(l, h, m, n_{\text {heads }}, h_k, d_{ff}, V\right) &amp; =\operatorname{Feed-Forward}\left(l, h, d_{ff}\right) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{… …(19)} \\
&amp; +\operatorname{QKVO}(l, h, r=1)  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{… …(20)} \\
&amp; +\operatorname{Attention}\left(l, h_k, n_{\text {heads }}, m\right)  \ \ \ \ \ \ \ \ \ \ \ \ \text{… …(21)} \\
&amp; +\operatorname{De-Embedding}(h, V) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{… …(22)} 
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6em;vertical-align:-2.75em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.25em;"><span style="top:-5.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">Transformer-FLOPs</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">heads </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">ff</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-0.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.25em;"><span style="top:-5.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop"><span class="mord mathrm">Feed-Forward</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">ff</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">(19)</span></span></span></span><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">QKVO</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord text"><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">(20)</span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">Attention</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">heads </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">(21)</span></span></span></span><span style="top:-0.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">De-Embedding</span></span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord text"><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">(22)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75em;"><span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="1689e7a6-7f26-8175-8ebc-cd46290f6227" class="">For BLT models, we use the above-mentioned primitives together with the flops equation from Section <a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">4.5</a> to compute total flops.</p><h2 id="1689e7a6-7f26-8128-8820-c1b09d20063d" class="">13 Rolling Polynomial Hashing</h2><p id="1689e7a6-7f26-81a5-a8bc-f5ae6b507d99" class="">Given a byte n-gram gi,n={bi−n+1,…,bi}, the rolling polynomial hash of gi,n is defined as:</p><table id="1689e7a6-7f26-81f7-bb80-fc210f7946b0" class="simple-table"><tbody><tr id="1689e7a6-7f26-810b-bb11-eb39a2ea7a7c"><td id="`~HC" class=""></td><td id="tbn?" class="">Hash⁢(gi,n)</td><td id="OT|\" class="">=∑j=1nbi−j+1⁢aj−1</td><td id="yKI~" class=""></td><td id="U]mP" class="">(23)</td></tr></tbody></table><p id="1689e7a6-7f26-8139-ab0a-fac01b9cf1fa" class="">Where a is chosen to be a 10-digit prime number.</p><h2 id="1689e7a6-7f26-8168-a884-c9e69344a40c" class="">14 Frequency-based n-gram Embedddings</h2><p id="1689e7a6-7f26-81d1-87ec-ddf28acc015a" class="">Prior to using hash n-gram embeddings in the final BLT architecture, we also experimented with frequency-based n-gram embeddings. For each n∈{1,2,3,4,5,6,7,8} there is an embedding matrix Enn⁢g⁢r⁢a⁢m that contains the most frequent byte-grams for the given n. Since it is intractable to store embeddings as n grows, we only store embeddings for the most frequent 100,000 byte-grams for each byte-gram. If a particular position i includes an n-gram present in the corresponding the embedding matrix, then this embedding is passed to the next step, encoder multi-headed cross-attention. If a byte-gram is infrequent and therefore not in the matrix, then its embedding is obtained from encoder hash embeddings instead.</p><p id="1689e7a6-7f26-8113-9b7a-ecad4ce02862" class="">Since frequency-based n-grams are limited by the vocabulary of the n-gram tables with infrequent n-grams not being represented at all, we subsequently moved to hash-based n-gram embeddings. See <a href="https://arxiv.org/html/2412.09871v1#S14.T12">Table 12</a> for a comparison of hash and frequency based n-gram embeddings.</p><h2 id="1689e7a6-7f26-8107-aba9-e2c19be31a9d" class="">15 Entropy Patching Example from MMLU</h2><p id="1689e7a6-7f26-814e-9a49-dec647ff2ec7" class="">We illustrate how a few-shot example from a downstream task i.e. MMLU (Hendrycks et al., <a href="https://arxiv.org/html/2412.09871v1#bib.bib20">2020</a>), is patched using an entropy-model trained for use with BLT models in Figure <a href="https://arxiv.org/html/2412.09871v1#S15.F9">9</a>. Directly using the entropy model with the full-context window causes repetitive patterns to be heavily patched. For example, “10 times, with an rms deviation of about” in the MMLU query is patched frequently the first time it is encountered, but is part of very large patches the next three times, which, although inference efficient, maybe undesirable for reasoning. One method that we use to avoid such a “entropy” drift is by resetting the entropy context with new lines and using a approximate monotonicity constraint (see Section <a href="https://arxiv.org/html/2412.09871v1#S4.SS4">4.4</a>).</p><figure id="1689e7a6-7f26-81f5-81db-c3d8c5f41371" class="image"><a href="https://arxiv.org/html/2412.09871v1/extracted/6066458/assets/patching.png"><img style="width:912px" src="https://arxiv.org/html/2412.09871v1/extracted/6066458/assets/patching.png"/></a><figcaption>Figure 9 An example of default entropy-based patching with global threshold during inference on mmlu. Green denotes the prompt, Blue denotes the few-shot examples, and red denotes the question to be answered. Note that the size of the patches for the repeated phrases in the answer choices is much larger, which means that the global model is invoked significantly fewer times than its tokenizer-based counterpart, with this inference patching scheme.</figcaption></figure><p id="1719e7a6-7f26-8085-81f6-ea2b463eb290" class="">
</p><p id="1689e7a6-7f26-816a-80f2-c509b831c3d3" class="">Refer to caption</p><figure id="1699e7a6-7f26-8151-b2cd-cf38d37a0042" class="link-to-page"><a href="https://www.notion.so/Getting-the-most-out-of-your-tokenizer-for-pre-training-and-domain-adaptation-1699e7a67f268151b2cdcf38d37a0042?pvs=21">Getting the most out of your tokenizer for pre-training and domain adaptation</a></figure><figure id="1699e7a6-7f26-8073-bd0a-f94480e1f700" class="link-to-page"><a href="https://www.notion.so/CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation-1699e7a67f268073bd0af94480e1f700?pvs=21">CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation</a></figure><figure id="16d9e7a6-7f26-808a-ae0b-ff7c35574579" class="link-to-page"><a href="https://www.notion.so/MEGABYTE-Predicting-Million-byte-Sequences-with-Multiscale-Transformers-16d9e7a67f26808aae0bff7c35574579?pvs=21">MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers</a></figure><figure id="16d9e7a6-7f26-8138-9c8f-e3e12801d6b9" class="link-to-page"><a href="https://www.notion.so/SpaceByte-Towards-Deleting-Tokenization-from-Large-Language-Modeling-16d9e7a67f2681389c8fe3e12801d6b9?pvs=21">SpaceByte: Towards Deleting Tokenization from Large Language Modeling</a></figure><figure id="16d9e7a6-7f26-8055-86bd-feb7fcfd1145" class="link-to-page"><a href="https://www.notion.so/Efficient-Transformers-with-Dynamic-Token-Pooling-16d9e7a67f26805586bdfeb7fcfd1145?pvs=21">Efficient Transformers with Dynamic Token Pooling</a></figure><figure id="16d9e7a6-7f26-8120-92d4-fb144ce483b1" class="link-to-page"><a href="https://www.notion.so/SpaceByte-Towards-Deleting-Tokenization-from-Large-Language-Modeling-16d9e7a67f26812092d4fb144ce483b1?pvs=21">SpaceByte: Towards Deleting Tokenization from Large Language Modeling</a></figure><figure id="16f9e7a6-7f26-8009-960f-e28b425ff2e0" class="link-to-page"><a href="https://www.notion.so/Perceiver-General-Perception-with-Iterative-Attention-16f9e7a67f268009960fe28b425ff2e0?pvs=21">Perceiver: General Perception with Iterative Attention</a></figure></div></article><span class="sans" style="font-size:14px;padding-top:2em"><hr/><details open="" style="padding-top:1em"><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Inline comments</summary><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">We present the first flop controlled scaling study of byte-level models up to 8B parameters and 4T training bytes. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 27, 2024, 1:33 PM</time></span></span></div><div style="padding:0.2em">模型参数：8B<br/>训练数据：4T training bytes<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><mark class="highlight-orange_background">Clark et al., </mark><mark class="highlight-orange_background"><a href="https://arxiv.org/html/2412.09871v1#bib.bib9">2022</a></mark></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 27, 2024, 4:55 PM</time></span></span></div><div style="padding:0.2em">这篇文章的主要内容是关于CANINE（“Character Architecture with No tokenization In Neural Encoders”）模型的研究。这是一种基于字符级的深度编码器，能够在不依赖显式分词器或固定词汇表的情况下直接处理字符序列。其设计目的是解决现有分词方法的局限性，并在提高模型准确性和通用性的同时减少工程复杂度。以下是文章的核心内容概述：<br/>	1.	<br/><strong>背景与动机</strong>：<br/>	•	传统自然语言处理（NLP）依赖显式分词器，但这些分词器可能不适合所有语言，并且固定词汇表可能限制模型的适应能力。<br/>	•	CANINE旨在通过直接操作字符序列，避免这些分词相关问题，从而提升模型对多语言和复杂语言现象（如拼接语法和拼写变化）的处理能力。<br/>	2.	<br/><strong>CANINE模型的核心组件</strong>：<br/>	•	<br/><strong>字符级输入表示</strong>：通过哈希方法嵌入Unicode字符，支持大范围字符处理，同时减少参数量。<br/>	•	<br/><strong>降采样与深度变换</strong>：使用局部注意力的降采样技术压缩输入序列长度，使模型在处理长序列时保持高效。<br/>	•	<br/><strong>预训练策略</strong>：提出两种预训练损失：<br/>	1.	全字符级的自回归预测损失。<br/>	2.	基于子词的损失（仅用于预训练）。<br/>	3.	<br/><strong>实验与结果</strong>：<br/>	•	CANINE在多语言信息检索任务（TYDI QA）中表现优于mBERT，并且模型参数更少。<br/>	•	尤其在形态丰富的语言（如斯瓦希里语）中，CANINE在匹配复杂形态变化时表现更出色。<br/>	•	在命名实体识别（NER）任务中，通过引入字符n-gram特征，CANINE显著改善了其记忆能力，同时保持了无分词特性的优势。<br/>	4.	<br/><strong>模型优势</strong>：<br/>	•	消除了分词器和固定词汇表的依赖，简化了工程流程。<br/>	•	对不同语言的广泛适应能力，特别是在形态复杂或低资源的语言中。<br/>	5.	<br/><strong>贡献与意义</strong>：<br/>	•	CANINE是首个预训练的无分词深度编码器，在语言理解质量上超越了依赖启发式分词器的模型。<br/>	•	为自然语言处理领域的多语言研究和工程实践提供了新方向。<br/><br/><br/>总结而言，CANINE通过创新的字符级建模方法，突破了现有NLP模型的分词依赖，展现了在多语言和多任务场景中的强大性能和适应能力。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Tokenization</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 30, 2024, 2:13 PM</time></span></span></div><div style="padding:0.2em">Based on the papers provided, here are the key works on tokenizer-free approaches:<br/><br/>1. ByT5 (Xue et al., 2022)<br/>- First large-scale byte-to-byte model without tokenization<br/>- Showed improved robustness but required significantly more compute than token-based models<br/>- Does not use any form of compression/patching<br/><br/>2. CANINE (Clark et al., 2022)<br/>- Pre-trained tokenization-free encoder that operates directly on character sequences<br/>- Uses downsampling via strided convolutions to reduce sequence length<br/>- Combines downsampling with a deep transformer stack<br/><br/>3. MegaByte (Yu et al., 2023)<br/>- Uses fixed-size patches of bytes as a form of compression<br/>- Combines patched representation with a byte-level decoder<br/>- Shows competitive performance with token models at 1B scale<br/><br/>4. MambaByte (Wang et al., 2024)<br/>- Adapts the Mamba state space model architecture for byte-level modeling<br/>- Uses fixed memory state instead of attention<br/>- Demonstrates competitive performance with subword models while being more robust<br/><br/>5. BLT (Byte Latent Transformer) (Pagnoni et al., 2024)<br/>- Dynamic, entropy-based patching of bytes<br/>- Three-part architecture with local encoder, global transformer, and local decoder<br/>- Matches tokenization-based model performance at scale while improving efficiency<br/><br/>The common themes across these works are:<br/>- Operating directly on byte/character sequences without tokenization<br/>- Using various forms of compression (fixed patches, downsampling, state spaces) to handle longer sequences efficiently<br/>- Demonstrating improved robustness compared to token-based models<br/>- Working towards matching token-based model performance while maintaining tokenizer-free benefits<br/><br/>The progression shows increasing sophistication in handling the computational challenges of byte-level modeling while preserving the benefits of avoiding tokenization.<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">At scale, the computational cost of a Transformer is dominated by large feed-forward network layers that run on every byte, not the cost of the attention mechanism.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 30, 2024, 3:43 PM</time></span></span></div><div style="padding:0.2em">在解释这个问题之前，先回顾一下标准 Transformer Block 的主要组成部分，以及它们各自的计算流程：<br/>	1.	<br/><strong>Self-Attention 子层（Multi-Head Attention）</strong><br/>	2.	<br/><strong>前馈网络子层（FeedForward Network, FFN）</strong><br/><br/><br/>在分析计算复杂度时，通常我们用以下符号来表示：<br/>	•	：序列长度（sequence length）。<br/>	•	：词向量或者隐藏向量的维度（hidden size）。<br/><br/><br/>在典型的 Transformer 结构中，这两部分的主要计算量分别是：<br/>	•	<br/><strong>Self-Attention 的计算复杂度：</strong> <br/>	•	<br/><strong>前馈网络（FFN）的计算复杂度：</strong> <br/><br/><br/>下面分别说明这两个复杂度从哪里来。<br/><br/><br/><br/><strong>1. Self-Attention：</strong><br/><br/><br/><br/><strong>1.1 以单头为例的计算分析</strong><br/><br/><br/>以单头自注意力（Self-Attention）为例，假设输入是一个长度为 、维度为  的序列 。通过投影矩阵分别得到 ，它们的维度依然是 （或者拆分成多头后，每一头的维度是 ，但我们这里先以不拆分或等效合并的方式分析）。自注意力机制的主要计算在于：<br/>	1.	<br/><strong>计算注意力得分</strong><br/><br/>	•	这里  和  的维度都是 。<br/>	•	 的矩阵乘法会产生一个  的矩阵，计算量约为 。<br/>	•	乘完之后还要进行一次 softmax 操作，不过相对于  的矩阵乘法，softmax 的开销通常记为  或略去常数因子后不影响主项，所以主要复杂度还是来自矩阵乘法。<br/>	2.	<br/><strong>将注意力得分与  相乘</strong><br/><br/>	•	 的维度是 ， 的维度是 。<br/>	•	最终得到的结果  为 。<br/>	•	这里的复杂度同样是 。<br/><br/><br/>因此，对自注意力层而言，每个头的主要计算都包含了一个  级别的操作，再乘上隐藏维度 。如果是多头注意力（Multi-Head Attention），多头并行时总体来说也维持同量级复杂度，常数倍会是“头数”，因此业界通常引用的复杂度结论是：<br/><br/><br/><br/><br/><strong>2. 前馈网络（FFN）：</strong><br/><br/><br/><br/><strong>2.1 标准 Transformer 中的 FFN 结构</strong><br/><br/><br/>在标准的 Transformer 中，前馈网络子层通常是两层全连接网络（Linear/MLP），并包含激活函数，比如：<br/><br/>其中：<br/>	•	 的维度是 ，或者如果把批和序列长度都算上就是 。<br/>	•	<br/><em> 的维度是 </em>，通常 。<br/>	•	<br/><em> 的维度是 </em>。<br/><br/><br/><br/><strong>2.2 计算量来源</strong><br/>	1.	<br/><strong>第一层投影 </strong><br/>	•	维度：<br/>	•	计算复杂度：。若 ，则这一项复杂度约为 ，省略常数后为 。<br/>	2.	<br/><strong>第二层投影与激活 </strong><br/>	•	维度：<br/>	•	计算复杂度：。同样，若 ，则是 ，也是  的量级。<br/><br/><br/>把这两个矩阵乘法相加，依然保持在  量级，所以我们常见地将 FFN 子层的计算量写为：<br/><br/><br/><br/><br/><strong>3. 总结</strong><br/>	•	<br/><strong>自注意力（Self-Attention）中  来自于“所有位置与所有位置”之间的相关性计算</strong>，在矩阵乘法和后续的加权过程中，每个 token 都要与长度为  的序列进行 dot-product 计算，因此得到  的复杂度。<br/>	•	<br/><strong>前馈网络（FFN）的  则来自于大维度映射的矩阵乘法</strong>。FFN 针对序列中每个位置单独做投影，但投影所用的矩阵往往是  和  的级别，因此每个 token 的计算量是 ，对全序列就是 。<br/><br/><br/>这就是在标准 Transformer 中常见的<br/><br/>的主要原因所在。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Segmenting bytes into <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">patches</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">es</span></span></span></span></span><span>﻿</span></span> allows BLT to dynamically allocate compute based on context. Figure <a href="https://arxiv.org/html/2412.09871v1#S2.F3">3</a> shows several different methods for segmenting bytes into patches. Formally, a patching function <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">f_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> segments a sequence of bytes <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒙</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∣</mi><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mi>n</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">𝒙=\{x_i,|i=1,…n\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> of length <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> into a sequence of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m&lt;n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> patches <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒑</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>p</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi><mi>j</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">𝒑=\{p_j|j=1,…,m\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord boldsymbol" style="margin-right:0.07861em;">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> by mapping each <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> to the set <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span> where <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span> indicates the start of a new patch.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 1:54 PM</time></span></span></div><div style="padding:0.2em">patching function的方法</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Patch boundaries are identified during a lightweight preprocessing step executed during dataloading. This is different from Nawrot et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib34">2023</a>) where classifier is trained to predict entropy-based patch boundaries. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:26 PM</time></span></span></div><div style="padding:0.2em">这是由于新的方式是基于原有LM的分布进行，所以可以直接得到P_e</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><mark class="highlight-red"><mark class="highlight-red_background"><strong>A critical difference between patches and tokens is that with tokens, the model has no direct access to the underlying byte features.</strong></mark></mark></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:36 PM</time></span></span></div><div style="padding:0.2em">这是造成经典的9.11&gt;9.8的问题所在</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:38 PM</time></span></span></div><div style="padding:0.2em"><strong>根据文本所述，使用tokens（标记）的模型无法直接访问底层的字节特征⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠，这意味着模型在处理数字序列时缺乏对原始字节级别的理解。这可能导致在处理和比较类似&quot;9.11&quot;和&quot;9.8&quot;这样的数值时出现问题，因为模型只能基于预定义的token来处理，而不能直接理解和处理底层的字节级数值表示。相比之下，BLT模型使用patches直接处理字节序列，可以更好地理解和处理原始数据的特征，这可能有助于更准确地处理数值比较。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><mark class="highlight-red"><mark class="highlight-red_background"><span style="border-bottom:0.05em solid">A crucial improvement of BLT over tokenization-based models is that redefines the trade off between the vocabulary size and compute. In standard llms, increasing the size of the vocabulary means larger tokens on average and therefore fewer steps for the model but also larger output dimension for the final projection layer of the model. </span></mark></mark></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:45 PM</time></span></span></div><div style="padding:0.2em">词表变大代表的FFN层计算复杂度增大，但也同时导致单token容纳的bytes更多</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:45 PM</time></span></span></div><div style="padding:0.2em"><strong>根据文中所述，这确实是一个权衡。在标准的大语言模型中，增大词表会带来两个相反的效果：词表变大会使得每个token平均能包含更多的字节，从而减少模型需要处理的步骤⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠但同时也会增大最终投影层的输出维度，增加计算开销⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠正是由于这种权衡的存在，基于分词(tokenization)的方法在调整token大小和推理成本方面的灵活性很有限⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。比如文中提到，Llama 3相比Llama 2的词表大小增加了4倍，但平均token大小只从3.7字节增加到4.4字节⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。</strong></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:47 PM</time></span></span></div><div style="padding:0.2em"><strong>BLT是一个基于字节(byte)级别的模型，而不是基于标记(token)的模型。它可以处理任何可以表示为字节序列的数据⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。实际上，BLT应该可以处理中文，因为：中文字符在计算机中最终也是以字节序列的形式存储(通常是UTF-8编码)BLT的设计特点是它能够根据数据的复杂性动态分配计算资源，这对于处理中文这样的复杂字符系统应该是有优势的⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠BLT使用熵补丁(entropy patching)的方式来识别高不确定性的下一个字节预测，这种方法是数据驱动的，不依赖于特定语言的规则⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠所以从技术原理上看，BLT应该能够处理包括中文在内的任何语言</strong></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:49 PM</time></span></span></div><div style="padding:0.2em">BLT作为一个基于byte级别的模型应该可以直接应用于中文,但需要注意以下几点:<br/>1. 中文字符的UTF-8编码特点:<br/>• 每个汉字通常使用3个bytes来编码<br/>• 会导致序列长度比英文ASCII文本长3倍左右<br/>• patch size的设置可能需要相应调整以适应这个特点<br/>1. 分组策略的调整:<br/>• 中文没有空格分词,不能使用whitespace-based patching<br/>• 可以考虑使用以下几种patching方式:<br/><br/>    ◦ Entropy-based patching: 基于模型预测的条件熵来确定边界<br/>    ◦ Identity patching: 不对序列进行任何预先切分<br/>    ◦ 针对中文优化的patching方法,比如基于字的边界<br/>1. 潜在优势:<br/>• 可以避免中文分词的问题<br/>• 能够处理中英混合文本<br/>• 对罕见字符有更好的泛化能力<br/>1. 需要验证的方面:<br/>• compression rate在中文上的效果<br/>• 模型在中文语料上的性能表现<br/>• 是否需要针对中文特点进行特殊的超参数调整<br/>虽然理论上BLT能处理中文,但目前论文没有在中文数据集上的实验结果。要确定其在中文上的实际效果,还需要进行专门的实验验证。<br/></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:54 PM</time></span></span></div><div style="padding:0.2em">根据BLT论文,我认为它可以部分但不能完全解决数字比较这类问题。让我详细分析一下：<br/><br/>1. BLT的优势：<br/>- 直接在byte级别建模,每个数字会被编码为单独的byte<br/>- N-gram embedding可以捕获数字序列的模式<br/>- 相比token-based模型,BLT不会把&quot;9.11&quot;作为单个token处理<br/><br/>2. 依然存在的挑战：<br/>- 数学推理是高层语义问题,仅仅改变token表示并不能完全解决<br/>- 模型仍然需要学习数字的概念和比较运算<br/>- 对小数点的处理可能仍有歧义<br/><br/>3. 可能的改进方向：<br/>- 在数字序列上使用特殊的patch策略<br/>- 为数字比较添加专门的预训练任务<br/>- 结合特定的数字表示方法(如positional encoding)<br/><br/>总的来说，BLT的byte-level处理可能有助于更好地理解数字序列的结构，但要真正解决数学推理问题，还需要在模型架构和训练方法上做进一步的改进。<br/></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 3:55 PM</time></span></span></div><div style="padding:0.2em">如果专门针对数字比较这类问题，我认为基于Chain of Thought (CoT)的微调方式会更有效：<br/><br/>1. CoT的优势：<br/>- 直接引导模型进行step-by-step推理<br/>- 可以显式分解数字比较步骤，如：<br/><br/><code>  Q: 9.11 &gt; 9.8?   A: 让我们一步步分析：   1. 先比较整数部分：9 = 9   2. 小数第一位比较：1 &lt; 8   3. 因此 9.11 &lt; 9.8   答案：否，9.11 &lt; 9.8  </code><br/>- 可以针对各种数字比较情况设计专门的提示模板<br/><br/>2. BLT的局限：<br/>- 虽然在byte级别有更好的表示<br/>- 但没有直接指导模型如何进行推理<br/>- 需要模型自己学习推理步骤，难度更大<br/><br/>3. 具体实现建议：<br/>- 构建数字比较的专门数据集<br/>- 设计清晰的CoT模板<br/>- 可以结合少量示例的few-shot学习<br/>- 考虑添加自我验证步骤<br/><br/>CoT微调能直接针对问题本质（推理过程），而BLT的改进主要在于表示层面。对于需要明确推理步骤的任务，CoT方法可能更有效。<br/><br/>不过这两种方法也不是互斥的，理想情况下可以将它们结合：<br/>- 使用BLT提供更好的底层表示<br/>- 用CoT微调来增强高层推理能力<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Thus patching cannot assume access to future bytes in order to choose how to segment the byte sequence. Formally, a patching scheme <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">f_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> satisfies the property of incremental patching if it satisfies:<br/><br/><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>𝒙</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>𝒙</mi><msub><mo stretchy="false">)</mo><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">f_p⁢(𝒙_{&lt;i})=f_p⁢(𝒙)_{&lt;i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1258em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 4:51 PM</time></span></span></div><div style="padding:0.2em"><strong>公式 f_p⁢(𝒙_{&lt;i})=f_p⁢(𝒙)_{&lt;i} 是增量分块(incremental patching)的形式化定义⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。让我来解释这个公式的含义：f_p⁢(𝒙_{&lt;i}) 表示对序列x的前i个字节进行分块f_p⁢(𝒙)_{&lt;i} 表示先对整个序列x进行分块，然后只取前i个位置的结果等式表明这两种方式必须得到相同的结果这个公式的实际意义是：当模型在生成文本时，只根据已经看到的字节来决定分块边界的位置，而且这个决定不会因为后面出现的内容而改变⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。这确保了模型可以在生成过程中实时、稳定地进行分块决策。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Thus patching cannot assume access to future bytes in order to choose how to segment the byte sequence. Formally, a patching scheme <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">f_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> satisfies the property of incremental patching if it satisfies:<br/><br/><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><msub><mi>𝒙</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mi>p</mi></msub><mtext>⁢</mtext><mo stretchy="false">(</mo><mi>𝒙</mi><msub><mo stretchy="false">)</mo><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">f_p⁢(𝒙_{&lt;i})=f_p⁢(𝒙)_{&lt;i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1258em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">⁢</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Dec 31, 2024, 4:51 PM</time></span></span></div><div style="padding:0.2em"><strong>公式 f_p⁢(𝒙_{&lt;i})=f_p⁢(𝒙)_{&lt;i} 是增量分块(incremental patching)的形式化定义⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。让我来解释这个公式的含义：f_p⁢(𝒙_{&lt;i}) 表示对序列x的前i个字节进行分块f_p⁢(𝒙)_{&lt;i} 表示先对整个序列x进行分块，然后只取前i个位置的结果等式表明这两种方式必须得到相同的结果这个公式的实际意义是：当模型在生成文本时，只根据已经看到的字节来决定分块边界的位置，而且这个决定不会因为后面出现的内容而改变⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。这确保了模型可以在生成过程中实时、稳定地进行分块决策。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">This model consumes the bulk of the flops during pre-training as well as inference, and thus, choosing when to invoke it allows us to control and vary the amount of compute expended for different portions of the input and output as a function of input/output complexity.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 1, 2025, 11:01 AM</time></span></span></div><div style="padding:0.2em">BLT通过动态分配计算资源的设计来实现高效的计算量分配。让我解释一下具体机制：<br/><br/>1. 熵预测驱动的动态分配：<br/><br/><code>- BLT使用一个小型字节级语言模型来预测下一个字节的熵 - 当熵值超过设定阈值时，会标记为一个patch的边界 - 熵值高意味着下一个字节预测的不确定性大，需要更多计算资源</code><br/><br/>2. 具体工作流程：<br/><br/><code>- 对于熵值低的部分(如单词末尾的字母)，只使用轻量级的Local Decoder - 当遇到熵值高的部分(如句子开头或生僻词)，才调用计算量大的Latent Global Transformer</code><br/><br/>3. 实际例子：<br/><br/><code>预测&quot;computer&quot;这个词时： - &quot;c&quot;: 熵值高 → 调用Global Transformer - &quot;omputer&quot;: 熵值低 → 只用Local Decoder</code><br/><br/>4. 优势：<br/>- 避免对简单预测使用大量计算资源<br/>- 将计算能力集中在真正需要的复杂预测上<br/>- 实现了计算资源的自适应分配<br/><br/>5. 效果：<br/>- 在保持性能的同时降低了50%的推理计算量<br/>- 特别适合处理长序列输入，因为可以动态跳过简单部分<br/><br/>这种设计让模型能够&quot;智能地&quot;分配计算资源，将大部分计算力用在真正需要的地方，从而提高整体效率。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">The transformer layers use a local block causal attention mask; each byte attends to a fixed window of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">w_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> preceding bytes that in general can cross the dynamic patch boundaries but can not cross document boundaries.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 11:21 AM</time></span></span></div><div style="padding:0.2em">byte encoder hidden states不会直接参与到Latent Global Transformer的计算中。让我解释其信息流向：<br/>1. 信息流向过程：<br/>• byte encoder hidden states → patch cross attention → patch representations → Latent Global Transformer<br/>1. 数据转换：<br/><br/><br/><code>pythonCopy</code><em><code># 1. byte embeddings转换为hidden states</code></em><code><br/>h_init = LocalTransformer(byte_embeddings)<br/><br/><br/></code><em><code># 2. cross attention将hidden states聚合为patch表示</code></em><code><br/>h_down = StridedConv(h_init)  <br/><br/></code><em><code># 这里patch representations才会输入Latent Global Transformer# 3. Latent Global Transformer只处理patch级别的表示</code></em><code><br/>h_down&#x27; = GlobalTransformer(h_down)<br/></code><br/>1. 关键点：<br/>• byte encoder hidden states的信息被压缩和聚合到patch representations中<br/>• Latent Global Transformer只接收和处理patch level的表示<br/>• 原始的byte level信息不会直接参与Global模型的计算<br/>这种设计的好处是：<br/>1. 降低了序列长度，提高计算效率<br/>2. 保持了层次化的特征表示<br/>3. 通过cross attention机制保留必要的字节级信息<br/>所以byte encoder hidden states主要作用是帮助构建patch表示，而不是直接参与Latent Global Transformer的计算。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"> ……(5)</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 12:13 PM</time></span></span></div><div style="padding:0.2em">是否有问题：应该是P_{0,j}=ℰ_C(f(f_{bytes}(p_j)))?</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Because we use multi-headed attention over <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span><span>﻿</span></span>, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span><span>﻿</span></span> and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span><span>﻿</span></span> and patch representations are typically of larger dimension (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">h_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>) than <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">h_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>, we maintain <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">P_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> as multiple heads of dimension <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi mathvariant="script">E</mi></msub></mrow><annotation encoding="application/x-tex">h_ℰ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.18583em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> when doing cross-attention, and later, concat these representations into <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>𝒢</mi></msub></mrow><annotation encoding="application/x-tex">h_𝒢</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathscr mtight" style="margin-right:0.17322em;">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> dimensions.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 3:15 PM</time></span></span></div><div style="padding:0.2em">h_𝒢 = concat(head_1, head_2, ..., head_n)<br/>其中每个head_i的维度是h_ℰ<br/>且 h_𝒢 = n * h_ℰ，n是head的数量<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">The local decoder predicts a sequence of raw bytes, as a function of previously decoded bytes, and thus, takes as input the hidden representations produced by the local encoder for the byte-sequence. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 3:39 PM</time></span></span></div><div style="padding:0.2em"><strong>本地解码器（local decoder）使用了本地编码器（local encoder）产生的隐藏表示（hidden representations）作为输入⁠</strong><strong><a href="https://www.notion.so/Byte-Latent-Transformer-Patches-Scale-Better-Than-Tokens-1689e7a67f2681d89c5de307f6b83e6a?pvs=21">1</a></strong><strong>⁠。具体来说，解码器在预测原始字节序列时，会利用之前已解码的字节信息，并将编码器生成的隐藏表示作为输入来辅助解码过程。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">split operation <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝒟</mi><mi>C</mi></msub></mrow><annotation encoding="application/x-tex">𝒟_C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.09371em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0937em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>,</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 4:27 PM</time></span></span></div><div style="padding:0.2em">从代码中我看到split实际上是通过reshape实现的，让我详细分析一下具体实现：<br/><br/>在LocalDecoder类中：<br/>def forward(self, tokens, embeds, patch_embeds, ...):<br/>    # ...<br/>    if self.patch_embedding_projection is not None:<br/>        # 1. 首先通过线性投影<br/>        patch_embeds = self.patch_embedding_projection(patch_embeds)<br/>        <br/>        # 2. 如果存在cross_attn_k,进行reshape操作<br/>        if self.cross_attn_k is not None:<br/>            # 这里实现了split操作<br/>            patch_embeds = patch_embeds.reshape(<br/>                bs,  # batch_size <br/>                patch_embeds.shape[1] * self.cross_attn_k,  # 新的序列长度<br/>                self.dim  # 每个head的维度<br/>            )<br/><br/>让我解释这个reshape操作的细节：<br/><br/>1. patch_embedding_projection的作用：<br/>def _create_patch_projection(self, args):<br/>    if not self._should_create_patch_projection(args):<br/>        return None<br/>    <br/>    # 输出维度是token_emb_dim乘以cross_attn_k<br/>    output_dim = args.dim_token_emb * (self.cross_attn_k or 1)<br/>    <br/>    return nn.Linear(<br/>        in_features=args.dim_patch_emb,<br/>        out_features=output_dim,<br/>        bias=False,<br/>    )<br/><br/>2. reshape的过程：<br/>- 输入形状: [batch_size, seq_len, dim_patch_emb]<br/>- 线性投影后: [batch_size, seq_len, dim_token_emb * cross_attn_k]<br/>- reshape后: [batch_size, seq_len * cross_attn_k, dim_token_emb]<br/><br/>这表明：<br/>1. split不是通过切分或平均操作实现的<br/>2. 而是先通过线性投影扩展维度<br/>3. 然后通过reshape重排这些维度<br/>4. cross_attn_k决定了要分成多少个head<br/><br/>这种实现方式的优点是：<br/>1. 保持了数据的连续性<br/>2. 避免了显式的切分操作<br/>3. 让每个head能够学习到不同的特征表示<br/>4. 计算效率更高<br/><br/>这与论文描述的&quot;maintain P_l as multiple heads&quot;是一致的，只是实现方式更加优雅和高效。<br/></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 5:00 PM</time></span></span></div><div style="padding:0.2em">这里线性投影，为什么不直接投影到reshape后的维度呢？而需要再进行一次reshape?</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 3, 2025, 5:01 PM</time></span></span></div><div style="padding:0.2em">这是一个常见的实现模式：先用线性层将  投影到  的“扁平”形状，然后再用 reshape/view 对最后一维进行拆分或合并，从而得到想要的  或  等多维结构。这样做最主要是为了遵循 <strong>线性层的标准输入/输出格式</strong> 以及 <strong>在后续阶段灵活地处理拆分和并行维度（比如多头、多分块）</strong>。在 PyTorch 中，一个 nn.Linear(in_features, out_features) 通常只对最后一维做线性变换，后续如果要进一步拆分或合并，需要显式地做一个 reshape。<br/><br/><br/><br/><strong>详细解析</strong><br/><br/><br/>在这段代码里，核心流程是：<br/>	1.	<br/><strong>线性投影</strong>（nn.Linear）：<br/>	•	将输入从  形状，投影成 。<br/>	•	代码里 out_features = dim_token_emb * cross_attn_k。<br/>	2.	reshape<br/><strong> 操作</strong>：<br/>	•	把投影后的最后一维 “拆分”/“折叠”成新的序列长度和新特征维度：<br/><br/>	•	或者在其他情况下，也可以 reshape 成<br/><br/>等等，不同项目中可能有不同的拆分方式。<br/><br/><br/>之所以 <br/><strong>不直接</strong> 在线性层中就输出三维甚至四维的形状，而是先输出  再 reshape，背后有以下常见原因：<br/>	1.	<br/><strong>PyTorch 中 </strong>nn.Linear<strong> 的“常规做法”</strong><br/>PyTorch (乃至大多数深度学习框架) 中的 nn.Linear(in_features, out_features)，其输入一般是 ，然后将最后一维 in_features 投影到 out_features，输出形状是 。如果要获得更高维度的输出（例如 [..., cross_attn_k, dim_token_emb]），往往需要显式地在算完线性层以后进行 reshape。<br/>	2.	<br/><strong>实现简单，可读性和维护性更好</strong><br/>	•	先将最后一维统一投影到 ，再在后面单点地 reshape，实现逻辑更直观。<br/>	•	如果后续要改动拆分方式（例如多头、多分块），只需要改动后面一个 reshape 的逻辑即可，而不必改动 nn.Linear 的初始化。<br/>	3.	<br/><strong>在多头、多路分块时的“通用套路”</strong><br/>	•	很多多头机制（multi-head attention）或多分块（multi-group）都会先把  线性投影到 (num_heads * head_dim)，再用 reshape/view/transpose 将序列维度或头的维度拆出来。<br/>	•	这是个极其常见的模式，目的是在矩阵乘法中维持一个干净且通用的「二维/三维输入输出」逻辑，后面再用 reshape 来做灵活的维度处理。<br/>	4.	<br/><strong>避免写“自定义”线性层</strong><br/>	•	如果想要一次性输出  那可能就需要自己写一个带有自定义 broadcast/reshape 的 Linear，会让代码更复杂、可读性更差。<br/>	•	在实际工程中，先 nn.Linear(in_features, out_features)，然后做 view/reshape 几乎是约定俗成的做法。<br/><br/><br/><br/><strong>类比：多头注意力的拆分</strong><br/><br/><br/>一个和这里非常类似的常见场景是 <br/><strong>多头自注意力 (Multi-Head Self-Attention)</strong>：<br/>	1.	我们通常先用 nn.Linear(hidden_dim, num_heads * head_dim)<br/>	2.	再 reshape 成 <br/>	3.	最终再 transpose 一下得到 <br/><br/><br/>它的思想和你看到的这段 BLT patch_embeds 代码是一样的：<br/>	•	先将倒数第二个维度投影到一个扁平的 num_heads * head_dim，<br/>	•	再 reshape 分拆出 num_heads 这个新维度。<br/><br/><br/>在 Byte/patch 级别的 cross-attn、分块、或 multi-group 等场景下，也是一模一样的套路。<br/><br/><br/><br/><strong>小结</strong><br/><br/><br/>	<br/><strong>“先线性投影，再 </strong>reshape<strong>”</strong> 是 PyTorch 等框架里主流的、惯用的实现方式，也是使代码更通用和易维护的常见实践。<br/><br/><br/>简而言之，nn.Linear() 只管把维度从  投影到 ，把更多维度或时序长度的处理逻辑留给了后续的 reshape/view/transpose，因此它先输出一个“扁平”的维度，再去做拆分、合并或广播，就能非常灵活地适配多头、多分块、以及各种不同下游模块的需求。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">We carefully design controlled experiments to compare BLT with tokenization based models with particular attention to not give BLT any advantages from possibly using longer sequence contexts.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:16 AM</time></span></span></div><div style="padding:0.2em">为什么要控制sequence length?这个对试验有什么影响？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:17 AM</time></span></span></div><div style="padding:0.2em">在原文中，作者多次强调要保证 BLT 和基于 token 的模型在实验中“看到”或处理到的序列（文本）长度大体一致，即“<strong>不让 BLT 因为能处理更长上下文而额外获利</strong>”。这一点之所以重要，主要基于以下考虑：<br/>	1.	<br/><strong>Byte 级模型与 Token 级模型天然序列长度不同</strong><br/>	•	对于传统的基于 subword token 的模型（如 BPE），一个 token 平均可能对应 3~4 个字节；<br/>	•	而在 BLT 中，最原始的输入是按字节（byte）级输入，如果不加控制，Byte 模型在同样的“步骤”（或同样的 batch size）下就有可能看到更多实际字符，从而获得“额外的信息量”或“更长的上下文”。<br/>	•	因此，如果让 Byte 模型直接处理比 BPE 模型更多的原始字节数，很可能会造成实验对比不公平，难以判断性能提升究竟来自架构改进还是来自可访问的上下文变长。<br/>	2.	<br/><strong>序列长度会影响模型的计算量与性能</strong><br/>	•	如果 BLT 的每次训练或推理都能“看到”比 BPE 模型更长的实际文本序列，那么有可能带来更好的语言建模效果，但这并非纯粹由 BLT 的“动态分组/patching”设计带来的优势，而是因为额外的上下文信息。<br/>	•	另一方面，序列长度也与计算成本（FLOPs）强相关：序列越长，需要的 self-attention 或 feed-forward 计算步数就越多。倘若 BLT 不限制序列长度，而 BPE 的序列长度被限制，那 BLT 就在算力/成本与数据使用上都存在“不对等”条件。<br/>	3.	<br/><strong>控制变量以排除干扰因素，突出模型本身的对比</strong><br/>	•	做对比实验时，通常会采用“控制变量法”去尽量排除所有无关因素（如上下文长度、能看到的字符数等），从而把焦点集中在 BLT 的“可动态分组”以及“字节级建模”本身的效果上。<br/>	•	一旦让 BLT “看到”更多的字节，<br/><strong>无法明确区分</strong>是因为见到更多文本造成的收益，还是确实来自架构改进（例如 local encoder、n-gram hash embeddings、cross-attention、dynamic patching 等）的收益。<br/><br/><br/>综上所述，<br/><strong>之所以在论文中严格控制或对齐 Byte 模型与基于 Token 的模型的输入序列长度，是为了让二者在“同样的文本长度”或“同样的可访问信息”条件下进行对比</strong>，从而更准确地评估 BLT 架构本身（如动态 patching、Local Encoder/Decoder 等）的改进带来的收益，而不是被额外的可见文本长度所“稀释”或“放大”。在实验设计上，这会影响到：<br/>	•	<br/><strong>训练和推理的 batch size 设定</strong>：需要确保 Byte 模型和 Token 模型在相同 batch 情况下，处理到的实际字节数或文本规模是等价的。<br/>	•	<br/><strong>上下文窗口大小的选择</strong>：Byte 模型因为是字节级，默认会比 Token 模型有更长的潜在序列，如果不控制，Byte 模型每个样本可能看到更多上下文。<br/>	•	<br/><strong>FLOPs（浮点运算量）或内存占用</strong>：较长序列的注意力计算更贵，控制序列长度可以让比较变得更公平。<br/><br/><br/>只有在这样“被控制”的场景下，才能凸显 BLT 在同等条件下与 BPE 类模型的真实差异，并做出更客观的结论。<br/></div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:19 AM</time></span></span></div><div style="padding:0.2em">对于“Byte 模型因为是字节级，默认会比 Token 模型有更长的潜在序列”的理解，意思是：相同的一句话，转换为tokens的序列长度比基于BLT模型转换的字节序列要短，是吗？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:19 AM</time></span></span></div><div style="padding:0.2em">是的，通常情况下，如果我们把同一句话分别用<br/>	•	<br/><strong>字节级（Byte-level）</strong> 的方式表示<br/>	•	<br/><strong>BPE/词片（Token-based）</strong> 的方式表示<br/><br/><br/>那么字节序列通常会更长（因为每个字符都要用一个或多个字节来表示），而 BPE 模型则会把多个字符合并成一个 token，因此得到的序列会更短。<br/><br/><br/>举个简单例子：<br/><br/><br/>	<br/><strong>“Hello world”</strong><br/>		•	以英文 ASCII 字节方式表示：H e l l o   w o r l d（共 11 个字符，包括空格），实际上还要算上结尾符号、换行、特殊标记等，往往字节数会更多。<br/>	•	经过 BPE 可能只会得到 2~3 个 token（比如 [Hello] [▁world]），因此序列长度较短。<br/><br/><br/>这也是为什么在不加控制的情况下，<br/><strong>Byte-level 模型会“看到”更长的序列</strong>：同样的文本，字节序列天然地比 BPE 序列更长。为了做公平的对比，论文中往往会控制或对齐二者“<strong>实际处理到的文本长度</strong>”或“<strong>处理到的字节总数</strong>”，避免让 Byte-level 模型因为处理了更多原始字节而额外获利。</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:19 AM</time></span></span></div><div style="padding:0.2em">文章中是控制基于相同字节的context length对BLT与token based model进行对比试验的吗？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:20 AM</time></span></span></div><div style="padding:0.2em">是的，<strong>他们主要是按“字节（bytes）总数”来控制上下文的长度</strong>，从而保证在同一次训练或推理中，BLT 和基于 Token 的模型在“能看到的原始字节总量”上是一致的。这样就避免了 BLT 因为默认字节序列更长而“额外获利”的问题。<br/><br/><br/>具体来说，论文中提到的做法大致包含以下要点：<br/>	1.	<br/><strong>固定每个批次(batch)的字节总数</strong><br/>	•	例如，在处理 Llama 2 数据集时，作者让每个序列的平均长度为 8k 字节；在处理 BLT-1T 数据集时，他们让每个序列的平均长度为 16k 字节。<br/>	•	如此一来，无论是 BPE 模型还是 BLT，在同一个 batch 中，都只能“看到”大约相同数量的原始字节。<br/>	2.	<br/><strong>对应地调整 BPE 模型的序列长度</strong><br/>	•	对于 BPE/token 模型，如果一行文本有 8k 字节，Token 化以后可能只有几千个 token（甚至更少），但总的“原始字节数”仍然控制在 8k。<br/>	•	BLT 则直接处理 8k 字节的序列（再进一步分成 dynamic patch），两边在字节量上是对齐的。<br/>	3.	<br/><strong>避免让 BLT “看到”比 BPE 模型更多的实际信息</strong><br/>	•	若不控制，BLT 可能会直接拿到更多的上下文（因为它按字节读入），而 BPE 模型在同样的文本下往往只对应更短的 token 序列。<br/>	•	通过固定“字节总数”的做法，可以排除“谁看了更多文本”这个因素，把实验对比的重点放在了「按字节 vs. 按 token」以及「动态分组 vs. 固定分词」本身的差异上。<br/>	4.	<br/><strong>Flops（计算成本）和上下文长度也因此得到可对齐的衡量</strong><br/>	•	作者还进一步做了推理/训练 Flops 的精细估算，并在同等“可见字节数”或同等训练预算时比较性能，保证了对比的公平性。<br/><br/><br/>因此，文中所谓的“carefully design controlled experiments”就是在保证<br/><strong>同等字节上下文</strong>及<strong>相同训练/推理 FLOPs 预算</strong>的情况下，对 BLT 与基于 token 的模型进行一系列实验，以排除序列长度或数据规模不同带来的干扰，让读者能更好地理解 BLT 架构本身的优劣势。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">The former is used for scaling law experiments on optimal number of tokens as determined by Dubey et al. (<a href="https://arxiv.org/html/2412.09871v1#bib.bib13">2024</a>) to determine the best architectural choices for BLT, while the latter is used for a complete pre-training run to compare with Llama 3 on downstream tasks. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:39 AM</time></span></span></div><div style="padding:0.2em">文中提到他们使用了两种数据集，并且对这两种数据集的用途做了区分：<br/><br/>	1.	<br/><strong>Llama 2 数据集</strong><br/>	2.	<br/><strong>BLT-1T 数据集</strong><br/><br/>然后给出这样一句话：<br/><br/>“The former is used for scaling law experiments on optimal number of tokens as determined by Dubey et al. (2024) to determine the best architectural choices for BLT, while the latter is used for a complete pre-training run to compare with Llama 3 on downstream tasks.”<br/><br/><br/>这句话可以拆解理解为：<br/>	1.	<br/><strong>前者（the former）</strong>——也就是 Llama 2 数据集，<strong>主要用来做“缩放规律（scaling law）”实验</strong>。<br/>	•	他们引用了 Dubey et al. (2024) 对 Llama 3 的分析，里面给出了“给定模型大小与训练预算时，最优的训练 token 数”这类“compute-optimal”或“scaling law”建议。<br/>	•	在这个阶段，研究者会做一些中等规模的训练（而不是直接全量预训练），对不同的架构选项、不同模型规模、不同训练步数等进行对照测试，看哪种 BLT 设计在同等计算量下效果最好，从而**“确定 BLT 最优的架构选择”**。<br/>	2.	<br/><strong>后者（the latter）</strong>——即 BLT-1T 数据集，<strong>用来做“完整的大规模预训练”并在下游任务上对比 Llama 3</strong>。<br/>	•	当他们在 Llama 2 数据集上对 BLT 的一些具体设计做完实验、挑选好最佳配置后，就用 BLT-1T 这个更大/更高质量的数据集来做一次真正的“完全体”预训练。<br/>	•	之后再把训练好的 BLT 和已经训练好的 Llama 3 在各种下游任务（例如各种推理/问答/翻译/代码生成等基准）上进行对比，最终验证 BLT 整体性能。<br/><br/><br/>简而言之：<br/>	•	<br/><strong>Llama 2 数据集 + 缩放规律实验</strong>：先做小～中规模的对照实验，参考 Dubey et al. (2024) 中对 Llama 3 的结论，帮助选择或验证 BLT 的各种架构超参数（例如 Patch 大小、Local Encoder/Decoder 层数、n-gram embedding 设置等）。<br/>	•	<br/><strong>BLT-1T 数据集 + 完整大规模预训练</strong>：用在上一步中确定的最佳架构配置，进行真正的大规模训练，拿到最终模型，然后和 Llama 3 做全面对比（下游任务）。<br/><br/><br/>这样做的原因是：<br/>	•	<br/><strong>先利用缩放规律（scaling laws）进行小规模或中规模实验</strong>，可以在较短时间和较少算力下快速迭代，找到最优/较优的架构；<br/>	•	<br/><strong>再进行大规模训练</strong>，确保最后的模型在高质量、海量数据下真正达到可比甚至超越 Llama 3 的性能。<br/><br/><br/>所以这句话的含义就是：<br/>	•	<br/><strong>Llama 2 数据</strong>只用于“找架构”阶段（依据 Dubey et al. (2024) 的最优训练策略来做对照实验）；<br/>	•	<br/><strong>BLT-1T 数据</strong>则用于最终“大规模正式预训练”，并在下游任务中与 Llama 3 做正面较量。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">To maintain the same average context length and avoid giving larger patch sizes unfair advantage, we ensure that the number of bytes in each batch remains constant in expectation. This means that we reduce the sequence length of models with larger patch sizes. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:24 AM</time></span></span></div><div style="padding:0.2em">如何理解以上这段话？是否与“按“字节（bytes）总数”来控制上下文的长度”的说法矛盾？</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">To maintain the same average context length and avoid giving larger patch sizes unfair advantage, we ensure that the number of bytes in each batch remains constant in expectation. This means that we reduce the sequence length of models with larger patch sizes. </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 10:30 AM</time></span></span></div><div style="padding:0.2em">这段话其实并不与“按字节总数来控制上下文长度”相冲突，二者所说的“长度”指的是<strong>不同层面的长度</strong>。可以从以下几个角度来理解：<br/><br/><br/><br/><strong>1. 两种“长度”与两处“控制”的区别</strong><br/>	1.	<br/><strong>“按字节（bytes）总数来控制上下文长度”</strong><br/>	•	这是在“输入原始文本”这个层面上控制，也就是保证“<br/><strong>每个 batch 中的原始字节数相同</strong>”。这样，无论 BLT 还是 BPE 模型，都在同一批次里处理同样多的原始文本字节，以保证公平对比。<br/>	2.	<br/><strong>“我们减少 sequence length 来避免较大 patch size 获得不公平优势”</strong><br/>	•	这里的“sequence length”通常指的是<br/><strong>全局模型（Latent Transformer）所看到的序列长度</strong>，也就是“<strong>patch 数量</strong>”（而非原始字节数）。<br/>	•	当 patch size 增大时，每个 patch 包含的字节也变多，这意味着<br/><strong>在同样多的总字节数下</strong>，全局模型看到的“patch 序列”会变短（因为同样总字节，被切成了更少但更大的 patch）。<br/><br/><br/>换句话说，文章里为了让大 patch 不额外受益，要让它“<br/><strong>在全局 Transformer 上也只能看到差不多量级的序列步数（patch 数）</strong>”，而不是比小 patch 模型更“频繁”地调用全局计算。如果不加这道限制，单纯让 patch 大就可以显著减少计算量，但却有可能在某些情形下带来额外好处（比如每步全局模型“看到”的上下文更宽泛等），从而不利于对比的客观性。<br/><br/><br/>因此：<br/>	•	<br/><strong>“保持 batch 的原始字节数相同”</strong>：这是从“输入层面”控制，让不同模型在相同的数据规模上训练、推理。<br/>	•	<br/><strong>“减小序列长度（patch 数）”</strong>：这是从“全局 Transformer 层面”来控制每个模型能处理多少个隐式的“时序步”。<br/><br/><br/>二者并不矛盾，只是不同层次上的对齐与限制。<br/><br/><br/><br/><strong>2. 为什么要“减少 sequence length”才能避免大 patch size 的不公平优势</strong><br/>	•	<br/><strong>如果 patch size 大</strong>：<br/>	•	同样的 8k 或 16k 字节，会被切成更少的 patch。<br/>	•	这样全局 Transformer 的“序列步数”就变少，在理论上推理的计算量会降低（因为全局 Transformer 主体最耗算力）。<br/>	•	但如果不限制别的地方，大 patch 也可能“见到”比想象中更大的上下文（或每个 patch 内部更长的 local context），从而潜在获得好处。<br/>	•	<br/><strong>论文的做法</strong>：<br/>	•	既然让大 patch 减少了全局 Transformer 的开销，也要相应限制它在一些超参数（如有效 context size、训练 steps 等）上的设置，避免因为“patch 大”而占额外便宜。<br/>	•	因为如果任由“大 patch + 同样的全局序列步数”存在，可能会带来不可控的上下文优势或训练不平衡，导致实验不公平。<br/><br/><br/><br/><strong>3. 结论：并不矛盾，只是不同层面“长度”的双管齐下</strong><br/>	•	<br/><strong>“按字节总数固定”</strong>：保证原始文本层面的公平。<br/>	•	<br/><strong>“减少全局 Transformer 的序列长度（patch 个数）”</strong>：在大的 patch size 情形下，避免额外上下文或计算不平衡。<br/><br/><br/>二者结合在一起，就能既让 BLT/Token 模型在处理<br/><strong>相同字节规模</strong>的数据，又让不同 patch size 的 BLT 模型在全局层面也保持可比的计算负载和上下文范围，从而使对比更客观。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Empirically, we find that using entropy patching yields progressively larger patches in structured content <mark class="highlight-red"><mark class="highlight-red_background">like multiple choice tasks</mark></mark> (see patching on an MMLU example in <a href="https://arxiv.org/html/2412.09871v1#S15.F9">Figure 9</a>) which are often very repetitive. These variations are caused by lower entropy on the repeated content found in the entropy model context. So for the large scale run of BLT-Entropy with patch size 4.5, we reset the entropy context with new lines and use approximate monotonicity constraint as it suffers less from &quot;entropy drift&quot; from changes in context length. This change only affects how we compute entropies, but we still follow the same procedure to identify the value of the entropy threshold.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 12:51 PM</time></span></span></div><div style="padding:0.2em">这段话是什么意思？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 12:52 PM</time></span></span></div><div style="padding:0.2em">这段话主要是在解释：当他们用“小熵模型”来做 <strong>entropy-based patching</strong> 时，为什么会在某些场景（比如 MMLU 这样的多项选择题）遇到 <strong>patch 越变越大</strong> 的现象，以及为了解决这个问题，他们在大规模实验中对“小熵模型”的上下文做了什么特殊处理。<br/><br/><br/>下面分几步来拆解这段话：<br/>	1.	<br/><strong>“Using entropy patching yields progressively larger patches in structured content like multiple choice tasks … which are often very repetitive.”</strong><br/>	•	多选题（MMLU）往往格式和内容都较“固定”，比如可能有很多重复的提示（A）、(B)、(C)、(D) 等，或重复的题干结构。<br/>	•	“熵补丁”（entropy patching）会在 <br/><strong>“高熵处切分 patch，低熵处则把更多字节合并到一个 patch”</strong>。如果文本很重复、可预测性高，那么熵模型给出的“熵值”就会很低，于是分割就不容易触发——<strong>导致 patch 越拼越大</strong>。<br/>	2.	<br/><strong>“These variations are caused by lower entropy on the repeated content found in the entropy model context.”</strong><br/>	•	之所以会越合越大，是因为文本重复度高，熵模型对下一个字节的预测非常自信（entropy 低），就不会触发新的 patch 边界。<br/>	•	并且如果熵模型的“上下文”带着很多重复信息，它越看得久，越觉得后面还是很可预测，从而可能持续保持低熵，patch 继续拉长。<br/>	3.	<br/><strong>“So for the large scale run of BLT-Entropy with patch size 4.5, we reset the entropy context with new lines … suffers less from ‘entropy drift’…”</strong><br/>	•	为了缓解这个“低熵越滚越低、patch 不断变大”的状况，他们在大规模训练中做了一个技巧：<br/><strong>定期地“重置”熵模型的上下文</strong>（比如以换行符为界），让熵模型的“记忆”不要无限延续。<br/>	•	同时还用了一种“近似单调性约束”（approximate monotonicity constraint），让熵值不会随上下文变化而“飘得太厉害”（即“entropy drift”）。<br/>	•	这样做可以让熵模型在下一段文本中重新估计，不会把之前那些重复内容的状态一直带到后面，进而避免 patch 无限制地变长。<br/>	4.	<br/><strong>“This change only affects how we compute entropies, but we still follow the same procedure to identify the value of the entropy threshold.”</strong><br/>	•	也就是说，他们并 <br/><strong>没有</strong> 改动“给定阈值、超过阈值就切分 patch”这个流程；<br/>	•	<br/><strong>改动的是</strong>——在计算每个字节的熵（即让小熵模型看多少上下文、何时重置）的时候，多插入一些“重置上下文”的策略，从而减轻了“重复导致的低熵级联”现象。<br/><br/><br/><br/><strong>总结</strong><br/>简言之，这段话要表达的是：对于内容高度重复的文本，如果一直让熵模型继承长上下文，会导致大量低熵、继而产生过大的 patch。为此他们在大规模实验中，对“小熵模型”的上下文做了定期重置并加上单调性约束，来减少“熵漂移”导致的意外超长 patch，但整个 patch 切分逻辑（如阈值判断）不变，只是让熵的计算更稳定而已。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Bits-Per-Byte (BPB)</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 3:26 PM</time></span></span></div><div style="padding:0.2em">根据MegaByte和BLT论文，正确的公式是：<br/>BPB(x) = L_{CE}(xxx)/(ln(2) · n_{bytes})<br/>具体来说：<br/>1. LCE(xxx)是序列x上的交叉熵损失总和<br/>2. nbytes是序列的总字节数<br/>3. ln(2)用于将自然对数转换为以2为底的对数<br/>4. 整体表示平均每个字节需要多少比特来编码<br/>这样的计算方式才能得到&quot;每个字节的平均比特数&quot;这个含义。如果用第一个公式(LCE(xxx)/ln(2) · nbytes)，结果会随着序列长度增加而增加，这显然不合理。<br/>BLT论文中的原文是：<br/><br/><br/><code>CopyBPB(x) = L_CE(xxx) / (ln(2) · n_bytes)</code><br/>这个公式本质上是在测量模型对每个字节的预测所需的平均信息量。值越小，说明模型的预测越准确，压缩效果越好。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>5</mn></msup></mrow><annotation encoding="application/x-tex">^5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> </mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 4:39 PM</time></span></span></div><div style="padding:0.2em">5: https://pytorch.org/blog/flexattention</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">Finally, our BLT architecture trends between Llama 2 and 3 when using significantly larger patch sizes. The bpe tokenizers of Llama 2 and 3 have an average token size of 3.7 and 4.4 bytes. In contrast, BLT can achieve similar scaling trends with an average patch size of 6 and even 8 bytes. Inference flop are inversely proportional to the average patch size, so using a patch size of 8 bytes would lead to nearly 50% inference flop savings. Models with larger patch sizes also seem to perform better as we scale model and data size. BLT with patch size of 8 starts at a significantly worse point compared to bpe Llama 2 at 1B but ends up better than bpe at 7B scale. This suggests that such patch sizes might perform better at even larger scales and possibly that even larger ones could be feasible as model size and training compute grow.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 5:31 PM</time></span></span></div><div style="padding:0.2em">BLT architecture相比Llama2要好，但比Llama3要差一些?</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 5:32 PM</time></span></span></div><div style="padding:0.2em">以下段落简要介绍了当 <strong>BLT</strong> 采用“大 patch 大小”（例如平均 6 字节甚至 8 字节/patch）时，与 <strong>Llama 2</strong> 及 <strong>Llama 3</strong> 在语言建模规模扩张（scaling）过程中的对比情况：<br/><br/><br/>	“Finally, our BLT architecture trends between Llama 2 and 3 when using significantly larger patch sizes. The bpe tokenizers of Llama 2 and 3 have an average token size of 3.7 and 4.4 bytes. In contrast, BLT can achieve similar scaling trends with an average patch size of 6 and even 8 bytes. Inference flop are inversely proportional to the average patch size, so using a patch size of 8 bytes would lead to nearly 50% inference flop savings. Models with larger patch sizes also seem to perform better as we scale model and data size. BLT with patch size of 8 starts at a significantly worse point compared to bpe Llama 2 at 1B but ends up better than bpe at 7B scale. This suggests that such patch sizes might perform better at even larger scales and possibly that even larger ones could be feasible as model size and training compute grow.”<br/><br/><br/><br/><strong>这段话可以分几点来理解：</strong><br/>	1.	<br/><strong>BLT 在“大 patch”情境下的表现，整体“介于 Llama 2 与 Llama 3 之间”</strong><br/>	•	文中提到：Llama 2 和 Llama 3 的平均子词 (token) 大小分别是 3.7 和 4.4 个字节，而 BLT 可以做到平均 6～8 个字节的 patch。<br/>	•	在此对比下，BLT 的性能趋势有时会比 Llama 2 好、但尚未赶超 Llama 3；作者用 “trends between Llama 2 and 3” 来概括这一现象。<br/>	2.	<br/><strong>使用更大 patch size 可以明显节省推理计算量（inference FLOPs）</strong><br/>	•	因为“全局 Transformer 的计算量”大致与“patch 的数量”成正比，而“patch 数量”又与“平均 patch 大小”成反比。<br/>	•	若把 patch size 提高到 8 字节，推理 FLOPs 理论上可省约一半（相比和 BPE 平均 4 字节左右时的开销）。<br/>	3.	<br/><strong>更大 patch size 在大规模模型/大数据量下反而表现更好</strong><br/>	•	作者观察到：当 BLT patch size=8 在 1B 参数规模时，性能起步要比 Llama 2 差不少；可是一旦扩张到 7B 参数规模后，BLT 反而反超了基于 BPE 的 Llama 2。<br/>	•	这说明：大 patch 在初期规模（小模型）不一定占优，但当模型和数据规模持续增大时，大 patch 可能获得更好效果，且还能节省推理成本。<br/>	4.	<br/><strong>或许还有继续增大 patch size 的潜力</strong><br/>	•	作者猜测：随着模型大小和训练算力（compute）进一步增长，更大的 patch 也许依然可行，并可能带来更优的性价比。<br/><br/><br/><br/><strong>那么，是否可以简单理解成“BLT 比 Llama 2 好、但比 Llama 3 差”呢？</strong><br/>	•	<br/><strong>在一些规模下</strong>（比如 1B 参数规模），BLT（patch size 很大）最初甚至不如 Llama 2；但到 7B 规模后，BLT 反而优于 Llama 2。<br/>	•	<br/><strong>与 Llama 3 的比较</strong>：这段话并没有直接给出数值对比，只是说 BLT 的整体趋势大约“夹在” Llama 2 和 Llama 3 之间。也就是，随着规模变大，BLT 性能有望接近甚至部分超过 Llama 2，但对比 Llama 3 可能仍略逊一些（至少在目前规模下）。不过作者也暗示：如果再进一步扩大模型与数据规模，大 patch 的 BLT 也可能继续提升。<br/><br/><br/>因此，这里“介于 Llama 2 与 Llama 3 之间”更多是一个总体趋势的描述：<br/>	•	<br/><strong>和 Llama 2 比</strong>：BLT 在大规模下可取得更好表现，并且显著降低推理成本；<br/>	•	<br/><strong>和 Llama 3 比</strong>：目前还<strong>没有</strong>在所有规模上全面超越，但随着模型与数据进一步扩大，BLT 的大 patch 方式有潜力逐步缩小差距，甚至超过某些版本的 Llama 3。<br/><br/><br/>所以一句话总结：<br/><br/><br/>	<br/><strong>BLT 的性能确实在 Llama 2 与 Llama 3 之间徘徊，但它利用“更大 patch 带来的 FLOPs 优势”在大规模下可显著节约推理计算，同时不输乃至超过 Llama 2，离 Llama 3 的水准也更近了。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><mark class="highlight-red"><mark class="highlight-red_background"><strong>The BLT-Entropy model outperforms the Llama 3 model on 4 out of 7 tasks while being trained on the same number of bytes.</strong></mark></mark></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 6:13 PM</time></span></span></div><div style="padding:0.2em">这个结论与前面所说的，性能在Llama2与Llama3之间的说法，是否有相驳？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 6:13 PM</time></span></span></div><div style="padding:0.2em">确实，文中一处说“BLT 模型在相同字节数训练下，有 4/7 的任务上超越了 Llama 3”，另一处又说“当采用更大 patch 大小时，BLT 的整体趋势大约介于 Llama 2 和 Llama 3 之间”。这二者并不真正矛盾，主要原因在于：<br/><br/><br/><br/><strong>1. 比较维度和实验设置不同</strong><br/>	•	<br/><strong>“在 4/7 任务上超过 Llama 3”</strong><br/>这是文中 <br/><strong>表 1</strong>（或相关段落）中的实验：<br/>	1.	使用了 <br/><strong>BLT-Entropy</strong>（带熵模型的动态分块），并且 <strong>平均 patch 大小大约是 4.5</strong> 个字节；<br/>	2.	与一个 <br/><strong>相同训练字节数</strong>（而非相同 FLOPs）的 Llama 3 进行对比；<br/>	3.	比较的 <br/><strong>下游任务</strong> 具体是几个常见基准（MMLU、HellaSwag、ArcChallenge 等）。<br/>在这组实验里，BLT-Entropy 的确在 7 个测试集中有 4 个优于 Llama 3。<br/>	•	<br/><strong>“BLT 的趋势介于 Llama 2 和 Llama 3 之间”</strong><br/>则通常是指在 <br/><strong>整体语言建模效果（例如困惑度/Bits-per-byte）或更大 patch (6 或 8 字节)</strong> 时的 <strong>大规模（多参数、更多训练步骤）</strong> “缩放趋势 (scaling trend)” 上做出的观察，尤其是作者在讨论 <strong>推理 FLOPs 与模型/数据规模的平衡</strong> 时提到：<br/>	“BLT (ps=8) 起初在 1B 规模不如 Llama 2，但到 7B 后却超越了 Llama 2；然而对比 Llama 3 还无法确认全面超越，整体效果可以说‘介于两者之间’。”<br/><br/><br/>换言之，前者更像是“同等训练字节、在一组下游任务上的对比”，而后者则是“随模型规模/训练量不断增大时，BLT 的整体表现（尤其是语言建模测度和推理效率）在什么水平”。评估指标、实验规模、patch 大小、对比模型的具体版本都存在差异，所以会看到“某些条件下 BLT 在特定任务上胜过 Llama 3”，“但从更大范围或更大 patch 尺寸的 scaling 性能上看，还没有在所有指标上超越 Llama 3”。<br/><br/><br/><br/><strong>2. “部分任务胜过” 不代表“整体全优”</strong><br/><br/><br/>即使在表 1 中，BLT-Entropy 只是在 4 个任务中胜出，并非 7 个全胜；而且研究者还提示 <br/><strong>“BLT-Space”</strong>（另一种分块方案）在多数任务中就不如 Llama 3。也就是说，BLT 不同配置、不同 patch 大小，在不同任务、不同训练数据量、不同算力预算下，<strong>可能会有不同的结果</strong>。有时能显著胜出 Llama 3（尤其在表征更细粒度字节信息的任务上），也有时略逊一筹。<br/><br/><br/><br/><strong>3. “介于 Llama 2 和 3 之间” 指的是整体“曲线”或“趋势”</strong><br/><br/><br/>文中“Finally, our BLT architecture trends between Llama 2 and 3…” 这句话强调的是 <br/><strong>“整体 scaling 曲线上的表现”</strong>：<br/>	•	当 patch size 很大（例如 6、8 字节）时，推理 FLOPs 可以显著下降，BLT 仍能取得不错的语言建模效果；<br/>	•	尤其在 7B 以上规模下，BLT 有机会超越 Llama 2，但未必全方位赶超 Llama 3；<br/>	•	作者也指出，随着模型和数据规模继续扩张，BLT 大 patch 可能进一步发挥优势，尚有潜力。<br/><br/><br/>所以，“介于 Llama 2 和 Llama 3 之间”更多是从 <br/><strong>整体曲线</strong> 来看，即大型语言模型随着规模增长，所需算力、所能达到的 BPB/perplexity、以及综合评估性能的一个大致排名。<br/><br/><br/><br/><strong>4. 总结</strong><br/>	•	<br/><strong>在某些具体场景或任务</strong>（例如文中表 1 的那几项），BLT-Entropy <strong>确实能</strong> 在同等训练字节下 <strong>部分胜过</strong> Llama 3；<br/>	•	<br/><strong>在更广义、更多模型规模/patch 大小的比较</strong>（尤其从语言建模困惑度和 scaling 曲线的角度），BLT 大 patch 版 <strong>整体表现和 Llama 3 还存在一定差距</strong>，不过也可能超过 Llama 2；<br/>	•	这并不矛盾，而是因为 <br/><strong>评估维度、实验条件、模型配置都不同</strong>，“4/7 任务优胜”和“整体性能介于 Llama 2 与 3”各自针对的情景并不相同。<br/><br/><br/>简单说：<br/><br/><br/>	<br/><strong>BLT 并非在所有场景下都比 Llama 3 更强，但也并非全面落后。在一些特定条件（相同字节数、某些下游任务）里它能优于 Llama 3，而就大规模模型的泛化和语言建模曲线而言，目前大 patch 版 BLT 大致落在 Llama 2~3 的区间，不过随着规模变大或任务的不同，它可能继续缩小差距甚至在某些方面超越</strong>。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">The crossover point where BLT improves over token-based models has shifted slightly closer to the compute-optimal point when moving to the larger flop class models (from 3x down to 2.5x the compute optimal budget)</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 8:45 PM</time></span></span></div><div style="padding:0.2em">基于图片，如何进行理解？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 8:46 PM</time></span></span></div><div style="padding:0.2em">这句话里的 <strong>“the crossover point where BLT improves over token-based models”</strong> 指的是在给定推理 FLOPs 预算下、随着训练规模（总 FLOPs 或训练字节数）不断增大，<strong>BLT 的 BPB 曲线与 BPE 模型曲线相交并开始优于 BPE</strong> 的那个关键点（也可以理解成“分水岭”或“反超点”）。<br/><br/><br/>文中提到它从“<br/><strong>3×</strong> (the compute-optimal budget)”变成了“<strong>2.5×</strong> (the compute-optimal budget)”，大意是说：<br/>	•	在<br/><strong>较小推理预算</strong>的情境下，BLT 要比 BPE 模型多训练到大约“原本最佳训练步数（compute-optimal）<strong>3 倍</strong>”左右时，才能反超 BPE 的 BPB 曲线；<br/>	•	而<br/><strong>当推理预算更大时</strong>（也就是可以容纳更大模型、或更大 patch），BLT 模型不需要多到 3 倍，只要额外训练到大约“最佳训练步数的 <strong>2.5 倍</strong>”就能超越 BPE。<br/><br/><br/>从图表（Figure 1）可见，两条（或多条）曲线在横轴（Total Training FLOPs）增加的过程中会逐渐靠近，直到某一点 BLT 的曲线低于（好于）BPE 模型。<br/><strong>这个点越“往左”</strong>（也就是距离最佳点越近），就说明“BLT 模型在相对更少的额外训练量下就能反超 BPE 模型”。<br/><br/><br/>换言之：<br/>	1.	<br/><strong>在较小推理预算版本</strong>（左图）：<br/>	•	如果我们沿着横轴从左到右走，会先看到 Llama 2、Llama 3 的 BPE 曲线都比 BLT 低（也就是更好），要到训练次数大约是“原本计算最佳点（比如 1×）的 3 倍”时，BLT 才在 BPB 上反超。<br/>	2.	<br/><strong>在更大推理预算版本</strong>（右图）：<br/>	•	同样地，从左向右看会发现 BLT 在相对更靠左一些（大约 <br/><strong>2.5×</strong> 而不是 <strong>3×</strong>）的训练量就赶上并超过 BPE。<br/>	•	这就说明，随着模型所允许的推理预算变大，BLT（尤其 patch size=8）可以更快地追平并超越 BPE 模型。<br/><br/><br/>因此，“<br/><strong>crossover point has shifted slightly closer to the compute-optimal point</strong>”表示：对于更大推理预算的情形，BLT 不需要额外花那么多训练量就能反超 BPE；也就是反超所需的训练倍数从 3× 降到了 2.5×。这意味着当推理预算允许更大 patch 与更大模型时，BLT 的优势能更早显现。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">We attribute this, in part, to the decreasing share of total flops used by the byte-level Encoder and Decoder modules which seem to scale slower than the Latent Transformer. When growing total parameters 20x from 400M to 8B, we only roughly double BLT’s local model parameters. This is important as larger patch sizes only affect flops from the patch Latent Transformer and not the byte-level modules. In fact, that is why the BLT-Entropy ps=8 went from 1.6x to 1.7x of the Llama 2 model size when moving to the larger model scale.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 8:51 PM</time></span></span></div><div style="padding:0.2em">这是什么原因？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 8:51 PM</time></span></span></div><div style="padding:0.2em">这段话主要想解释：<strong>当我们把模型规模（尤其是“Global Latent Transformer”部分）从中等（400M 参数）扩张到非常大（8B 参数）时，BLT 的“本地模块”（即 byte-level Encoder 和 Decoder）所占的比例并不会同比例膨胀，因而实际所占的 FLOPs 比重随之下降；并且在大规模下，“更大的 patch size”对推理的加速效果就会更加显著。</strong><br/><br/><br/>下面分几步来理解：<br/>	1.	<br/><strong>BLT 的“Global Latent Transformer” vs. “Byte-level”本地模块</strong><br/>	•	整个 BLT 模型由三部分组成：<br/>	1.	<br/><strong>Local Encoder</strong>：编码原始字节；<br/>	2.	<br/><strong>Global Latent Transformer</strong>：对每个 patch 的表示进行“大模型”级别的深度处理；<br/>	3.	<br/><strong>Local Decoder</strong>：将 Global Latent Transformer 的输出再映射回字节序列。<br/>	•	其中，<br/><strong>Global Transformer</strong> 通常是参数规模最大的“主体”，而本地的 Encoder/Decoder（加上 n-gram hash embedding 等）相对比较小。<br/>	2.	<br/><strong>随着模型规模从 400M → 8B，Global Transformer 的参数增加更快，本地模块只增加少量</strong><br/>	•	比如文中说“当总参数扩大 20 倍时，我们只把本地模块的参数量翻了大约 2 倍”。<br/>	•	也就是说，<br/><strong>大部分的额外参数都用在了 Global Transformer 上</strong>（例如加更多层、更大隐藏维度等），而本地层的大小并没有“水涨船高”那么多。<br/>	•	结果：当模型非常大时，<br/><strong>本地 Encoder/Decoder 占的 FLOPs 与参数比例在整体里变得更小</strong>，因为它只是在处理字节输入输出的“轻量”部分。<br/>	3.	<br/><strong>“Larger patch sizes only affect flops from the patch Latent Transformer and not the byte-level modules”</strong><br/>	•	patch size 越大 → patch 数量越少 → Global Transformer 的序列长度越短 → 每一步“全局计算”花费的 FLOPs 就少了。<br/>	•	而本地模块（Encoder/Decoder）<br/><strong>依旧要处理同样多的字节</strong>，无论 patch size 如何，它们都会遍历各个字节。<br/>	•	可是因为在大模型里，本地模块本就只占小头，所以大 patch 带来的好处（减少 Global Transformer FLOPs）越来越明显。<br/>	4.	<br/><strong>这也解释了：“BLT-Entropy ps=8 的模型大小相对于 Llama 2，从 1.6× 变为 1.7×”</strong><br/>	•	当模型规模增大时，Global Transformer 占比越大，而本地模块所占的额外比重（诸如 cross-attention、n-gram embedding 等）就更小地摊到了整体参数里。<br/>	•	于是为了保持一定的性能（或与 token-based Llama 2 对齐），BLT 可能需要稍微增大一些本地模块参数（所以从 1.6× 变到 1.7×），但总体来看占比仍相对较低。<br/>	•	这样一来，在大规模下，<br/><strong>大 patch + 较少的全局步骤</strong> 的组合能让 BLT 进一步拉大与小 patch 或 token-based 模型在 FLOPs 效率上的差距。<br/><br/><br/><br/><strong>总结</strong>：<br/><br/><br/>	当模型从中等规模扩张到非常大规模时，BLT 的本地字节模块（Byte-level Encoder / Decoder）并不会和全球 Transformer 一起等比例“爆炸”，它们的参数与 FLOPs 占比反而更小了；而 patch size 越大时，全局 Transformer 的 FLOPs 可降低得更多。<br/><strong>因此在大规模下，大 patch 版 BLT 能更加凸显其推理效率优势，同时在总体性能上也能保持或提升。</strong></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">byte-ify pretrained token-based models</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 9:14 PM</time></span></span></div><div style="padding:0.2em">在 BLT 论文的语境下，<strong>“byte-ify pretrained token-based models”</strong> 可以理解为一种“将已经训练好的基于 Token（如 BPE、SentencePiece 等分词方式）的模型转化为直接处理字节（byte-level）的模型”的方法或流程。换句话说，就是把一个原先只懂得“token”级输入的预训练大模型（如 Llama 3.1），在其架构上嫁接或替换成 BLT 的形式，使之能够直接理解字节序列（而非 token 序列），从而“去掉”固定分词步骤，变成**真正的“tokenizer-free”**模型。<br/><br/><br/><br/><strong>为什么要“byte-ify”一个已有的 token-based 模型？</strong><br/>	1.	<br/><strong>加速训练收敛</strong><br/>	•	如果直接从头训练一个新的字节级模型，所需的计算量通常非常大。<br/>	•	而如果先利用现成的、已经在海量数据上训练过的 token-based 大模型（例如 Llama 3.1），初始化 BLT 的全局 Transformer 参数，再去专门训练本地 byte-level 编码/解码模块，就能在较少训练步骤下让模型学会处理字节输入。<br/>	2.	<br/><strong>利用已有模型的“知识”</strong><br/>	•	预训练的大模型已经在浩如烟海的文本中学到了丰富的语义、世界知识等，只是它的输入/输出层是基于 token。<br/>	•	如果能将它“改造”成字节级模型，那么就可以兼顾它已有的知识和 BLT 在“更好地处理噪声、掌握拼写细节、多语言字形”等方面的优势。<br/>	3.	<br/><strong>兼容现有生态</strong><br/>	•	很多先进的语言模型和下游应用，都已经围绕一些 token-based 大模型展开。<br/>	•	“byte-ify”使得 BLT 可以<br/><strong>以较低成本</strong>复用这些大型预训练权重，并把它们直接升级为“无 tokenizer”形态。<br/><br/><br/><br/><strong>简要原理</strong><br/>	•	<br/><strong>保留并初始化全局 Transformer</strong><br/>	•	将 BLT 架构中“Global Latent Transformer”的大部分参数直接从已有的 token-based 模型（如 Llama 3.1）拷贝或映射过来。<br/>	•	这样，全局 Transformer 层相当于“带着”预训练中的大量语义、语言知识。<br/>	•	<br/><strong>引入新的“Local Encoder / Decoder”处理字节</strong><br/>	•	BLT 需要在输入端（Local Encoder）把原始字节映射到内部 patch 表示，在输出端（Local Decoder）将 patch 表示解码回字节。<br/>	•	这些局部模块是新加的，因此需要从头或小范围训练，但它们规模相对小、训练成本也低。<br/>	•	<br/><strong>训练时的微调策略</strong><br/>	•	往往只让本地模块（Byte Encoder/Decoder）和可能少量 Transformer 参数先用较大学习率进行训练，<br/>	•	而将预训练好的全局 Transformer 用一个更小的学习率（甚至在初期阶段冻结）来微调或保持不变。<br/>	•	这样就能快速“把”字节级能力接上去，而不破坏原本已经学习到的知识。<br/><br/><br/><br/><strong>小结</strong><br/><br/><br/><br/><strong>“Byte-ify pretrained token-based models”</strong> 本质就是：<br/>	1.	先拿一个已经训练好的基于 tokenizer 的大模型；<br/>	2.	在其“核心层”参数基础上，加上/替换 BLT 的本地字节处理模块；<br/>	3.	用相对少量数据与算力训练或微调，使得原模型从“只接收 token”变为“直接处理字节”。<br/><br/><br/>如此一来，就能让已有的大模型保留其能力，同时获得字节级建模的鲁棒性与灵活性。<br/></div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background"><mark class="highlight-red"><mark class="highlight-red_background"><strong><span style="border-bottom:0.05em solid">Our model experiences a slight performance decline on MMLU and HumanEval, but a more significant drop on other tasks. This suggests that further work is needed to fully leverage the pre-trained model and improve upon its performance, particularly in terms of optimizing data mixtures and other hyperparameters.</span></strong></mark></mark></mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 5, 2025, 9:46 PM</time></span></span></div><div style="padding:0.2em">存在的问题</div><div style="padding:0.3em"></div></li></ul></div><hr/></div><div class="indented"><div><p style="padding:0.2em"><b>Block text</b>: <mark class="highlight-yellow_background">To study the effect of varying entropy model size and context window length on scaling performance, we train byte-level entropy transformer models of different model sizes between 1m and 100m parameters, with varying context window lengths from 64 to 512. We plot bpb vs training flop scaling law curves, created using our 400⁢m and 1⁢b BLT models trained on the Llama-2 dataset and present them in <a href="https://arxiv.org/html/2412.09871v1#S7.F8">Figure 8</a>. We find that scaling performance is positively correlated with both these dimensions of the entropy model, with diminishing returns when we scale beyond 50m parameters.</mark></p><ul class="toggle"><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 9:03 PM</time></span></span></div><div style="padding:0.2em">这段话如何理解？ 图示中的BPB VS FLOPs，不是说明训练更多压缩率更高的意思吗？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 9:05 PM</time></span></span></div><div style="padding:0.2em">先从<strong>大图景</strong>说起：<br/>	•	<br/><strong>这段话和 Figure 8 讨论的是</strong>：在做 “Entropy-based patching” 时，需要先有一个“预测字节熵（entropy）”的小模型（即“entropy model”），用它给每个字节打分，再动态地决定在哪些地方切分（patch）。<br/>	•	这里作者做了一系列对比实验：把这个“小熵模型”本身做成不同规模（从 1M 参数到 100M 参数不等），并且让它有不同的上下文窗口（context window 长度从 64 到 512）。然后再把它们各自得到的“分块策略”用于训练 BLT 主模型（400M 或 1B 参数）。最后，他们比较<br/><strong>BLT 主模型</strong>的语言建模性能（用 BPB 表示）和所需训练 FLOPs，得到如图所示的几条曲线。<br/><br/><br/><br/><strong>1. “Scaling performance is positively correlated with both these dimensions”的含义</strong><br/>作者说：<br/>	“We find that scaling performance is positively correlated with both these dimensions of the entropy model (size and context window length)…”<br/>	•	<br/><strong>“these dimensions”</strong> 指的就是 <strong>小熵模型的规模</strong>（parameter size）和 <strong>小熵模型的上下文窗口大小</strong>（context window）。<br/>	•	<br/><strong>“positively correlated”</strong> 的意思是：当小熵模型做得越大、或能看更多上下文（更大 window），它对字节下一步预测就越准确，进而<strong>分块（patching）做得更好</strong>——也就能给 BLT 主模型带来更好的语言建模效果（BPB 更低）。<br/><br/>所以，从图中可以看到：同样的训练 FLOPs 下，那些使用更大熵模型/更大熵模型上下文窗口的曲线，往往能到达更低的 Bits-per-byte (BPB)，即性能更好。<br/><br/><br/><strong>2. “with diminishing returns when we scale beyond 50m parameters”的含义</strong><br/>	•	当把小熵模型规模从 1M 提高到 10M、再到 50M，确实能明显改善 BLT 主模型的最终性能；但是再往上（比如到 100M）时，收益<br/><strong>开始变小</strong>，即 “diminishing returns”。<br/>	•	简言之：<br/><strong>熵模型越大，动态分块越精细，但在 50M~100M 再继续增大时，收益在缩减</strong>。投入的额外计算或参数并没有带来线性增长的收益。<br/><br/>这就是“边际效益递减”——当熵模型规模到一定程度后，对 BLT 最终训练的提升开始变得不如前面明显。<br/><br/><br/><strong>3. 图示中 BPB vs. FLOPs 与“压缩率更高”的关系</strong><br/>	•	<br/><strong>BPB（bits per byte）</strong> 本身可以理解为“模型对文本数据的压缩率或不确定性”的度量：BPB 越低，意味着模型预测下一个字节越自信、越准确，也就是能更好地“压缩”文本。<br/>	•	<br/><strong>横轴是 Total Training FLOPs</strong>：表示在给定总训练预算下，我们把模型训到哪个点。<br/><br/>图中曲线的左到右，大体代表“让主模型训练更多步数、或更大 batch 等”，于是模型性能（BPB）逐渐变好、下降得更低——<br/><strong>这确实可以说“训练更多，模型越能把文本压得更低”。</strong><br/><br/>但是，这里最主要的实验目的是<br/><strong>比较不同大小/上下文的熵模型</strong>如何影响最终的 BLT 训练效率和性能**，因此：<br/>	•	每条曲线代表一种“熵模型规模 + 上下文”组合，以及在不同训练 FLOPs 下，BLT 主模型取得的 BPB。<br/>	•	观察曲线彼此之间的相对位置和斜率，就能知道：更大的熵模型、或更大的上下文 window，能否让 BLT 主模型在相同的训练 FLOPs 下取得更低的 BPB。<br/><br/><br/><strong>并不只是简单地说“训练多就能有更高压缩率”。</strong> 当然，随着训练步数（FLOPs）增多，任何模型都会变好；但作者更关注的是：熵模型本身的大小/window 对 BLT 的提升作用有多大，是否值得把这小模型做得无限大（他们发现到 50M 左右后收益就趋缓了）。<br/><br/><br/><strong>4. 小结</strong><br/>	•	图 8 以及对应文字主要说明：<br/>	1.	<br/><strong>小熵模型的规模</strong> 和 <strong>其上下文窗口</strong> 越大，做出的分块越合理，BLT 主模型就能在相同训练预算下取得更好（更低）的 BPB；<br/>	2.	但当小熵模型超过 50M 参数后，继续扩大规模的收益开始递减。<br/>	•	这里的 BPB 代表语言建模质量，也可以视作某种“压缩率”或“对文本序列预测能力”的量化指标；横轴是总训练 FLOPs，即随着训练更多，对应的模型性能会逐渐上升（BPB 下降）。<br/>	•	“得到更低 BPB”并不只是因为“训练步数多”——<br/><strong>更关键是因为小熵模型更强，能提供更优的 patch 边界</strong>，让 BLT 省去在简单字节上浪费大模型算力，从而整体性能得到提升。</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 9:09 PM</time></span></span></div><div style="padding:0.2em">这里指的BLT主模型，是包括熵模型在内的所有模型的集合后整体的效果模型吗？</div><div style="padding:0.3em"></div></li><li><div><span class="user" style="padding:0.2em"><img src="https://lh3.googleusercontent.com/a/AGNmyxbVSyvf7-iYAieHv61H_gYACQW9HFm2KdAP8bxomw=s100" class="icon user-icon"/><span><b>Jason deng</b> <time style="font-size:0.8em">Jan 4, 2025, 9:09 PM</time></span></span></div><div style="padding:0.2em">不是的。在这篇文章的设计中，<strong>“BLT 主模型”指的是论文第 3 节所描述的主架构——即由 Local Encoder、Latent Global Transformer 和 Local Decoder 三部分组成的“大”语言模型。而“熵模型（entropy model）”则是一个额外、独立的小模型</strong>，用来在训练或推理时对字节（bytes）进行熵估计、确定动态 patch 的边界。<br/><br/>具体来说：<br/>	1.	<br/><strong>BLT 主模型</strong><br/>	•	包含三个核心模块：Local Encoder（轻量编码器）、Latent Global Transformer（全局大模型）和 Local Decoder（轻量解码器）。<br/>	•	这是实际进行主要语言建模（预测下一个字节/生成文本）的主体模型。<br/>	2.	<br/><strong>熵模型（entropy model）</strong><br/>	•	是一個<br/><strong>单独训练的“小”字节级语言模型</strong>（例如在论文中尝试了 1M～100M 参数规模），只负责预测下一个字节的概率分布，以此计算“熵”高低；再根据设定的阈值或规则来决定哪些字节处于“高熵”状态，从而在这些位置切分出新的 patch 边界。<br/>	•	训练 BLT 主模型之前或同时，会先（或并行）训练好该熵模型；训练或推理时，就用它来给字节打分。<br/>	•	它并不和 BLT 主模型“合并”成一个大模型，也不是 BLT 架构不可分割的一部分。换言之，熵模型只是给“动态分块”提供信息，<br/><strong>不直接参与 BLT 的语言建模预测</strong>。<br/><br/><br/>因此，当论文里提到“我们发现熵模型规模越大、上下文越长，BLT 的最终表现越好”时，指的是：<br/><strong>更强的熵模型</strong>能更准确地划分高/低熵区域，帮助“动态分块”过程更加合理，进而让主模型（BLT）在合适的位置投入更多/更少算力，从而整体得到更好的语言建模效果。<strong>但熵模型本身并不属于 BLT 主模型的组成部分</strong>。</div><div style="padding:0.3em"></div></li></ul></div><hr/></div></details></span></body></html>