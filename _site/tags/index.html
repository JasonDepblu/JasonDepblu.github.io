<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Tags</title>

  <!-- MathJax -->
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]],
        displayMath: [["$$", "$$"], ["\\[", "\\]"]],
        processEscapes: true
      },
      "HTML-CSS": {
      scale: 70  // 调整公式字体大小，默认 100（百分比）
      },
      CommonHTML: {
      scale: 70  // 如果使用 CommonHTML 输出，也需要设置
      }
    });
  </script>

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/custom.css">
</head>

<body class="post-layout">
<!--     Header -->
    <header class="header">
      <div class="container">
        <span class="logo">🌟 Jason's Blog</span>
        <nav class="nav">
          <ul>
            
              <li><a href="/">Posts</a></li>
            
              <li><a href="/archive/">Archive</a></li>
            
              <li><a href="/chat/">Q&A</a></li>
            
              <li><a href="/tags/">Tags</a></li>
            
              <li><a href="/about/">About</a></li>
            
              <li><a href="/contact/">Contact</a></li>
            
          </ul>
        </nav>
      </div>
    </header>

    <article>
        <h1>Tags</h1>
        <div class="post-meta">
          <span class="post-date">Date: December 03, 2024</span> |
          <span class="reading-time">Estimated Reading Time: 5 min</span> |
          <span class="post-author">Author: Jason</span>
        </div>
        <main class="container">
            <ul>
    
        <li>
            <a href="#history">history</a> (1)
        </li>
    
        <li>
            <a href="#post">post</a> (3)
        </li>
    
        <li>
            <a href="#first">first</a> (1)
        </li>
    
        <li>
            <a href="#reason">reason</a> (1)
        </li>
    
        <li>
            <a href="#cot">CoT</a> (1)
        </li>
    
        <li>
            <a href="#new">new</a> (1)
        </li>
    
        <li>
            <a href="#reasoning">reasoning</a> (1)
        </li>
    
        <li>
            <a href="#reinforcement-learning">reinforcement_learning</a> (1)
        </li>
    
</ul>

<hr>


    <h2 id="history">history</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2024/12/03/history1-post.html">Super Weights in Large Language Model</a> - December 03, 2024
            </li>
        
    </ul>

    <h2 id="post">post</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2025/01/06/Byte-Latent-Transformer-Patches.html">Byte Latent Transformer: Patches Scale Better Than Tokens — 开创无tokenizer语言建模的新维度</a> - January 06, 2025
            </li>
        
            <li>
                <a href="/llm/papers/2024/12/12/my-first-post.html">Reasoning with REinforced Fine-Tuning</a> - December 12, 2024
            </li>
        
            <li>
                <a href="/llm/papers/2024/12/03/history1-post.html">Super Weights in Large Language Model</a> - December 03, 2024
            </li>
        
    </ul>

    <h2 id="first">first</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2024/12/12/my-first-post.html">Reasoning with REinforced Fine-Tuning</a> - December 12, 2024
            </li>
        
    </ul>

    <h2 id="reason">reason</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2024/12/25/reason-cot-post.html">Coconut：在连续潜在空间中的大语言模型推理范式研究</a> - December 25, 2024
            </li>
        
    </ul>

    <h2 id="cot">CoT</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2024/12/25/reason-cot-post.html">Coconut：在连续潜在空间中的大语言模型推理范式研究</a> - December 25, 2024
            </li>
        
    </ul>

    <h2 id="new">new</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2025/01/06/Byte-Latent-Transformer-Patches.html">Byte Latent Transformer: Patches Scale Better Than Tokens — 开创无tokenizer语言建模的新维度</a> - January 06, 2025
            </li>
        
    </ul>

    <h2 id="reasoning">reasoning</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2025/02/19/Reasoning-model-reproduced.html">Reasoning model的复现之路</a> - February 19, 2025
            </li>
        
    </ul>

    <h2 id="reinforcement-learning">reinforcement_learning</h2>
    <ul>
        
            <li>
                <a href="/llm/papers/2025/02/19/Reasoning-model-reproduced.html">Reasoning model的复现之路</a> - February 19, 2025
            </li>
        
    </ul>

        </main>
        
    </article>
    <!-- Footer -->
    <footer class="footer">
      <p>&copy; 2025 Jason‘s Blog</p>
    </footer>

    <!-- Custom JavaScript -->
    <script src="/assets/js/main.js"></script>
</body>
<!--<script src="/assets/js/main.js"></script>-->

<!--&lt;!&ndash;<link rel="stylesheet" href="/assets/main.css">&ndash;&gt;-->
<!--<link rel="stylesheet" href="/assets/css/custom.css">-->
</html>