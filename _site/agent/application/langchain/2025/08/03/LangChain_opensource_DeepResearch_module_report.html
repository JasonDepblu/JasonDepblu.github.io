<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LangChain 开源 Deep Research 模块深度调研报告</title>

  <!-- MathJax -->
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]],
        displayMath: [["$$", "$$"], ["\\[", "\\]"]],
        processEscapes: true
      },
      "HTML-CSS": {
      scale: 70  // 调整公式字体大小，默认 100（百分比）
      },
      CommonHTML: {
      scale: 70  // 如果使用 CommonHTML 输出，也需要设置
      }
    });
  </script>

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/custom.css">
</head>

<body class="post-layout">
<!--     Header -->
    <header class="header">
      <div class="container">
        <span class="logo">🌟 Jason's Blog</span>
        <nav class="nav">
          <ul>
            
              <li><a href="/">Posts</a></li>
            
              <li><a href="/archive/">Archive</a></li>
            
              <li><a href="/chat/">Q&A</a></li>
            
              <li><a href="/tags/">Tags</a></li>
            
              <li><a href="/about/">About</a></li>
            
              <li><a href="/contact/">Contact</a></li>
            
          </ul>
        </nav>
      </div>
    </header>

    <article>
        <h1>LangChain 开源 Deep Research 模块深度调研报告</h1>
        <div class="post-meta">
          <span class="post-date">Date: August 03, 2025</span> |
          <span class="reading-time">Estimated Reading Time: 15 min</span> |
          <span class="post-author">Author: Jason Deng</span>
        </div>
        <main class="container">
            <h1 id="目录">目录</h1>

<ol>
  <li>引言</li>
  <li>LangChain Deep Research 模块综述</li>
  <li>主流 Deep Research 产品对比</li>
  <li>LangChain 劣势与源码解析</li>
  <li>结论与展望</li>
  <li>参考文献</li>
</ol>

<h2 id="引言">引言</h2>

<p>“Deep Research”（深度研究）已成为大模型代理应用的新热点。不同于传统搜索仅返回结果列表，
深度研究代理能够自主检索多源信息并产出长篇、引注明确的综合报告。
OpenAI 在 2025 年推出了 Deep Research 工作流，引发开源社区的响应：
LangChain 开源了 Deep Research 模块（Open Deep Research），并有 HuggingFace、Camel 等推出类似方案。
本文将深入解析 LangChain 的 Deep Research 模块，包括其架构与功能特性，
并对比当前主流深度研究产品（OpenAI GPT-4 检索、Anthropic Claude、Manus、Camel-AI Eigent）的异同。
在此基础上，我们分析 LangChain Deep Research 的不足，并通过源码实例讲解其中关键机制的实现和优化空间。</p>

<h2 id="langchain-deep-research-模块概览">LangChain Deep Research 模块概览</h2>

<h3 id="技术架构与流程">技术架构与流程</h3>

<p>LangChain 的 Open Deep Research 是一个多阶段、多代理的研究代理，构建于 LangChain 新推出的 LangGraph 框架之上。其整体流程分为三个阶段：</p>
<ol>
  <li><strong>Scope（确定范围）</strong>：利用LLM与用户澄清对话，生成研究提纲</li>
  <li><strong>Research（检索研究）</strong>：主管代理拆分任务，并行调度子代理检索</li>
  <li><strong>Write（报告撰写）</strong>：汇总子代理结果生成结构化报告</li>
</ol>

<p>架构采用<strong>“主管-子代理”调度模式</strong>：</p>

<ul>
  <li>研究主管代理（Supervisor）根据用户请求规划任务</li>
  <li>并行调度多个子代理（Sub-Agent）执行子课题检索</li>
  <li>子代理完成后生成内容并附来源引用</li>
  <li>主管代理汇总结果并生成最终报告</li>
</ul>

<p><img src="https://blog.langchain.com/content/images/size/w1600/2025/07/simple.png" alt="simple.png" /></p>

<h4 id="scope-阶段"><strong>Scope 阶段</strong>：</h4>
<p>在Scope 阶段，系统首先利用LLM与用户进行澄清对话，以获取完整需求上下文。
   随后，生成一份研究提纲 (research brief)，明确研究范围、要点和成功标准。
   提纲相当于后续研究的“北极星”，指导代理深入检索并避免偏题。
   由于用户初始请求往往信息不足，这一阶段通过补充提问和示例，使模型精准理解用户意图。</p>

<ul>
  <li>通过澄清对话获取完整需求上下文</li>
  <li>生成研究提纲（research brief）明确范围、要点和成功标准</li>
  <li>提纲作为后续研究的”北极星”指导方向</li>
</ul>

<p><img src="https://blog.langchain.com/content/images/2025/07/scope.png" alt="image2.png" /></p>
<ul>
  <li>User Clarification
<img src="https://blog.langchain.com/content/images/2025/07/brief.png" alt="image3.png" /></li>
  <li>Brief Generation
<img src="https://blog.langchain.com/content/images/2025/07/actualbrief.png" alt="image4.png" /></li>
</ul>

<h4 id="research-阶段"><strong>Research 阶段</strong>：</h4>
<p>在Research阶段，进入多代理协作检索：研究主管代理读取提纲，将总任务按主题或子问题拆分成若干独立的子任务。
   对于每个子任务，主管生成一个子代理指令，说明该子代理只需关注特定主题，无需关心全局。
   然后主管并行启动多个子代理（典型默认最多 5 个），分别执行工具调用循环（如网络搜索和MCP工具）
   来搜集各自领域的信息。这种并行多线程检索避免了单代理串行搜索的上下文混杂和低效——Anthropic 的评估显示，
   多代理并行在广度型查询上比单代理提升90%性能。每个子代理在检索若干轮后，都会调用LLM将所得资料整理撰写成
   该子课题的详尽回答，并引用关键来源。为减少无关冗余信息占用上下文，每个子代理还会对自身结果做压缩清洗
   （剔除失败的工具调用痕迹和不相关内容）再返回主管。研究主管收集所有子代理的结果后，会判断是否满足提纲要求，
   若有遗漏可进一步发起迭代研究（例如再深入某子主题或新增子主题），直至信息充分。</p>

<ul>
  <li>主管代理按主题拆分任务</li>
  <li>并行启动子代理（默认最多5个）</li>
  <li>每个子代理执行工具调用循环（网络搜索/MCP工具）</li>
  <li>子代理对结果压缩清洗后返回主管</li>
  <li>主管判断信息完整性并触发迭代研究</li>
</ul>

<p><img src="https://blog.langchain.com/content/images/size/w1600/2025/07/research.png" alt="image5.png" /></p>

<h4 id="write-阶段"><strong>Write 阶段</strong>：</h4>
<p>在Write 阶段，当研究信息足够后，主管进入报告撰写。此时将研究提纲以及所有经清洗的子代理研究结果，
   一并提供给一个LLM，请其一次性生成最终报告。生成的报告针对提纲要求进行完整回答，并严格依据研究结果撰写，
   确保内容有据可依。报告通常采用结构化Markdown格式，包含引言、各章节内容以及结论等，字数往往较多且
   插入引用以保证可追溯出处。这种“集中书写”方式避免了让多个子代理各写报告段落可能产生的风格不一致、
   上下文割裂问题。</p>

<ul>
  <li>主管将提纲和子代理结果提供给LLM</li>
  <li>一次性生成结构化Markdown报告</li>
  <li>报告包含引言、正文、结论和引用</li>
  <li>“集中书写”保证风格一致性</li>
</ul>

<p><img src="https://blog.langchain.com/content/images/2025/07/one-shot.png" alt="image6.png" /></p>

<h4 id="底层支撑"><strong>底层支撑</strong>：</h4>
<p>底层支撑方面，LangChain Deep Research 充分利用了 LangGraph 提供的长生命周期、有状态执行能力。
   代理的对话历史、提纲、子代理结果等都维护在有状态工作流中，使长时间运行不丢失中间状态，并支持出错恢复
   和人为检查。此外，LangGraph 的调度使并行子代理协作、更复杂的子图流程成为可能，同时支持人类中控
   （随时监视和干预代理状态）以提高可靠性。这些架构设计保证了 Deep Research 代理在处理开放式、
   步骤不确定的研究任务时具备灵活策略和稳健执行的能力。</p>

<ul>
  <li>利用 LangGraph 的长生命周期有状态执行能力</li>
  <li>维护对话历史、提纲和中间状态</li>
  <li>支持出错恢复和人为检查</li>
  <li>实现复杂子图流程和人类中控</li>
</ul>

<p><img src="https://blog.langchain.com/content/images/2025/07/multi-agent.png" alt="image6.png" /></p>

<h3 id="主要功能特性">主要功能特性</h3>

<ol>
  <li><strong>多轮网络检索与信息汇总</strong>
    <ul>
      <li>自主生成多跳搜索查询</li>
      <li>子代理在独立上下文内反复调用搜索引擎</li>
      <li>主管整合多源信息形成完整答案</li>
    </ul>
  </li>
  <li><strong>引用来源保证信息可追溯</strong>
    <ul>
      <li>每条重要论断附来源引用</li>
      <li>引用形式为文内标注或链接</li>
      <li>提高报告可信度和透明度</li>
    </ul>
  </li>
  <li><strong>分段写作与链式思维控制</strong>
    <ul>
      <li>通过链式思考（Chain-of-Thought）引导任务</li>
      <li>提示策略控制代理行为</li>
      <li>执行搜索→分析→精简循环</li>
    </ul>
  </li>
  <li><strong>内存与上下文管理</strong>
    <ul>
      <li>Scope阶段浓缩对话成提纲</li>
      <li>子代理独立处理子课题</li>
      <li>结果返回前裁剪无关信息</li>
      <li>显著降低令牌消耗</li>
    </ul>
  </li>
  <li><strong>工具集成与插件机制</strong>
    <ul>
      <li>默认集成网络搜索API和MCP工具</li>
      <li>支持配置不同搜索服务</li>
      <li>插件式工具配置（通过.env或UI）</li>
      <li>支持函数式调用（类似OpenAI function calling）</li>
    </ul>
  </li>
  <li><strong>易用的界面与配置</strong>
    <ul>
      <li>提供 LangGraph Studio 和 Open Agent Platform (OAP)</li>
      <li>可视化查看执行流程和调试提示</li>
      <li>支持自定义：并发子代理数、迭代轮次、模型选择等</li>
    </ul>
  </li>
</ol>

<h3 id="典型适用场景">典型适用场景</h3>

<table>
  <thead>
    <tr>
      <th>场景类型</th>
      <th>示例</th>
      <th>优势</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>比较分析类</td>
      <td>“对比产品A和B的优缺点”</td>
      <td>多代理使其对每个对象进行深入搜索，再生成对比报告（类似人类先各自调研再比较）</td>
    </tr>
    <tr>
      <td>开放式列举类</td>
      <td>“找出某领域排名前20的人选”</td>
      <td>传统检索很难一下找到20个，但深度研究代理可以不断追踪不同来源累积结果。</td>
    </tr>
    <tr>
      <td>事实验证类</td>
      <td>“X说法是否属实？”</td>
      <td>其 iterative 策略和注重来源的特点，使其擅长谣言查证和事实核查任务。</td>
    </tr>
    <tr>
      <td>复杂知识汇总类</td>
      <td>“解读长篇报告提炼要点”</td>
      <td>代理可将长文分段由不同子代理阅读总结，再汇总出一份提炼报告。这相当于多人阅读长文各写摘要，再合并成果，效率和质量都较高。</td>
    </tr>
    <tr>
      <td>决策情报类</td>
      <td>市场调研、竞品分析</td>
      <td>代理可以并行收集多个来源的数据（官网、新闻、评价），并整理成决策报告，节省人工调研的大量时间。</td>
    </tr>
    <tr>
      <td>跨领域综合类</td>
      <td>“分析技术科研现状与应用”</td>
      <td>这种问题涉及多个维度，Deep Research 可拆分成学术、产业、公众舆论等子课题分别研究，最后由主管融合成一篇全面报告。</td>
    </tr>
  </tbody>
</table>

<h2 id="深度研究代理对比langchain-vs-openai-vs-anthropic-vs-manus-vs-camel-ai">深度研究代理对比：LangChain vs OpenAI vs Anthropic vs Manus vs Camel-AI</h2>

<h3 id="技术架构对比">技术架构对比</h3>

<table>
  <thead>
    <tr>
      <th>方案</th>
      <th>架构特点</th>
      <th>优势</th>
      <th>劣势</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>LangChain</strong></td>
      <td>多代理+多阶段架构<br />Supervisor协调Sub-Agent</td>
      <td>灵活探索+上下文独立</td>
      <td>子代理间缺少中途交流</td>
    </tr>
    <tr>
      <td><strong>OpenAI GPT-4</strong></td>
      <td>单智能体序贯工具调用</td>
      <td>部署简单+高质量语言组织</td>
      <td>线性流程效率低</td>
    </tr>
    <tr>
      <td><strong>Anthropic Claude</strong></td>
      <td>主代理+子代理+独立CitationAgent</td>
      <td>高可信度+引文精确</td>
      <td>闭源商用不可定制</td>
    </tr>
    <tr>
      <td><strong>Manus</strong></td>
      <td>分布式Agent群（Wide模式）</td>
      <td>超大规模并行（100+代理）</td>
      <td>黑盒操作+资源消耗大</td>
    </tr>
    <tr>
      <td><strong>Camel-AI Eigent</strong></td>
      <td>开放式多Agent编排</td>
      <td>高度自定义+本地优先</td>
      <td>配置复杂度高</td>
    </tr>
  </tbody>
</table>

<h3 id="功能能力对比">功能能力对比</h3>

<table>
  <thead>
    <tr>
      <th>方案</th>
      <th>核心能力</th>
      <th>特色功能</th>
      <th>局限</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>LangChain</strong></td>
      <td>多轮检索+多文档归纳</td>
      <td>来源引用+结构化报告</td>
      <td>实时性和多媒体处理弱</td>
    </tr>
    <tr>
      <td><strong>OpenAI</strong></td>
      <td>单代理串行检索</td>
      <td>高质量语言表述</td>
      <td>缺少平行检索机制</td>
    </tr>
    <tr>
      <td><strong>Anthropic</strong></td>
      <td>平行思考+引文检查</td>
      <td>AI自改善提示工程</td>
      <td>聚焦文本分析</td>
    </tr>
    <tr>
      <td><strong>Manus</strong></td>
      <td>研究转行动</td>
      <td>操作型工具（浏览器控制等）</td>
      <td>封闭不可控</td>
    </tr>
    <tr>
      <td><strong>Camel-AI</strong></td>
      <td>自由定制Agent角色</td>
      <td>200+工具适配+本地运行</td>
      <td>需编排设计能力</td>
    </tr>
  </tbody>
</table>

<h3 id="用户可控性与可扩展性">用户可控性与可扩展性</h3>

<table>
  <thead>
    <tr>
      <th>方案</th>
      <th>可控性</th>
      <th>扩展机制</th>
      <th>适用场景</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>LangChain</strong></td>
      <td>完全开源+插件配置</td>
      <td>替换LLM/搜索源/Prompt</td>
      <td>开发者定制</td>
    </tr>
    <tr>
      <td><strong>OpenAI</strong></td>
      <td>几乎不可控</td>
      <td>有限API扩展</td>
      <td>开箱即用</td>
    </tr>
    <tr>
      <td><strong>Anthropic</strong></td>
      <td>API外围控制</td>
      <td>Claude on your data</td>
      <td>企业级应用</td>
    </tr>
    <tr>
      <td><strong>Manus</strong></td>
      <td>仅任务输入控制</td>
      <td>无扩展接口</td>
      <td>大众用户</td>
    </tr>
    <tr>
      <td><strong>Camel-AI</strong></td>
      <td>完全开源+高度定制</td>
      <td>自由组装Agent团队</td>
      <td>研发人员DIY</td>
    </tr>
  </tbody>
</table>

<h3 id="开源-vs-闭源社区与维护性">开源 vs 闭源、社区与维护性</h3>

<table>
  <thead>
    <tr>
      <th>方案</th>
      <th>开源状态</th>
      <th>社区规模</th>
      <th>维护性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>LangChain</strong></td>
      <td>MIT许可</td>
      <td>6万+⭐主库</td>
      <td>专业团队+社区保障</td>
    </tr>
    <tr>
      <td><strong>OpenAI</strong></td>
      <td>闭源SaaS</td>
      <td>API文档+论坛</td>
      <td>供应风险</td>
    </tr>
    <tr>
      <td><strong>Anthropic</strong></td>
      <td>闭源服务</td>
      <td>商业支持</td>
      <td>依赖厂商</td>
    </tr>
    <tr>
      <td><strong>Manus</strong></td>
      <td>闭源商业</td>
      <td>小型私域</td>
      <td>初创风险</td>
    </tr>
    <tr>
      <td><strong>Camel-AI</strong></td>
      <td>完全开源</td>
      <td>2000+成员</td>
      <td>社区共建</td>
    </tr>
  </tbody>
</table>

<h3 id="代码复杂度与依赖性">代码复杂度与依赖性</h3>

<table>
  <thead>
    <tr>
      <th>方案</th>
      <th>实现复杂度</th>
      <th>依赖项</th>
      <th>部署难度</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>LangChain</strong></td>
      <td>中等偏上</td>
      <td>LangChain+LangGraph+API密钥</td>
      <td>模块化配置</td>
    </tr>
    <tr>
      <td><strong>OpenAI</strong></td>
      <td>零复杂度</td>
      <td>官方SDK/API</td>
      <td>最简单</td>
    </tr>
    <tr>
      <td><strong>Anthropic</strong></td>
      <td>不可见</td>
      <td>Claude API</td>
      <td>云端完成</td>
    </tr>
    <tr>
      <td><strong>Manus</strong></td>
      <td>云端隐藏</td>
      <td>联网使用</td>
      <td>完全依赖厂商</td>
    </tr>
    <tr>
      <td><strong>Camel-AI</strong></td>
      <td>中高复杂度</td>
      <td>Python+Node.js+本地模型</td>
      <td>需要开发能力</td>
    </tr>
  </tbody>
</table>

<h2 id="langchain-deep-research-的不足与源码解析">LangChain Deep Research 的不足与源码解析</h2>

<h3 id="主要不足">主要不足</h3>

<ol>
  <li>
    <h4 id="高token消耗与成本问题"><strong>高Token消耗与成本问题</strong></h4>
    <p>高Token消耗与成本问题：多代理并行和多轮工具调用意味着生成大量Token。正如Anthropic指出，多代理研究比普通对话Token使用高出约15倍。
LangChain虽通过上下文压缩缓解，但在处理超长文档或非常广的课题时，仍可能遇到上下文长度瓶颈或费用高昂的问题。如果用户不加限制地提高并发
子代理数量和搜索轮数，成本会线性上涨。如何智能地控制代理搜索深度、过滤无效内容仍有优化空间。例如，引入自适应搜索终止条件，根据信息增益
决定是否继续，而不是固定迭代次数。</p>

    <ul>
      <li>多代理并行导致Token使用量激增</li>
      <li>需智能控制搜索深度（自适应终止条件）</li>
    </ul>
  </li>
  <li>
    <h4 id="多代理协调与重复风险"><strong>多代理协调与重复风险</strong></h4>
    <p>多代理系统一个固有挑战是子代理可能目标重叠或互相干扰。LangChain Deep Research目前通过让每个子代理只看自己的topic来避免串话。
但如果用户请求的子话题存在关联（例如交叉领域），子代理仍可能检索到重复内容或遗漏需要协作的部分。当前架构中，子代理彼此独立检索，缺少中途
交流机制，只有主管汇总阶段才能发现重复或缺口。这可能导致报告部分内容冗余或章节衔接不紧密。改进思路是在主管代理层面增加子代理任务规划的
优化：例如先搜集所有子代理找到的来源列表，消除重复，再指导尚未完成的子代理避开这些来源，以减少冗余。或者引入一个全局观察者Agent，在子
代理进行过程中监控其进展并提示调整策略。另外，LangChain早期尝试让子代理并行写报告各章节，但效果不好，于是改为集中写作。如何既利用并行
又保持章节连贯，依然值得探索。</p>

    <ul>
      <li>子代理可能目标重叠</li>
      <li>缺少中途交流机制</li>
      <li>改进思路：全局观察者Agent监控</li>
    </ul>
  </li>
  <li>
    <h4 id="本地化和长期知识"><strong>本地化和长期知识</strong></h4>
    <p>LangChain Deep Research依赖于在线搜索，对专有本地知识或长远记忆支持不足。如果研究课题涉及用户自有文档或历史研究结果，目前框架并未
整合向量数据库或长时记忆模块来利用它们。这方面可以借鉴AutoGPT等的内存机制，或LangChain自家的RetrievalQA链，将Deep Research产生的
知识存档，用于下次类似问题的加速回答。此外，Deep Research产生的详尽报告本身就是很有价值的知识，每次都从头研究有些浪费。如果引入知识库
缓存（哪怕简单地将报告存入数据库，下次遇到相关问题时优先引用），将提升效率。然而如何保证知识不过时、何时触发重新检索，这是实现中的难点，
需要更智能的策略。</p>

    <ul>
      <li>未整合向量数据库</li>
      <li>缺乏知识重用机制</li>
      <li>改进方向：引入知识库缓存</li>
    </ul>
  </li>
  <li>
    <h4 id="代码与文档"><strong>代码与文档</strong></h4>
    <p>对于开发者用户来说，LangChain Deep Research的代码文档较简略，上手不易。一些功能需要通过博客或案例才能明白。比如open_deep_research
仓库中只有README描述配置，核心逻辑埋在LangGraph Graph定义里，不阅读源码难以理解全貌。这对社区贡献和二次开发是门槛。希望后续LangChain
团队能提供更详细的架构讲解文档，或者像Camel社区那样提供教程范例，帮助开发者定制Deep Research流程。</p>

    <ul>
      <li>核心逻辑埋在LangGraph定义中</li>
      <li>需要更详细架构文档</li>
    </ul>
  </li>
</ol>

<h3 id="源码解析多代理调度">源码解析：多代理调度</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># supervisor_tools 函数简化片段
</span><span class="k">if</span> <span class="n">sections_list</span><span class="p">:</span>
    <span class="c1"># 规划报告章节后并行发送给子代理
</span>    <span class="k">return</span> <span class="n">Command</span><span class="p">(</span>
        <span class="n">goto</span><span class="o">=</span><span class="p">[</span><span class="n">Send</span><span class="p">(</span><span class="s">"research_team"</span><span class="p">,</span> <span class="p">{</span><span class="s">"section"</span><span class="p">:</span> <span class="n">s</span><span class="p">})</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sections_list</span><span class="p">],</span>
        <span class="n">update</span><span class="o">=</span><span class="p">{</span><span class="s">"messages"</span><span class="p">:</span> <span class="n">result</span><span class="p">}</span>
    <span class="p">)</span>

<span class="c1"># research_agent_tools 函数简化片段
</span><span class="k">if</span> <span class="n">completed_section</span><span class="p">:</span>
    <span class="c1"># 子代理完成章节写作后返回
</span>    <span class="k">return</span> <span class="p">{</span>
        <span class="s">"messages"</span><span class="p">:</span> <span class="n">result</span><span class="p">,</span>
        <span class="s">"completed_sections"</span><span class="p">:</span> <span class="p">[</span><span class="n">completed_section</span><span class="p">]</span>
    <span class="p">}</span>

</code></pre></div></div>

<h3 id="关键机制">关键机制：</h3>

<ul>
  <li>自动任务拆分：Supervisor通过Sections工具获取章节列表</li>
  <li>并行子代理执行：LangGraph的Send命令启动并行任务</li>
  <li>上下文隔离：每个子代理仅接收自己的section参数</li>
  <li>同步汇总：LangGraph等待所有子代理返回</li>
</ul>

<h3 id="优化方向">优化方向：</h3>

<ul>
  <li>基于知识图谱的智能任务划分</li>
  <li>动态增减子代理（层次化子代理）</li>
  <li>子代理间适度通信</li>
  <li>自适应并发度控制</li>
</ul>

<h3 id="源码解析报告撰写">源码解析：报告撰写</h3>

<h4 id="核心流程">核心流程：</h4>

<ul>
  <li>子代理调用Section工具生成章节内容</li>
  <li>主管整理completed_sections</li>
  <li>触发写作模型生成引言/结论</li>
  <li>按顺序拼接最终报告</li>
</ul>

<h4 id="优化空间">优化空间：</h4>

<ul>
  <li>引用校验步骤确保准确性</li>
  <li>压缩机制避免上下文超限</li>
  <li>模板化输出保证格式统一</li>
  <li>分段写作+长上下文模型支持</li>
</ul>

<h2 id="结语">结语</h2>
<p>LangChain Deep Research 展示了多智能体协作在复杂信息检索任务上的强大潜力，其核心价值在于：</p>

<ul>
  <li>用LLM+工具实现自动规划和并行执行</li>
  <li>开源方式让研究代理走向大众开发者</li>
  <li>LangGraph框架支持状态管理和错误恢复</li>
</ul>

<h3 id="未来方向">未来方向：</h3>

<ul>
  <li>更智能的Agent调度机制</li>
  <li>长期记忆和知识重用</li>
  <li>多模态能力扩展</li>
  <li>生成结果准确度提升</li>
  <li>深度研究代理让专业知识的获取和整合变得前所未有地高效，随着技术成熟，人人都将拥有专属的AI研究员</li>
</ul>

<h2 id="参考文献">参考文献</h2>
<ol>
  <li><a href="https://blog.langchain.com/open-deep-research/?utm_source=chatgpt.com">LangChain Blog. Open Deep Research, Jul 16 2025.</a></li>
  <li><a href="https://github.com/langchain-ai/open_deep_research?utm_source=chatgpt.com">LangChain GitHub. open_deep_research Repository, 2025. </a></li>
  <li><a href="https://www.anthropic.com/engineering/built-multi-agent-research-system?utm_source=chatgpt.com">Anthropic Engineering Blog. How we built our multi-agent research system, Jun 13 2025. </a></li>
  <li><a href="https://openai.com/index/introducing-deep-research/?utm_source=chatgpt.com">OpenAI Blog. Introducing Deep Research, Feb 2 2025. </a></li>
  <li><a href="https://help.openai.com/en/articles/10500283-deep-research-faq?utm_source=chatgpt.com">OpenAI Help Center. Deep Research FAQ, 2025. </a></li>
  <li><a href="https://indianexpress.com/article/technology/artificial-intelligence/what-is-wide-research-manus-multi-agent-ai-tool-openai-google-10167139/?utm_source=chatgpt.com">The Indian Express. “Manus has positioned Wide Research…”, Aug 3 2025.</a></li>
  <li><a href="https://www.businessinsider.com/manus-early-access-test-general-ai-agent-china-deepseek-2025-3?utm_source=chatgpt.com">Business Insider. “I tested Manus, China’s ‘fully autonomous’ AI agent…”, Apr 2025. </a></li>
  <li><a href="https://www.camel-ai.org/?utm_source=chatgpt.com">Camel-AI. Eigent — World’s First Multi-agent Workforce, 2025. </a></li>
  <li><a href="https://github.com/langchain-ai/local-deep-researcher?utm_source=chatgpt.com">LangChain GitHub. local-deep-researcher Repository, 2025. </a></li>
  <li><a href="https://github.com/camel-ai/camel?utm_source=chatgpt.com">Camel-AI GitHub. CAMEL Framework, 2025.</a></li>
</ol>


        </main>
        
        <div class="tags">
            标签:
            
            <span class="tag">deepresearch</span>
            
            <span class="tag">langchain</span>
            
        </div>
        
    </article>
    <!-- Footer -->
    <footer class="footer">
      <p>&copy; 2025 Jason‘s Blog</p>
    </footer>

    <!-- Custom JavaScript -->
    <script src="/assets/js/main.js"></script>
</body>
<!--<script src="/assets/js/main.js"></script>-->

<!--&lt;!&ndash;<link rel="stylesheet" href="/assets/main.css">&ndash;&gt;-->
<!--<link rel="stylesheet" href="/assets/css/custom.css">-->
</html>